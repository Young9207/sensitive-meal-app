#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
diet_analyzer.py (with condition-based personalized suggestions + clickable details)
"""

from __future__ import annotations
import re, sys, ast, json, base64, zlib
from collections import defaultdict
from typing import List, Dict, Tuple, Any
from datetime import datetime, date, timedelta
from zoneinfo import ZoneInfo
import pandas as pd

try:
    import streamlit as st
except Exception:
    st = None  # allow import without Streamlit

# ====================== ì„¤ì • ======================
FOOD_DB_CSV = "food_db.csv"
NUTRIENT_DICT_CSV = "nutrient_dict.csv"
LOG_CSV = "log.csv"
FOOD_DB_UPDATED_CSV = "food_db_updated.csv"

SLOTS = ["ì•„ì¹¨", "ì•„ì¹¨ë³´ì¡°ì œ", "ì˜¤ì „ ê°„ì‹", "ì ì‹¬", "ì ì‹¬ë³´ì¡°ì œ",
         "ì˜¤í›„ ê°„ì‹", "ì €ë…", "ì €ë…ë³´ì¡°ì œ", "ì €ë… ê°„ì‹"]

TZ = ZoneInfo("Europe/Paris")

# ==================== ë‚ ì§œ/ìƒíƒœ ê´€ë¦¬ ====================
def today_str() -> str:
    return datetime.now(TZ).date().isoformat()

def next_midnight():
    now = datetime.now(TZ)
    return (now + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0, tzinfo=TZ)

def init_daily_state():
    """ìì • ë‹¨ìœ„ë¡œ stateë¥¼ ìœ ì§€. ë‚ ì§œ ë°”ë€Œë©´ ìë™ ì´ˆê¸°í™”."""
    if "daily_date" not in st.session_state:
        st.session_state.daily_date = today_str()
    if st.session_state.daily_date != today_str():
        for k in ["inputs", "conditions", "last_items_df", "last_nutri_df", "last_recs", "last_combo"]:
            st.session_state.pop(k, None)
        st.session_state.daily_date = today_str()

    st.session_state.setdefault("inputs", {s: "" for s in SLOTS})
    st.session_state.setdefault("conditions", {s: "" for s in SLOTS})
    st.session_state.setdefault("last_items_df", None)
    st.session_state.setdefault("last_nutri_df", None)
    st.session_state.setdefault("last_recs", [])
    st.session_state.setdefault("last_combo", [])
    st.session_state.setdefault("threshold", 1)
    st.session_state.setdefault("export_flag", True)

    # âœ… log.csvì—ì„œ ì˜¤ëŠ˜ ë‚ ì§œì˜ ìµœì‹  1ê±´ì”© ë³µì›
    try:
        df_log = pd.read_csv(LOG_CSV)
        today_logs = df_log[df_log["date"] == today_str()]
        if not today_logs.empty:
            for slot in SLOTS:
                slot_logs = today_logs[today_logs["slot"] == slot]
                if not slot_logs.empty:
                    latest = slot_logs.sort_values("timestamp").tail(1).iloc[0]
                    st.session_state.inputs[slot] = str(latest.get("ì…ë ¥í•­ëª©", "") or "")
                    st.session_state.conditions[slot] = str(latest.get("ì»¨ë””ì…˜", "") or "")
            st.session_state.last_items_df = today_logs.rename(columns={"slot": "ìŠ¬ë¡¯", "date": "ë‚ ì§œ"})
    except FileNotFoundError:
        pass

# ==================== ìœ í‹¸ ====================
def _parse_tags_from_slash(cell) -> List[str]:
    if pd.isna(cell):
        return []
    return [t.strip() for t in str(cell).split('/') if t.strip()]

def _parse_taglist_cell(cell: Any) -> List[str]:
    if isinstance(cell, list):
        return [str(x).strip() for x in cell if str(x).strip()]
    s = "" if cell is None or (isinstance(cell, float) and pd.isna(cell)) else str(cell).strip()
    if not s or s == "[]":
        return []
    try:
        v = ast.literal_eval(s)
        if isinstance(v, list):
            return [str(x).strip() for x in v if str(x).strip()]
    except Exception:
        pass
    try:
        v = json.loads(s)
        if isinstance(v, list):
            return [str(x).strip() for x in v if str(x).strip()]
    except Exception:
        pass
    s2 = s.strip().strip("[]")
    parts = [p.strip().strip("'").strip('"') for p in re.split(r"[,/]", s2) if p.strip()]
    return [p for p in parts if p]

def load_food_db_simple(path: str = FOOD_DB_CSV) -> pd.DataFrame:
    df = pd.read_csv(path)
    for c in ["ì‹í’ˆ", "ë“±ê¸‰", "íƒœê·¸(ì˜ì–‘)"]:
        if c not in df.columns:
            df[c] = ""
    if "íƒœê·¸ë¦¬ìŠ¤íŠ¸" in df.columns:
        df["íƒœê·¸ë¦¬ìŠ¤íŠ¸"] = df["íƒœê·¸ë¦¬ìŠ¤íŠ¸"].apply(_parse_taglist_cell)
    else:
        df["íƒœê·¸ë¦¬ìŠ¤íŠ¸"] = df["íƒœê·¸(ì˜ì–‘)"].apply(_parse_tags_from_slash)
    return df[["ì‹í’ˆ", "ë“±ê¸‰", "íƒœê·¸(ì˜ì–‘)", "íƒœê·¸ë¦¬ìŠ¤íŠ¸"]]

def load_nutrient_dict_simple(path: str = NUTRIENT_DICT_CSV) -> Dict[str, str]:
    nd = pd.read_csv(path)
    for c in ["ì˜ì–‘ì†Œ", "í•œì¤„ì„¤ëª…"]:
        if c not in nd.columns:
            nd[c] = ""
    return {str(r["ì˜ì–‘ì†Œ"]).strip(): str(r["í•œì¤„ì„¤ëª…"]).strip() for _, r in nd.iterrows()}

_GRADE_ORDER = {"Avoid": 2, "Caution": 1, "Safe": 0}
def _worse_grade(g1: str, g2: str) -> str:
    return g1 if _GRADE_ORDER.get(g1, 0) >= _GRADE_ORDER.get(g2, 0) else g2
def _norm(s: str) -> str:
    return str(s or "").strip()

def split_items(text: str) -> List[str]:
    if not text:
        return []
    first = [p.strip() for p in re.split(r"[,|\n|(|)]+", text) if p.strip()]
    final = []
    for part in first:
        final += [q.strip() for q in part.split('+') if q.strip()]
    return final

def parse_qty(token: str) -> Tuple[str, float]:
    m = re.search(r"(.*?)(\d+(?:\.\d+)?)\s*$", token)
    if m:
        return m.group(1).strip(), float(m.group(2))
    return token.strip(), 1.0

# ================== ë¶„ì„ í•¨ìˆ˜ ==================
def match_item_to_foods(item: str, df_food: pd.DataFrame) -> pd.DataFrame:
    it = _norm(item)
    hits = df_food[df_food["ì‹í’ˆ"].apply(lambda x: _norm(x) in it or it in _norm(x))].copy()
    hits = hits[hits["ì‹í’ˆ"].apply(lambda x: len(_norm(x)) >= 1)]
    return hits

def analyze_items_for_slot(input_text: str, slot: str, df_food: pd.DataFrame,
                           nutrient_desc: Dict[str, str], condition: str = ""):
    raw_tokens = split_items(input_text)
    items = [parse_qty(tok) for tok in raw_tokens]

    per_item_rows, log_rows, unmatched_names = [], [], []
    nutrient_counts = defaultdict(float)

    for raw, qty in items:
        if not raw:
            continue
        matched = match_item_to_foods(raw, df_food)
        timestamp = datetime.now(TZ).isoformat(timespec="seconds")

        if matched.empty:
            per_item_rows.append({"ìŠ¬ë¡¯": slot, "ì…ë ¥í•­ëª©": raw, "ìˆ˜ëŸ‰": qty,
                                  "ë§¤ì¹­ì‹í’ˆ": "", "ë“±ê¸‰": "", "íƒœê·¸": "", "ì»¨ë””ì…˜": condition})
            log_rows.append({"timestamp": timestamp, "date": today_str(), "time": timestamp.split("T")[1],
                             "slot": slot, "ì…ë ¥í•­ëª©": raw, "ìˆ˜ëŸ‰": qty, "ë§¤ì¹­ì‹í’ˆ": "",
                             "ë“±ê¸‰": "", "íƒœê·¸": "", "ì»¨ë””ì…˜": condition})
            unmatched_names.append(_norm(raw))
            continue

        agg_grade, tag_union, matched_names = "Safe", [], []
        for _, r in matched.iterrows():
            name = _norm(r["ì‹í’ˆ"])
            grade = _norm(r["ë“±ê¸‰"]) or "Safe"
            tags = r.get("íƒœê·¸ë¦¬ìŠ¤íŠ¸", [])
            if not isinstance(tags, list):
                tags = _parse_taglist_cell(tags)
            if not tags:
                tags = _parse_tags_from_slash(r.get("íƒœê·¸(ì˜ì–‘)", ""))
            agg_grade = _worse_grade(agg_grade, grade)
            matched_names.append(name)
            for t in tags:
                if t:
                    tag_union.append(t)
                    nutrient_counts[t] += float(qty or 1.0)

        per_item_rows.append({"ìŠ¬ë¡¯": slot, "ì…ë ¥í•­ëª©": raw, "ìˆ˜ëŸ‰": qty,
                              "ë§¤ì¹­ì‹í’ˆ": ", ".join(dict.fromkeys(matched_names)),
                              "ë“±ê¸‰": agg_grade, "íƒœê·¸": ", ".join(dict.fromkeys(tag_union)),
                              "ì»¨ë””ì…˜": condition})
        log_rows.append({"timestamp": timestamp, "date": today_str(), "time": timestamp.split("T")[1],
                         "slot": slot, "ì…ë ¥í•­ëª©": raw, "ìˆ˜ëŸ‰": qty,
                         "ë§¤ì¹­ì‹í’ˆ": ", ".join(dict.fromkeys(matched_names)),
                         "ë“±ê¸‰": agg_grade, "íƒœê·¸": ", ".join(dict.fromkeys(tag_union)),
                         "ì»¨ë””ì…˜": condition})
    return (pd.DataFrame(per_item_rows), dict(nutrient_counts),
            pd.DataFrame(log_rows), unmatched_names)

# ==================== URL ìƒíƒœ ì €ì¥/ë³µì› ====================
def _b64_encode(obj: dict) -> str:
    raw = json.dumps(obj, ensure_ascii=False, separators=(",", ":")).encode("utf-8")
    comp = zlib.compress(raw, level=9)
    return base64.urlsafe_b64encode(comp).decode("ascii")

def _b64_decode(s: str) -> dict | None:
    try:
        comp = base64.urlsafe_b64decode(s.encode("ascii"))
        raw = zlib.decompress(comp)
        return json.loads(raw.decode("utf-8"))
    except Exception:
        return None

def save_state_to_url():
    data = {
        "inputs": st.session_state.get("inputs", {}),
        "conditions": st.session_state.get("conditions", {}),
        "threshold": st.session_state.get("threshold", 1),
        "export_flag": st.session_state.get("export_flag", True),
        "daily_date": st.session_state.get("daily_date", None)
    }
    st.experimental_set_query_params(state=_b64_encode(data))

def load_state_from_url():
    params = st.experimental_get_query_params()
    if "state" not in params:
        return
    decoded = _b64_decode(params["state"][0])
    if not decoded:
        return
    st.session_state.inputs = decoded.get("inputs", {})
    st.session_state.conditions = decoded.get("conditions", {})
    st.session_state.threshold = decoded.get("threshold", 1)
    st.session_state.export_flag = decoded.get("export_flag", True)

# ================== ì»¨ë””ì…˜ â†’ íƒœê·¸ ë§¤í•‘ ==================
def condition_to_nutrients(condition: str) -> List[str]:
    cond = condition.lower()
    needs = []
    if any(k in cond for k in ["í”¼ê³¤", "ë¬´ê¸°ë ¥", "ê¸°ìš´ ì—†ìŒ"]):
        needs += ["ë‹¨ë°±ì§ˆ", "ë¹„íƒ€ë¯¼B", "ì² ë¶„"]
    if any(k in cond for k in ["ë³µë¶€íŒ½ë§Œ", "ë”ë¶€ë£©", "ì†Œí™”ë¶ˆëŸ‰"]):
        needs += ["ì €FODMAP", "ì‹ì´ì„¬ìœ (ì ë‹¹ëŸ‰)"]
    if any(k in cond for k in ["ì†ì“°ë¦¼", "ìœ„ì‚°"]):
        needs += ["ì €ì§€ë°©", "ì €ì‚°ì„±"]
    if "ë‘í†µ" in cond or "ì–´ì§€ëŸ½" in cond:
        needs += ["ë§ˆê·¸ë„¤ìŠ˜", "ìˆ˜ë¶„"]
    if "ë¶ˆë©´" in cond or "ìˆ˜ë©´" in cond:
        needs += ["íŠ¸ë¦½í† íŒ", "ì¹¼ìŠ˜"]
    if "ë³€ë¹„" in cond:
        needs += ["ì‹ì´ì„¬ìœ ", "ìˆ˜ë¶„"]
    if "ì„¤ì‚¬" in cond:
        needs += ["ì „í•´ì§ˆ", "ìˆ˜ë¶„"]
    return list(dict.fromkeys(needs))

# ================== íƒœê·¸ â†’ ì‹í’ˆêµ° ì¶”ì²œ ==================
NUTRIENT_TO_FOODS = {
    "ë‹¨ë°±ì§ˆ": ["ë‹¬ê±€", "ë‹­ê°€ìŠ´ì‚´", "ë‘ë¶€", "ê·¸ë¦­ìš”ê±°íŠ¸", "ìƒì„ "],
    "ë¹„íƒ€ë¯¼B": ["í˜„ë¯¸", "í†µê³¡ë¬¼ë¹µ", "ì½©ë¥˜", "ê³„ë€ë…¸ë¥¸ì"],
    "ì² ë¶„": ["ì‹œê¸ˆì¹˜", "ê°„", "ë¶‰ì€ì‚´ìƒì„ ", "ë Œí‹¸ì½©"],
    "ì €FODMAP": ["í˜¸ë°•", "ë‹¹ê·¼", "ê°ì", "ìŒ€ë°¥"],
    "ì‹ì´ì„¬ìœ ": ["ê·€ë¦¬", "í†µê³¡ë¬¼", "ì‚¬ê³¼", "ë¸Œë¡œì½œë¦¬"],
    "ì‹ì´ì„¬ìœ (ì ë‹¹ëŸ‰)": ["ë‹¹ê·¼", "í˜¸ë°•ì£½", "ë°”ë‚˜ë‚˜"],
    "ì €ì§€ë°©": ["ì°ê°ì", "ë‹­ê°€ìŠ´ì‚´", "ë‘ë¶€", "ì €ì§€ë°©ìš”ê±°íŠ¸"],
    "ì €ì‚°ì„±": ["ë°”ë‚˜ë‚˜", "ê°ì", "ë‘ìœ ", "í°ì£½"],
    "ë§ˆê·¸ë„¤ìŠ˜": ["ê²¬ê³¼ë¥˜", "ì‹œê¸ˆì¹˜", "ì¹´ì¹´ì˜¤ë‹™ìŠ¤"],
    "ìˆ˜ë¶„": ["êµ­ë¬¼", "ê³¼ì¼", "ë¬¼", "ìˆ˜í”„"],
    "íŠ¸ë¦½í† íŒ": ["ë‹¬ê±€", "ê·€ë¦¬", "ë°”ë‚˜ë‚˜", "ì•„ë³´ì¹´ë„"],
    "ì¹¼ìŠ˜": ["ìš”ê±°íŠ¸", "ë©¸ì¹˜", "ì¹˜ì¦ˆ", "ë‘ìœ "],
    "ì „í•´ì§ˆ": ["ë°”ë‚˜ë‚˜", "ì†Œê¸ˆê°„ êµ­ë¬¼", "ë¯¸ìŒ"]
}

# ================== ì‹í’ˆ ì„¸ë¶€ì •ë³´ í‘œì‹œ ==================
def show_food_details(food: str, df_food: pd.DataFrame, nutrient_desc: Dict[str, str]):
    matches = df_food[df_food["ì‹í’ˆ"].str.contains(food, case=False, na=False)]
    if matches.empty:
        st.warning(f"'{food}' ì •ë³´ ì—†ìŒ")
        return
    with st.expander(f"ğŸ½ {food} ì„¸ë¶€ì •ë³´ ë³´ê¸°"):
        for _, row in matches.iterrows():
            grade = row.get("ë“±ê¸‰", "ì •ë³´ì—†ìŒ")
            tags = row.get("íƒœê·¸ë¦¬ìŠ¤íŠ¸", [])
            if not tags:
                tags = _parse_taglist_cell(row.get("íƒœê·¸(ì˜ì–‘)", ""))
            st.write(f"**ë“±ê¸‰:** {grade}")
            st.write(f"**ì˜ì–‘ íƒœê·¸:** {', '.join(tags) if tags else 'ì—†ìŒ'}")
            for t in tags:
                desc = nutrient_desc.get(t, "")
                if desc:
                    st.caption(f"â€¢ {t}: {desc}")

# ==================== Streamlit UI ====================
def main():
    st.set_page_config(page_title="ìŠ¬ë¡¯ë³„ ì‹ë‹¨ ë¶„ì„ Â· ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ", page_icon="ğŸ¥—", layout="centered")
    st.title("ğŸ¥— ìŠ¬ë¡¯ë³„ ì‹ë‹¨ ë¶„ì„ Â· ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ")

    init_daily_state()
    remain = next_midnight() - datetime.now(TZ)
    st.caption(f"í˜„ì¬ ì…ë ¥/ê²°ê³¼ëŠ” ìì •ê¹Œì§€ ë³´ì¡´ë©ë‹ˆë‹¤. ë‚¨ì€ ì‹œê°„: {remain.seconds//3600}ì‹œê°„ {remain.seconds%3600//60}ë¶„")

    load_state_from_url()

    df_food = load_food_db_simple(FOOD_DB_CSV)
    nutrient_desc = load_nutrient_dict_simple(NUTRIENT_DICT_CSV)

    d = st.date_input("ê¸°ë¡ ë‚ ì§œ", value=date.today())

    for slot in SLOTS:
        val = st.text_area(slot, height=70, placeholder=f"{slot}ì— ë¨¹ì€ ê²ƒ ì…ë ¥",
                           key=f"ta_{slot}", value=st.session_state.inputs.get(slot, ""))
        st.session_state.inputs[slot] = val

        cond = st.text_input(f"{slot} ì»¨ë””ì…˜", placeholder="ì˜ˆ: ì–‘í˜¸ / í”¼ê³¤í•¨ / ë³µë¶€íŒ½ë§Œ",
                             key=f"cond_{slot}", value=st.session_state.conditions.get(slot, ""))
        st.session_state.conditions[slot] = cond

    c1, c2, c3 = st.columns([1, 1, 1])
    with c1:
        st.number_input("ì¶©ì¡± ì„ê³„(ìˆ˜ëŸ‰í•©)", min_value=1, max_value=5,
                        value=st.session_state.get("threshold", 1),
                        step=1, key="threshold")
    with c2:
        st.checkbox("log.csv ì €ì¥", value=st.session_state.get("export_flag", True), key="export_flag")
    with c3:
        analyze_clicked = st.button("ë¶„ì„í•˜ê¸°", type="primary", key="analyze_btn")

    save_state_to_url()

    if analyze_clicked:
        all_items, all_logs, total_counts, all_unmatched = [], [], defaultdict(float), []
        for slot in SLOTS:
            items_df, counts, log_df, unmatched = analyze_items_for_slot(
                st.session_state.inputs.get(slot, ""), slot, df_food, nutrient_desc,
                condition=st.session_state.conditions.get(slot, "")
            )
            if not items_df.empty:
                items_df["ë‚ ì§œ"] = d.isoformat()
            all_items.append(items_df)
            all_logs.append(log_df)
            all_unmatched += unmatched
            for k, v in counts.items():
                total_counts[k] += v

        items_df_all = pd.concat(all_items, ignore_index=True) if all_items else pd.DataFrame()
        logs_all = pd.concat(all_logs, ignore_index=True) if all_logs else pd.DataFrame()

        if st.session_state.export_flag and not logs_all.empty:
            try:
                try:
                    prev = pd.read_csv(LOG_CSV)
                    merged = pd.concat([prev, logs_all], ignore_index=True)
                except Exception:
                    merged = logs_all.copy()
                merged = merged.drop_duplicates(
                    subset=["date","slot","ì…ë ¥í•­ëª©","ë§¤ì¹­ì‹í’ˆ","ë“±ê¸‰","íƒœê·¸","ì»¨ë””ì…˜"], keep="last"
                )
                merged.to_csv(LOG_CSV, index=False, encoding="utf-8-sig")
                st.success("log.csv ì €ì¥ ì™„ë£Œ")
            except Exception as e:
                st.error(f"log.csv ì €ì¥ ì˜¤ë¥˜: {e}")

        st.session_state.last_items_df = items_df_all

        # âœ… ì»¨ë””ì…˜+ì˜ì–‘ íƒœê·¸ ê¸°ë°˜ ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ (í´ë¦­í˜•)
        st.markdown("### ğŸ½ ê°œì¸í™”ëœ ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ")

        total_tags = []
        if not items_df_all.empty and "íƒœê·¸" in items_df_all.columns:
            for tags in items_df_all["íƒœê·¸"].dropna():
                total_tags += [t.strip() for t in str(tags).split(",") if t.strip()]
        tag_counts = pd.Series(total_tags).value_counts().to_dict() if total_tags else {}

        suggestions = []
        for slot in SLOTS:
            cond = st.session_state.conditions.get(slot, "")
            if not cond.strip():
                continue
            needed_tags = condition_to_nutrients(cond)
            suggested_foods = []
            for tag in needed_tags:
                # í˜„ì¬ íƒœê·¸ ì„­ì·¨ëŸ‰ì´ ì„ê³„ì¹˜ë³´ë‹¤ ì ìœ¼ë©´ ë³´ì™„ ì œì•ˆ
                if tag_counts.get(tag, 0) < st.session_state.threshold:
                    foods = NUTRIENT_TO_FOODS.get(tag, [])
                    if foods:
                        suggested_foods += foods
            suggestions.append((slot, cond, list(dict.fromkeys(suggested_foods[:5]))))

        if suggestions:
            for slot, cond, foods in suggestions:
                if foods:
                    st.markdown(f"#### ğŸ©º {slot} ì»¨ë””ì…˜: {cond}")
                    cols = st.columns(len(foods))
                    for i, food in enumerate(foods):
                        with cols[i]:
                            if st.button(food, key=f"suggest_btn_{slot}_{food}"):
                                show_food_details(food, df_food, nutrient_desc)
                else:
                    if cond.strip():
                        st.info(f"{slot} ì»¨ë””ì…˜({cond}) â†’ í˜„ì¬ ì‹ë‹¨ ê· í˜• ì–‘í˜¸")
        else:
            st.info("ì˜¤ëŠ˜ ê¸°ë¡ëœ ì»¨ë””ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ================== ê²°ê³¼ í‘œ ì˜ì—­ ==================
    st.markdown("### ğŸ± ìŠ¬ë¡¯ë³„ ë§¤ì¹­ ê²°ê³¼")
    if st.session_state.last_items_df is None or st.session_state.last_items_df.empty:
        st.info("ë§¤ì¹­ëœ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        cols = ["ë‚ ì§œ","ìŠ¬ë¡¯","ì…ë ¥í•­ëª©","ìˆ˜ëŸ‰","ë§¤ì¹­ì‹í’ˆ","ë“±ê¸‰","íƒœê·¸"]
        if "ì»¨ë””ì…˜" in st.session_state.last_items_df.columns:
            cols.append("ì»¨ë””ì…˜")
        # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í‘œì‹œ(ë°©ì–´ì )
        cols = [c for c in cols if c in st.session_state.last_items_df.columns]
        st.dataframe(
            st.session_state.last_items_df[cols],
            use_container_width=True,
            height=min(420, 36*(len(st.session_state.last_items_df)+1))
        )

if __name__ == "__main__":
    if st is None:
        print("This script requires Streamlit. Install with: pip install streamlit")
        sys.exit(1)
    main()