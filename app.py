# -*- coding: utf-8 -*-
"""
app_v5.py â€” Instant Diet Evaluator (fixed)
-----------------------------------------
- Robust tag parsing (_to_tags)
- Today-only analysis option (logs)
- One-line intuitive daily summary
- Per-meal breakdown: what boosted which nutrients (with simple benefits)
- Nutrient tips + glossary (plain-language)

Run:
    streamlit run app_v5.py
"""
import re
import ast
import random
from typing import List, Tuple, Dict, Any

import pandas as pd
import streamlit as st
from difflib import get_close_matches

# -----------------------------
# Minimal in-app "DB" (demo)
# -----------------------------
CORE_NUTRIENTS = [
    "ë‹¨ë°±ì§ˆ", "ì‹ì´ì„¬ìœ ", "ì² ", "ì¹¼ìŠ˜", "ë§ˆê·¸ë„¤ìŠ˜", "ì¹¼ë¥¨",
    "ì˜¤ë©”ê°€3", "ë¹„íƒ€ë¯¼A", "ë¹„íƒ€ë¯¼B", "ë¹„íƒ€ë¯¼C", "ë¹„íƒ€ë¯¼D", "ë¹„íƒ€ë¯¼E",
    "ì €ë‹¹", "ì €ì—¼", "ê±´ê°•í•œì§€ë°©"
]
ESSENTIALS = ["ë‹¨ë°±ì§ˆ", "ì‹ì´ì„¬ìœ ", "ë¹„íƒ€ë¯¼C", "ì¹¼ìŠ˜"]

NUTRIENT_TIPS: Dict[str, str] = {
    "ë‹¨ë°±ì§ˆ": "ê·¼ìœ¡ ìœ ì§€ì™€ í¬ë§Œê°ì— ì¢‹ì•„ìš”â€”ì‹ì‚¬ í›„ í—ˆê¸°ë¥¼ ì¤„ì—¬ì¤˜ìš”.",
    "ì‹ì´ì„¬ìœ ": "ë°°ë³€ ë¦¬ë“¬ê³¼ í¬ë§Œê°, í˜ˆë‹¹ ê¸‰ìƒìŠ¹ì„ ì™„í™”í•´ìš”.",
    "ì² ": "í”¼ë¡œê° ì¤„ì´ê³  ì§‘ì¤‘ì— ë„ì›€â€”í˜ˆì•¡ ì‚°ì†Œ ìš´ë°˜ì— í•„ìˆ˜ì˜ˆìš”.",
    "ì¹¼ìŠ˜": "ë¼ˆÂ·ì¹˜ì•„ ê±´ê°•ì˜ ê¸°ë³¸â€”ê·¼ìœ¡ ìˆ˜ì¶•ì—ë„ í•„ìš”í•´ìš”.",
    "ë§ˆê·¸ë„¤ìŠ˜": "ê¸´ì¥ ì™„í™”ì™€ ìˆ˜ë©´Â·ê·¼ìœ¡ ê¸°ëŠ¥ì— ë„ì›€ì„ ì¤˜ìš”.",
    "ì¹¼ë¥¨": "ë‚˜íŠ¸ë¥¨ ë°°ì¶œì„ ë„ì™€ ë¶“ê¸°Â·í˜ˆì•• ê´€ë¦¬ì— ìœ ë¦¬í•´ìš”.",
    "ì˜¤ë©”ê°€3": "ì‹¬í˜ˆê´€ ê±´ê°•ê³¼ ì—¼ì¦ ê· í˜•ì— ë„ì›€â€”ë“±í‘¸ë¥¸ ìƒì„ ì— ë§ì•„ìš”.",
    "ë¹„íƒ€ë¯¼A": "ëˆˆÂ·í”¼ë¶€ ì ë§‰ ë³´í˜¸â€”ìƒ‰ ì§„í•œ ì±„ì†Œì— í’ë¶€í•´ìš”.",
    "ë¹„íƒ€ë¯¼B": "ì—ë„ˆì§€ ëŒ€ì‚¬ ì„œí¬íŠ¸â€”í”¼ë¡œê° ì™„í™”ì— ë„ì›€.",
    "ë¹„íƒ€ë¯¼C": "ë©´ì—­ê³¼ ì²  í¡ìˆ˜ì— ë„ì›€â€”ê°€ì—´ ëœ í•œ ì±„ì†ŒÂ·ê³¼ì¼ë¡œ.",
    "ë¹„íƒ€ë¯¼D": "ë¼ˆ ê±´ê°•ê³¼ ë©´ì—­ì— ë„ì›€â€”í–‡ë¹›Â·ê³„ë€Â·ìƒì„ ì—ë„ ìˆì–´ìš”.",
    "ë¹„íƒ€ë¯¼E": "ì„¸í¬ ë³´í˜¸(í•­ì‚°í™”)ì™€ í”¼ë¶€ ì»¨ë””ì…˜ì— ë„ì›€.",
    "ì €ë‹¹": "ì‹í›„ í˜ˆë‹¹ ì¶œë ì„ì„ ì¤„ì´ëŠ” ì„ íƒì´ì—ìš”.",
    "ì €ì—¼": "ë¶“ê¸°Â·í˜ˆì•• ê´€ë¦¬ì— ìœ ë¦¬â€”ê°€ê³µì‹í’ˆ ì†Œê¸ˆ ì²´í¬!",
    "ê±´ê°•í•œì§€ë°©": "í¬ë§Œê°Â·ì§€ìš©ì„± ë¹„íƒ€ë¯¼ í¡ìˆ˜ì— ë„ì›€(ì•„ë³´ì¹´ë„Â·ê²¬ê³¼).",
    "ì €ì§€ë°©": "ì—´ëŸ‰ ëŒ€ë¹„ ë‹¨ë°±ì§ˆì„ ì±„ìš°ê¸° ì¢‹ê³  ë¶€ë‹´ì´ ëœí•´ìš”."
}
NUTRIENT_TIPS_LONG: Dict[str, str] = {
    "ë‹¨ë°±ì§ˆ": "ê·¼ìœ¡ ìœ ì§€, ìƒì²˜ íšŒë³µ, í¬ë§Œê° ìœ ì§€ì— í•µì‹¬.",
    "ì‹ì´ì„¬ìœ ": "ë°°ë³€ ê·œì¹™ì„±, í¬ë§Œê°, í˜ˆë‹¹ ê¸‰ìƒìŠ¹ ì™„í™”ì— ë„ì›€.",
    "ì² ": "í”¼ë¡œê°Â·ì–´ì§€ëŸ¬ì›€ ì˜ˆë°©(ì‚°ì†Œ ìš´ë°˜). ë¹„íƒ€ë¯¼ Cì™€ í•¨ê»˜ ì„­ì·¨í•˜ë©´ í¡ìˆ˜â†‘",
    "ì¹¼ìŠ˜": "ë¼ˆÂ·ì¹˜ì•„ ê±´ê°•, ì‹ ê²½Â·ê·¼ìœ¡ ê¸°ëŠ¥.",
    "ë§ˆê·¸ë„¤ìŠ˜": "ê·¼ìœ¡ ì´ì™„, ìˆ˜ë©´Â·ê¸´ì¥ ì™„í™”, ì—ë„ˆì§€ ëŒ€ì‚¬.",
    "ì¹¼ë¥¨": "ë‚˜íŠ¸ë¥¨ ë°°ì¶œì„ ë„ì™€ ë¶“ê¸°Â·í˜ˆì•• ì¡°ì ˆ.",
    "ì˜¤ë©”ê°€3": "ì‹¬í˜ˆê´€Â·ë‡Œ ê±´ê°•, ì—¼ì¦ ê· í˜•.",
    "ë¹„íƒ€ë¯¼A": "ì•¼ê°„ ì‹œë ¥Â·í”¼ë¶€Â·ì ë§‰ ë³´í˜¸.",
    "ë¹„íƒ€ë¯¼B": "ì—ë„ˆì§€ ìƒì„±Â·í”¼ë¡œ ì™„í™”(ë³µí•©êµ°).",
    "ë¹„íƒ€ë¯¼C": "ë©´ì—­, ì²  í¡ìˆ˜, í•­ì‚°í™”.",
    "ë¹„íƒ€ë¯¼D": "ì¹¼ìŠ˜ í¡ìˆ˜Â·ë¼ˆ ê±´ê°•, ë©´ì—­ ì¡°ì ˆ.",
    "ë¹„íƒ€ë¯¼E": "í•­ì‚°í™”(ì„¸í¬ ë³´í˜¸), í”¼ë¶€ ì»¨ë””ì…˜.",
    "ì €ë‹¹": "ì‹í›„ í˜ˆë‹¹ ì¶œë ì„ ê°ì†Œ.",
    "ì €ì—¼": "ë¶“ê¸° ì™„í™”Â·í˜ˆì•• ê´€ë¦¬.",
    "ê±´ê°•í•œì§€ë°©": "í¬ë§Œê°Â·ì§€ìš©ì„± ë¹„íƒ€ë¯¼ í¡ìˆ˜ ë„ìš°ë¯¸."
}
BENEFIT_MAP: Dict[str, str] = {
    "ë‹¨ë°±ì§ˆ": "ê·¼ìœ¡Â·í¬ë§Œê°",
    "ì‹ì´ì„¬ìœ ": "ì¥ê±´ê°•Â·í¬ë§Œê°Â·í˜ˆë‹¹ì™„í™”",
    "ì¹¼ìŠ˜": "ë¼ˆÂ·ì¹˜ì•„",
    "ë¹„íƒ€ë¯¼D": "ë¼ˆÂ·ë©´ì—­",
    "ë¹„íƒ€ë¯¼C": "ë©´ì—­Â·ì² í¡ìˆ˜",
    "ì˜¤ë©”ê°€3": "ì‹¬í˜ˆê´€Â·ì—¼ì¦ì™„í™”",
    "ì¹¼ë¥¨": "ë¶“ê¸°Â·í˜ˆì••",
    "ë§ˆê·¸ë„¤ìŠ˜": "ê¸´ì¥ì™„í™”Â·ìˆ˜ë©´",
    "ë¹„íƒ€ë¯¼E": "í•­ì‚°í™”Â·í”¼ë¶€",
    "ë¹„íƒ€ë¯¼A": "ëˆˆÂ·í”¼ë¶€",
    "ë¹„íƒ€ë¯¼B": "ì—ë„ˆì§€ëŒ€ì‚¬"
}
NUTRIENT_SOURCES: Dict[str, List[str]] = {
    "ë‹¨ë°±ì§ˆ": ["ë‹­ê°€ìŠ´ì‚´", "ë‘ë¶€", "ì—°ì–´", "ê³„ë€", "ëŒ€êµ¬êµ¬ì´", "ìš”ê±°íŠ¸"],
    "ì‹ì´ì„¬ìœ ": ["í˜„ë¯¸ë°¥", "ê·€ë¦¬", "ë¸Œë¡œì½œë¦¬", "ì–‘ë°°ì¶”", "ì•„ë³´ì¹´ë„", "ë²„ì„¯"],
    "ì² ": ["ì‹œê¸ˆì¹˜", "ê·€ë¦¬", "ë¶‰ì€ì‚´ ìƒì„ ", "ì½©ë¥˜"],
    "ì¹¼ìŠ˜": ["ë‘ë¶€", "ë¸Œë¡œì½œë¦¬", "ìš”ê±°íŠ¸", "ì•„ëª¬ë“œ"],
    "ë§ˆê·¸ë„¤ìŠ˜": ["í˜„ë¯¸ë°¥", "ì‹œê¸ˆì¹˜", "ê²¬ê³¼ë¥˜"],
    "ì¹¼ë¥¨": ["ì•„ë³´ì¹´ë„", "ë°”ë‚˜ë‚˜", "ê°ì", "ì‹œê¸ˆì¹˜"],
    "ì˜¤ë©”ê°€3": ["ì—°ì–´", "ë“±í‘¸ë¥¸ ìƒì„ ", "í˜¸ë‘"],
    "ë¹„íƒ€ë¯¼A": ["ë‹¹ê·¼", "ì‹œê¸ˆì¹˜", "í˜¸ë°•"],
    "ë¹„íƒ€ë¯¼B": ["ë²„ì„¯", "í†µê³¡ë¬¼", "ë‹¬ê±€"],
    "ë¹„íƒ€ë¯¼C": ["ë¸Œë¡œì½œë¦¬", "ì–‘ë°°ì¶”", "í‚¤ìœ„", "íŒŒí”„ë¦¬ì¹´"],
    "ë¹„íƒ€ë¯¼D": ["ê³„ë€", "ì—°ì–´", "ë²„ì„¯(ì¼ê´‘ ê±´ì¡°)"],
    "ë¹„íƒ€ë¯¼E": ["ì˜¬ë¦¬ë¸Œìœ ", "ì•„ëª¬ë“œ", "ì•„ë³´ì¹´ë„"],
    "ì €ë‹¹": ["ì±„ì†Œ ìœ„ì£¼ ë°˜ì°¬", "í†µê³¡ë¬¼ ì†ŒëŸ‰", "ë¬´ê°€ë‹¹ ìš”ê±°íŠ¸"],
    "ì €ì—¼": ["êµ¬ìš´/ì° ì¡°ë¦¬", "ì–‘ë…ì ˆì œ", "í—ˆë¸ŒÂ·ë ˆëª¬ í™œìš©"],
    "ê±´ê°•í•œì§€ë°©": ["ì˜¬ë¦¬ë¸Œìœ ", "ì•„ë³´ì¹´ë„", "ê²¬ê³¼ë¥˜"]
}

FOOD_ROWS = [
    ("ë‹­ê°€ìŠ´ì‚´", "Safe", ["ë‹¨ë°±ì§ˆ", "ì €ì§€ë°©"]),
    ("ë‘ë¶€", "Safe", ["ë‹¨ë°±ì§ˆ", "ì¹¼ìŠ˜"]),
    ("ì—°ì–´", "Safe", ["ë‹¨ë°±ì§ˆ", "ì˜¤ë©”ê°€3", "ê±´ê°•í•œì§€ë°©"]),
    ("ê³„ë€", "Safe", ["ë‹¨ë°±ì§ˆ", "ë¹„íƒ€ë¯¼D"]),
    ("ëŒ€êµ¬êµ¬ì´", "Safe", ["ë‹¨ë°±ì§ˆ"]),
    ("í˜„ë¯¸ë°¥", "Safe", ["ì‹ì´ì„¬ìœ ", "ë§ˆê·¸ë„¤ìŠ˜"]),
    ("ê·€ë¦¬", "Safe", ["ì‹ì´ì„¬ìœ ", "ì² "]),
    ("í†µë°€ë¹µ", "Caution", ["ì‹ì´ì„¬ìœ "]),
    ("ìŒ€ë°¥", "Safe", []),
    ("ì‹œê¸ˆì¹˜", "Safe", ["ì² ", "ë¹„íƒ€ë¯¼A", "ë§ˆê·¸ë„¤ìŠ˜"]),
    ("ë¸Œë¡œì½œë¦¬", "Safe", ["ë¹„íƒ€ë¯¼C", "ì‹ì´ì„¬ìœ ", "ì¹¼ìŠ˜"]),
    ("ì–‘ë°°ì¶”", "Safe", ["ë¹„íƒ€ë¯¼C", "ì‹ì´ì„¬ìœ "]),
    ("ë‹¹ê·¼", "Safe", ["ë¹„íƒ€ë¯¼A"]),
    ("ë²„ì„¯", "Safe", ["ë¹„íƒ€ë¯¼B", "ì‹ì´ì„¬ìœ "]),
    ("ì˜¬ë¦¬ë¸Œìœ ", "Safe", ["ê±´ê°•í•œì§€ë°©", "ë¹„íƒ€ë¯¼E"]),
    ("ì•„ë³´ì¹´ë„", "Safe", ["ê±´ê°•í•œì§€ë°©", "ì¹¼ë¥¨", "ì‹ì´ì„¬ìœ "]),
    ("ì•„ëª¬ë“œ", "Caution", ["ê±´ê°•í•œì§€ë°©", "ë¹„íƒ€ë¯¼E", "ì¹¼ìŠ˜"]),
    ("ìš”ê±°íŠ¸", "Caution", ["ì¹¼ìŠ˜", "ë‹¨ë°±ì§ˆ"]),
]
food_db = pd.DataFrame(FOOD_ROWS, columns=["ì‹í’ˆ", "ë“±ê¸‰", "íƒœê·¸(ì˜ì–‘)"])

# -----------------------------
# Helpers
# -----------------------------
def _to_tags(val):
    """Normalize a 'íƒœê·¸(ì˜ì–‘)' cell into a list of clean tag strings."""
    if val is None:
        return []
    if isinstance(val, list):
        return [str(x).strip() for x in val if str(x).strip()]
    s = str(val).strip()
    # Try JSON/python-like list: "['ë‹¨ë°±ì§ˆ','ì¹¼ìŠ˜']" or '["ë‹¨ë°±ì§ˆ", "ì¹¼ìŠ˜"]'
    try:
        parsed = ast.literal_eval(s)
        if isinstance(parsed, list):
            return [str(x).strip() for x in parsed if str(x).strip()]
    except Exception:
        pass
    # Fallback: split by common separators
    parts = [x.strip() for x in re.split(r'[\/,\|\;]+', s) if x.strip()]
    out = []
    for t in parts:
        t2 = t.strip().strip('"').strip("'")
        if t2 == "ì‹ì´ ì„¬ìœ ":
            t2 = "ì‹ì´ì„¬ìœ "
        out.append(t2)
    return out

def split_free_text(text: str) -> List[str]:
    if not text:
        return []
    parts = re.split(r"[,|\n]+", text)
    return [p.strip() for p in parts if p.strip()]

def parse_qty(token: str) -> Tuple[str, float]:
    m = re.search(r"([0-9]+(?:\.[0-9]+)?)\s*$", token)
    if m:
        qty = float(m.group(1))
        name = token[: m.start()].strip()
        return name, qty
    return token.strip(), 1.0

def contains_any(text: str, keywords: List[str]) -> bool:
    text = (text or "").lower()
    for k in keywords or []:
        if k.lower() in text:
            return True
    return False

def match_food(name: str, df_food: pd.DataFrame) -> Tuple[str, bool]:
    names = df_food["ì‹í’ˆ"].tolist()
    if name in names:
        return name, True
    cand = get_close_matches(name, names, n=1, cutoff=0.6)
    if cand:
        return cand[0], True
    base = re.sub(r"(êµ¬ì´|ë³¶ìŒ|ì°œ|ìƒëŸ¬ë“œ|ìˆ˜í”„|ì¡°ë¦¼|êµ¬ìš´|ìƒ)", "", name).strip()
    if base and base != name:
        cand = get_close_matches(base, names, n=1, cutoff=0.6)
        if cand:
            return cand[0], True
    return name, False

def ensure_log() -> pd.DataFrame:
    """Stub for demo. Replace to connect with your real diary/log storage."""
    return pd.DataFrame(columns=["type", "date", "time", "food_norm", "item"])

def tokens_from_today_log() -> List[str]:
    import datetime as _dt
    df = ensure_log()
    if df is None or df.empty:
        return []
    today = _dt.datetime.now().date()
    try:
        df["date"] = pd.to_datetime(df["date"]).dt.date
    except Exception:
        return []
    df_today = df[(df["type"] == "food") & (df["date"] == today)].copy()
    now_time = _dt.datetime.now().time()
    try:
        df_today["time"] = pd.to_datetime(df_today["time"].astype(str), errors="coerce").dt.time
        df_today = df_today[df_today["time"].isna() | (df_today["time"] <= now_time)]
    except Exception:
        pass
    toks = []
    for _, r in df_today.iterrows():
        token = (str(r.get("item") or "")).strip() or (str(r.get("food_norm") or "")).strip()
        if token:
            toks.append(token)
    return toks

def today_food_log_df() -> pd.DataFrame:
    """Return today's log with time-of-day labels for per-meal breakdown."""
    import datetime as _dt
    df = ensure_log()
    if df is None or df.empty:
        return pd.DataFrame(columns=["type","date","time","food_norm","item","_dt","ì‹œê°„ëŒ€"])
    try:
        df = df[df["type"] == "food"].copy()
        df["date"] = pd.to_datetime(df["date"], errors="coerce")
        df = df.dropna(subset=["date"])
    except Exception:
        return pd.DataFrame(columns=["type","date","time","food_norm","item","_dt","ì‹œê°„ëŒ€"])
    today = pd.Timestamp.now().normalize()
    df = df[df["date"].dt.normalize() == today]
    def _parse_dt(row):
        try:
            t = pd.to_datetime(str(row.get("time") or ""), errors="coerce").time()
        except Exception:
            t = None
        d = row["date"].date()
        if t is None:
            return pd.Timestamp.combine(d, pd.Timestamp.now().time())
        return pd.Timestamp.combine(d, t)
    if not df.empty:
        df["_dt"] = df.apply(_parse_dt, axis=1)
        def _tod_label(ts):
            h = ts.hour
            if 5 <= h < 11: return "ì•„ì¹¨"
            if 11 <= h < 16: return "ì ì‹¬"
            if 16 <= h < 21: return "ì €ë…"
            return "ê°„ì‹"
        df["ì‹œê°„ëŒ€"] = df["_dt"].apply(_tod_label)
        df = df.sort_values("_dt")
    else:
        df["_dt"] = pd.NaT
        df["ì‹œê°„ëŒ€"] = ""
    return df

def per_meal_breakdown(df_food: pd.DataFrame, df_today: pd.DataFrame) -> pd.DataFrame:
    rows = []
    for _, r in df_today.iterrows():
        raw = str(r.get("item") or "").strip() or str(r.get("food_norm") or "").strip()
        if not raw:
            continue
        mapped, matched = match_food(raw, df_food)
        tags = []
        if matched:
            try:
                rec = df_food[df_food["ì‹í’ˆ"] == mapped].iloc[0]
                tags = _to_tags(rec.get("íƒœê·¸(ì˜ì–‘)", []))
            except Exception:
                tags = []
        benefits = []
        for t in tags:
            b = BENEFIT_MAP.get(t) or NUTRIENT_TIPS.get(t) or ""
            if b and b not in benefits:
                benefits.append(b)
        rows.append({
            "ì‹œê°„ëŒ€": r.get("ì‹œê°„ëŒ€", ""),
            "ì‹œê°": r.get("_dt"),
            "ë¨¹ì€ ê²ƒ": raw,
            "ë§¤ì¹­": mapped if matched else raw,
            "íƒœê·¸": ", ".join(tags[:5]),
            "í•œì¤„ì„¤ëª…": " Â· ".join(benefits[:3])
        })
    out = pd.DataFrame(rows)
    if not out.empty:
        out = out.sort_values(["ì‹œê°„ëŒ€", "ì‹œê°"])
    return out

def score_tokens(free_text: str, df_food: pd.DataFrame, user_rules: Dict[str, Any]):
    tokens = split_free_text(free_text)
    rows = []
    score = {k: 0.0 for k in CORE_NUTRIENTS}
    for tok in tokens:
        name_raw, qty = parse_qty(tok)
        name_norm = (name_raw or "").strip()
        if not name_norm:
            continue
        if contains_any(name_norm, user_rules.get("avoid_keywords", [])):
            rows.append({
                "ì‹í’ˆ": name_raw, "ì •ê·œí™”": name_norm, "ìˆ˜ëŸ‰": qty,
                "ë“±ê¸‰": "Avoid", "ì‚¬ìœ ": "ê°œì¸ íšŒí”¼ë¦¬ìŠ¤íŠ¸", "íƒœê·¸(ì˜ì–‘)": []
            })
            continue
        mapped, matched = match_food(name_norm, df_food)
        tags, grade, flags = [], "Safe", ""
        if matched:
            rec = df_food[df_food["ì‹í’ˆ"] == mapped].iloc[0]
            grade = rec.get("ë“±ê¸‰", "Safe")
            tags = _to_tags(rec.get("íƒœê·¸(ì˜ì–‘)", []))
            if contains_any(name_norm, user_rules.get("allow_keywords", [])) and grade != "Avoid":
                grade = "Safe"
        else:
            grade, flags, tags = "Unknown", "DB ë¯¸ë“±ì¬", []
        for t in tags:
            if t in score:
                score[t] += float(qty or 1.0)
        rows.append({
            "ì‹í’ˆ": name_raw,
            "ì •ê·œí™”": mapped if matched else name_norm,
            "ìˆ˜ëŸ‰": qty,
            "ë“±ê¸‰": grade,
            "ì‚¬ìœ ": flags,
            "íƒœê·¸(ì˜ì–‘)": tags
        })
    items_df = pd.DataFrame(rows)
    return score, items_df

def gen_meal(df_food: pd.DataFrame, include_caution: bool,
             recent_items: List[str], favor_tags: List[str], rng: random.Random) -> Tuple[str, List[str], str]:
    df = df_food.copy()
    if not include_caution:
        df = df[df["ë“±ê¸‰"] != "Caution"]
    # prioritize by favor_tags
    pool = []
    for _, r in df.iterrows():
        tags = _to_tags(r.get("íƒœê·¸(ì˜ì–‘)", []))
        overlap = len(set(tags) & set(favor_tags or []))
        pool.append((overlap, r["ì‹í’ˆ"]))
    pool.sort(key=lambda x: (-x[0], x[1]))
    cand = [name for ov, name in pool if ov > 0] or df["ì‹í’ˆ"].tolist()
    # avoid recent repeats
    recent_items = set(recent_items or [])
    cand = [x for x in cand if x not in recent_items] or cand
    picks = rng.sample(cand, k=min(3, len(cand))) if len(cand) >= 3 else cand
    explain = ""
    if favor_tags:
        explain = f"ë¶€ì¡± íƒœê·¸ ë³´ì™„ ì¤‘ì‹¬: {', '.join(favor_tags)}"
    return "ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ", picks, explain

def make_intuitive_summary(scores: Dict[str, float], threshold: float = 1.0) -> str:
    filled_benefits, low_benefits = [], []
    ordered = list(ESSENTIALS) + [k for k in BENEFIT_MAP.keys() if k not in ESSENTIALS]
    for k in ordered:
        v = float(scores.get(k, 0) or 0)
        b = BENEFIT_MAP.get(k)
        if not b:
            continue
        if v >= threshold:
            if b not in filled_benefits:
                filled_benefits.append(b)
        else:
            if b not in low_benefits:
                low_benefits.append(b)
    left = " Â· ".join(filled_benefits[:3]) if filled_benefits else ""
    right = " Â· ".join(low_benefits[:3]) if low_benefits else ""
    if left and right:
        return f"ì˜¤ëŠ˜ í•œ ì¤„ ìš”ì•½: {left}ëŠ” ê½¤ ì±„ì›Œì¡Œê³ , {right}ëŠ” ë³´ì¶©ì´ í•„ìš”í•´ìš”."
    if left:
        return f"ì˜¤ëŠ˜ í•œ ì¤„ ìš”ì•½: {left}ëŠ” ì˜ ì±™ê²¨ì¡Œì–´ìš”."
    if right:
        return f"ì˜¤ëŠ˜ í•œ ì¤„ ìš”ì•½: {right} ë³´ì¶©ì´ í•„ìš”í•´ìš”."
    return "ì˜¤ëŠ˜ í•œ ì¤„ ìš”ì•½: ë¶„ì„í•  í•­ëª©ì´ ì—†ì–´ìš”."

# -----------------------------
# UI
# -----------------------------
st.set_page_config(page_title="ì¦‰ì„ ì‹ë‹¨ í‰ê°€", layout="wide")
st.title("âš¡ ì¦‰ì„ ì‹ë‹¨ í‰ê°€ (Instant Diet Evaluator)")

with st.expander("ë°ëª¨ í‘¸ë“œ DB ë³´ê¸° / CSV êµì²´ ì•ˆë‚´", expanded=False):
    st.write("í˜„ì¬ëŠ” ë°ëª¨ìš© DBë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì›í•˜ëŠ” CSVë¥¼ ì—…ë¡œë“œí•˜ì—¬ êµì²´í•  ìˆ˜ ìˆì–´ìš”.")
    st.dataframe(food_db, use_container_width=True, height=220)
    up = st.file_uploader("CSVë¡œ DB êµì²´ (ì‹í’ˆ, ë“±ê¸‰, íƒœê·¸(ì˜ì–‘) ì»¬ëŸ¼ í•„ìš”)", type=["csv"])
    if up is not None:
        try:
            df_new = pd.read_csv(up)
            df_new["íƒœê·¸(ì˜ì–‘)"] = df_new["íƒœê·¸(ì˜ì–‘)"].apply(_to_tags)
            food_db = df_new
            st.success("DB êµì²´ ì™„ë£Œ! ì•„ë˜ ë¶„ì„ì— ë°˜ì˜ë©ë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"CSV íŒŒì‹± ì‹¤íŒ¨: {e}")

with st.sidebar:
    st.header("ê°œì¸ ê·œì¹™")
    avoid = st.text_input("íšŒí”¼ í‚¤ì›Œë“œ(ì‰¼í‘œë¡œ êµ¬ë¶„)", value="")
    allow = st.text_input("í—ˆìš© í‚¤ì›Œë“œ(ì‰¼í‘œë¡œ êµ¬ë¶„)", value="")
    include_caution = st.checkbox("ê²½ê³„(Caution) í¬í•¨í•´ì„œ ì œì•ˆ", value=False)
    diversity_n = st.slider("ë‹¤ì–‘í™”(ìµœê·¼ NíšŒ ì¤‘ë³µ íšŒí”¼)", min_value=0, max_value=10, value=5, step=1)

user_rules = {
    "avoid_keywords": [x.strip() for x in avoid.split(",") if x.strip()],
    "allow_keywords": [x.strip() for x in allow.split(",") if x.strip()],
}

st.subheader("ì…ë ¥í•œ ì‹ë‹¨ì„ ì¦‰ì„ ë¶„ì„")
source_mode = st.radio("ë¶„ì„ ì†ŒìŠ¤", ["ì˜¤ëŠ˜ ê¸°ë¡ ì‚¬ìš©", "ì§ì ‘ ì…ë ¥"], horizontal=True, index=0)
sample = "ìŒ€ë°¥1, ëŒ€êµ¬êµ¬ì´1, ë¸Œë¡œì½œë¦¬1, ì˜¬ë¦¬ë¸Œìœ 0.5"
text_in = st.text_area("ì‹ë‹¨ í…ìŠ¤íŠ¸ (ì‰¼í‘œ ë˜ëŠ” ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„, ì˜ˆ: "+sample+")",
                       height=120, placeholder=sample,
                       disabled=(source_mode == "ì˜¤ëŠ˜ ê¸°ë¡ ì‚¬ìš©"))

if source_mode == "ì˜¤ëŠ˜ ê¸°ë¡ ì‚¬ìš©":
    _toks = tokens_from_today_log()
    if _toks:
        st.caption("ì˜¤ëŠ˜ ê¸°ë¡ì—ì„œ ë¶ˆëŸ¬ì˜¨ í•­ëª©: " + ", ".join(_toks))
        text_in = ", ".join(_toks)
    else:
        st.info("ì˜¤ëŠ˜ ë‚ ì§œì˜ ìŒì‹ ê¸°ë¡ì´ ì—†ì–´ìš”. ì§ì ‘ ì…ë ¥ìœ¼ë¡œ ì „í™˜í•´ ì£¼ì„¸ìš”.")

col_btn1, col_btn2 = st.columns([1,1])
with col_btn1:
    analyze = st.button("ë¶„ì„í•˜ê¸°", type="primary")
with col_btn2:
    clear = st.button("ì§€ìš°ê¸°")
if clear:
    text_in = ""
    st.experimental_rerun()

with st.expander("ğŸ“˜ ì˜ì–‘ì†Œ í•œëˆˆ ìš”ì•½ (ë¬´ì—‡ì— ì¢‹ì€ê°€ + ëŒ€í‘œ ì‹í’ˆ)", expanded=False):
    df_gloss = pd.DataFrame([
        {"ì˜ì–‘ì†Œ": k,
         "ë¬´ì—‡ì— ì¢‹ì€ê°€(ì‰½ê²Œ)": NUTRIENT_TIPS_LONG.get(k, NUTRIENT_TIPS.get(k, "")),
         "ëŒ€í‘œ ì‹í’ˆ": ", ".join(NUTRIENT_SOURCES.get(k, [])[:4])}
        for k in CORE_NUTRIENTS if k in NUTRIENT_TIPS or k in NUTRIENT_TIPS_LONG
    ])
    st.dataframe(df_gloss, use_container_width=True, height=360)

if analyze:
    try:
        scores, items_df = score_tokens(text_in, food_db, user_rules)

        st.markdown("### ğŸ± íŒŒì‹± ê²°ê³¼")
        if items_df.empty:
            st.info("í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤. ì‹ë‹¨ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        else:
            st.dataframe(items_df, use_container_width=True, height=280)

        st.markdown("### ğŸ§­ íƒœê·¸ ì ìˆ˜ + í•œì¤„ ì„¤ëª…")
        score_df = (
            pd.DataFrame([scores])
            .T.reset_index().rename(columns={"index":"ì˜ì–‘ì†Œ", 0:"ì ìˆ˜"})
            .sort_values("ì ìˆ˜", ascending=False)
        )
        score_df["í•œì¤„ì„¤ëª…"] = score_df["ì˜ì–‘ì†Œ"].map(lambda x: NUTRIENT_TIPS.get(x, ""))
        st.dataframe(score_df, use_container_width=True, height=320)

        # Missing essentials
        missing = [n for n in ESSENTIALS if scores.get(n, 0) < 1]
        if missing:
            tips_list = [f"- **{n}**: {NUTRIENT_TIPS.get(n, '')}" for n in missing]
            st.warning("ë¶€ì¡± íƒœê·¸:\n" + "\n".join(tips_list))
        else:
            st.success("í•µì‹¬ íƒœê·¸ ì¶©ì¡±! (ESSENTIALS ê¸°ì¤€)")

        # Intuitive one-liner
        try:
            st.info(make_intuitive_summary(scores, threshold=1.0))
        except Exception:
            pass

        # Per-meal breakdown (today-only)
        if source_mode == "ì˜¤ëŠ˜ ê¸°ë¡ ì‚¬ìš©":
            df_today = today_food_log_df()
            df_meal = per_meal_breakdown(food_db, df_today)
            if not df_meal.empty:
                st.markdown("### ğŸ½ï¸ ì‹ì‚¬ë³„ ë³´ì¶© í¬ì¸íŠ¸ (ì˜¤ëŠ˜)")
                for label in ["ì•„ì¹¨","ì ì‹¬","ì €ë…","ê°„ì‹"]:
                    sub = df_meal[df_meal["ì‹œê°„ëŒ€"] == label]
                    if sub.empty:
                        continue
                    st.markdown(f"**{label}**")
                    st.dataframe(sub[["ì‹œê°","ë¨¹ì€ ê²ƒ","ë§¤ì¹­","íƒœê·¸","í•œì¤„ì„¤ëª…"]]
                                 .rename(columns={"ì‹œê°":"ì‹œê°„"}),
                                 use_container_width=True,
                                 height=min(300, 60+28*len(sub)))
                    uniq = []
                    for s in sub["í•œì¤„ì„¤ëª…"].tolist():
                        for part in [x.strip() for x in s.split("Â·")]:
                            if part and part not in uniq:
                                uniq.append(part)
                    if uniq:
                        st.caption("ë³´ì¶©ëœ í¬ì¸íŠ¸: " + " Â· ".join(uniq[:6]))

        # Suggestions
        st.markdown("### ğŸ½ï¸ ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ (3ê°€ì§€)")
        # Diversity recent items (stub)
        recent_items = []
        try:
            if diversity_n > 0:
                r = ensure_log()
                r = r[r["type"] == "food"].copy()
                if not r.empty:
                    r["date"] = r["date"].astype(str)
                    r["time"] = r["time"].astype(str)
                    recent_df = r.sort_values(["date", "time"]).tail(diversity_n * 5)
                    recent_items = (recent_df["food_norm"].fillna("") + "|" + recent_df["item"].fillna("")).tolist()
                    recent_items = [x.split("|")[0] for x in recent_items if x]
        except Exception:
            recent_items = []

        rng = random.Random(hash(("quick-eval", text_in)) % (10**9))
        favor_tags = missing
        cols = st.columns(3)
        for idx in range(3):
            try:
                title, meal, explain = gen_meal(
                    food_db, include_caution,
                    recent_items=recent_items, favor_tags=favor_tags, rng=rng
                )
                with cols[idx]:
                    st.markdown(f"**{title} #{idx+1}**")
                    st.write(" / ".join(meal))
                    if favor_tags:
                        why = [f"Â· {t}: {NUTRIENT_TIPS.get(t, '')}" for t in favor_tags[:2]]
                        st.caption("ë³´ì™„ í¬ì¸íŠ¸:\n" + "\n".join(why))
                    elif explain:
                        st.caption(explain)
            except Exception as e:
                st.error(f"ì œì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
    except Exception as e:
        st.error(f"ë¶„ì„ ì‹¤íŒ¨: {e}")
