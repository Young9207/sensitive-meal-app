#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
diet_analyzer.py
ì…ë ¥(ì•„ì¹¨/ì˜¤ì „ ê°„ì‹/ì ì‹¬/ì˜¤í›„ ê°„ì‹/ì €ë…) â†’ ì‹í’ˆ ë§¤ì¹­ â†’ ì˜ì–‘ ë¶„ì„ â†’ ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ â†’ log.csv ì €ì¥
+ ë§¤ì¹­ ì•ˆëœ ì¬ë£ŒëŠ” food_dbì— ì‹ ê·œ ì‹í’ˆ í–‰ìœ¼ë¡œ ì¶”ê°€í•˜ì—¬ food_db_updated.csv ìƒì„±

- í•„ìš” íŒŒì¼: food_db.csv (ì‹í’ˆ, ë“±ê¸‰, íƒœê·¸(ì˜ì–‘), íƒœê·¸ë¦¬ìŠ¤íŠ¸), nutrient_dict.csv(ì˜ì–‘ì†Œ, í•œì¤„ì„¤ëª… ...)
- ì‹¤í–‰: streamlit run diet_analyzer.py
- íŒŒì‹± ê·œì¹™:
  * ì‰¼í‘œ(,) / ì¤„ë°”ê¿ˆìœ¼ë¡œ 1ì°¨ ë¶„ë¦¬ â†’ ê° í† í°ì„ '+' ë¡œ 2ì°¨ ë¶„ë¦¬
  * í† í° ë ìˆ«ìëŠ” ìˆ˜ëŸ‰ìœ¼ë¡œ í•´ì„ (ì˜ˆ: 'ìš°ë©”ë³´ì‹œ2' â†’ ì´ë¦„='ìš°ë©”ë³´ì‹œ', ìˆ˜ëŸ‰=2.0) ì—†ìœ¼ë©´ 1.0
"""

import re
import sys
import ast
import json
from collections import defaultdict
from typing import List, Dict, Tuple, Any
from datetime import datetime, date

import pandas as pd

try:
    import streamlit as st
except Exception:
    st = None  # allow import without Streamlit


# ====================== ì„¤ì • ======================
FOOD_DB_CSV = "food_db.csv"
NUTRIENT_DICT_CSV = "nutrient_dict.csv"
LOG_CSV = "log.csv"
FOOD_DB_UPDATED_CSV = "food_db_updated.csv"

SLOTS = ["ì•„ì¹¨", "ì˜¤ì „ ê°„ì‹", "ì ì‹¬", "ì˜¤í›„ ê°„ì‹", "ì €ë…"]


# ==================== ìœ í‹¸/ì „ì²˜ë¦¬ ====================
def _parse_tags_from_slash(cell) -> List[str]:
    if pd.isna(cell):
        return []
    return [t.strip() for t in str(cell).split('/') if t.strip()]


def _parse_taglist_cell(cell: Any) -> List[str]:
    """
    íƒœê·¸ë¦¬ìŠ¤íŠ¸ ì…€ì„ 'í•­ìƒ ë¦¬ìŠ¤íŠ¸'ë¡œ ë³€í™˜.
    í—ˆìš© í¬ë§·:
      - íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ ë¬¸ìì—´: "['ë‹¨ë°±ì§ˆ', 'ì €ì§€ë°©']"
      - JSON ë°°ì—´ ë¬¸ìì—´: '["ë‹¨ë°±ì§ˆ","ì €ì§€ë°©"]'
      - ìŠ¬ë˜ì‹œ êµ¬ë¶„: "ë‹¨ë°±ì§ˆ/ì €ì§€ë°©"
      - ì‹¤ì œ ë¦¬ìŠ¤íŠ¸: ['ë‹¨ë°±ì§ˆ', 'ì €ì§€ë°©']
      - ë¹ˆ ê°’/[] â†’ []
    """
    if isinstance(cell, list):
        return [str(x).strip() for x in cell if str(x).strip()]
    s = "" if cell is None or (isinstance(cell, float) and pd.isna(cell)) else str(cell).strip()
    if not s or s == "[]":
        return []
    # 1) literal_eval ì‹œë„ (íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ í‘œê¸°)
    try:
        v = ast.literal_eval(s)
        if isinstance(v, list):
            return [str(x).strip() for x in v if str(x).strip()]
    except Exception:
        pass
    # 2) JSON íŒŒì‹± ì‹œë„
    try:
        v = json.loads(s)
        if isinstance(v, list):
            return [str(x).strip() for x in v if str(x).strip()]
    except Exception:
        pass
    # 3) ìŠ¬ë˜ì‹œ/ì‰¼í‘œ êµ¬ë¶„ ë¬¸ìì—´ë¡œ ì²˜ë¦¬
    #    (ë”°ì˜´í‘œ/ëŒ€ê´„í˜¸ í”ì  ì œê±°)
    s2 = s.strip().strip("[]")
    parts = [p.strip().strip("'").strip('"') for p in re.split(r"[,/]", s2) if p.strip()]
    return [p for p in parts if p]


def _ensure_taglist(lst_from_row: Any, fallback_slash: Any) -> List[str]:
    """
    ìš°ì„  íƒœê·¸ë¦¬ìŠ¤íŠ¸ íŒŒì‹± â†’ ë¹„ì–´ìˆìœ¼ë©´ íƒœê·¸(ì˜ì–‘) ìŠ¬ë˜ì‹œ ë¶„ë¦¬ë¡œ ëŒ€ì²´
    """
    tags = _parse_taglist_cell(lst_from_row)
    if not tags:
        tags = _parse_tags_from_slash(fallback_slash)
    return tags


def load_food_db_simple(path: str = FOOD_DB_CSV) -> pd.DataFrame:
    df = pd.read_csv(path)
    # ë³´ì¥ ì»¬ëŸ¼
    for c in ["ì‹í’ˆ", "ë“±ê¸‰", "íƒœê·¸(ì˜ì–‘)"]:
        if c not in df.columns:
            df[c] = ""
    # íƒœê·¸ë¦¬ìŠ¤íŠ¸ ì •ê·œí™”
    if "íƒœê·¸ë¦¬ìŠ¤íŠ¸" not in df.columns:
        df["íƒœê·¸ë¦¬ìŠ¤íŠ¸"] = df["íƒœê·¸(ì˜ì–‘)"].apply(_parse_tags_from_slash)
    else:
        df["íƒœê·¸ë¦¬ìŠ¤íŠ¸"] = [
            _ensure_taglist(row.get("íƒœê·¸ë¦¬ìŠ¤íŠ¸", None), row.get("íƒœê·¸(ì˜ì–‘)", None))
            if isinstance(row, dict) else _ensure_taglist(df.loc[i, "íƒœê·¸ë¦¬ìŠ¤íŠ¸"], df.loc[i, "íƒœê·¸(ì˜ì–‘)"])
            for i, row in enumerate([{}]*len(df))
        ]
    # ìµœì†Œ ì»¬ëŸ¼ ë°˜í™˜
    return df[["ì‹í’ˆ", "ë“±ê¸‰", "íƒœê·¸(ì˜ì–‘)", "íƒœê·¸ë¦¬ìŠ¤íŠ¸"]]


def load_nutrient_dict_simple(path: str = NUTRIENT_DICT_CSV) -> Dict[str, str]:
    nd = pd.read_csv(path)
    for c in ["ì˜ì–‘ì†Œ", "í•œì¤„ì„¤ëª…"]:
        if c not in nd.columns:
            nd[c] = ""
    return {str(r["ì˜ì–‘ì†Œ"]).strip(): str(r["í•œì¤„ì„¤ëª…"]).strip() for _, r in nd.iterrows()}


_GRADE_ORDER = {"Avoid": 2, "Caution": 1, "Safe": 0}


def _worse_grade(g1: str, g2: str) -> str:
    return g1 if _GRADE_ORDER.get(g1, 0) >= _GRADE_ORDER.get(g2, 0) else g2


def _norm(s: str) -> str:
    return str(s or "").strip()


# ==================== íŒŒì„œ (ì½¤ë§ˆ/í”ŒëŸ¬ìŠ¤/ìˆ˜ëŸ‰) ====================
def split_items(text: str) -> List[str]:
    """ì‰¼í‘œ(,)ì™€ ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¨¼ì € ë¶„ë¦¬í•œ ë’¤, ê° í† í°ì„ '+'ë¡œ ì¶”ê°€ ë¶„ë¦¬"""
    if not text:
        return []
    first = [p.strip() for p in re.split(r"[,|\n|(|)]+", text) if p.strip()]
    final = []
    for part in first:
        final += [q.strip() for q in part.split('+') if q.strip()]
    return final


def parse_qty(token: str) -> Tuple[str, float]:
    """í† í° ëì˜ ìˆ«ìë¥¼ ìˆ˜ëŸ‰ìœ¼ë¡œ íŒŒì‹±. ì—†ìœ¼ë©´ 1.0"""
    m = re.search(r"(.*?)(\d+(?:\.\d+)?)\s*$", token)
    if m:
        name = m.group(1).strip()
        qty = float(m.group(2))
        return name, qty
    return token.strip(), 1.0


# ================== ë§¤ì¹­/ë¶„ì„/ì¶”ì²œ ë¡œì§ ==================
def match_item_to_foods(item: str, df_food: pd.DataFrame) -> pd.DataFrame:
    """item(ì˜ˆ: 'ì†Œê³ ê¸° ë¯¸ì—­êµ­')ì— ëŒ€í•´ food_dbì˜ ì‹í’ˆëª…ì´ í¬í•¨ë˜ë©´ ë§¤ì¹­.
       ë°˜ëŒ€ë°©í–¥(í•­ëª©ëª…ì´ ë” ì§§ê³  DBê°€ ê¸¸ ë•Œ)ë„ í—ˆìš©."""
    it = _norm(item)
    hits = df_food[
        df_food["ì‹í’ˆ"].apply(lambda x: _norm(x) in it or it in _norm(x))
    ].copy()
    hits = hits[hits["ì‹í’ˆ"].apply(lambda x: len(_norm(x)) >= 1)]
    return hits


def analyze_items_for_slot(input_text: str, slot: str, df_food: pd.DataFrame, nutrient_desc: Dict[str, str]):
    """ìŠ¬ë¡¯ ë‹¨ìœ„ ë¶„ì„ â†’ (items_df, nutrient_counts(dict), log_df, unmatched_names(list))"""
    raw_tokens = split_items(input_text)
    items = [parse_qty(tok) for tok in raw_tokens]  # [(name, qty), ...]

    per_item_rows = []
    nutrient_counts = defaultdict(float)
    log_rows = []
    unmatched_names = []

    for raw, qty in items:
        if not raw:
            continue
        matched = match_item_to_foods(raw, df_food)
        timestamp = datetime.now().isoformat(timespec="seconds")
        if matched.empty:
            per_item_rows.append({
                "ìŠ¬ë¡¯": slot, "ì…ë ¥í•­ëª©": raw, "ìˆ˜ëŸ‰": qty, "ë§¤ì¹­ì‹í’ˆ": "", "ë“±ê¸‰": "", "íƒœê·¸": ""
            })
            log_rows.append({
                "timestamp": timestamp,
                "date": date.today().isoformat(),
                "time": timestamp.split("T")[1],
                "slot": slot,
                "ì…ë ¥í•­ëª©": raw, "ìˆ˜ëŸ‰": qty, "ë§¤ì¹­ì‹í’ˆ": "", "ë“±ê¸‰": "", "íƒœê·¸": ""
            })
            unmatched_names.append(_norm(raw))
            continue

        agg_grade = "Safe"
        tag_union = []
        matched_names = []

        for _, r in matched.iterrows():
            name = _norm(r["ì‹í’ˆ"])
            grade = _norm(r["ë“±ê¸‰"]) or "Safe"
            tags = r.get("íƒœê·¸ë¦¬ìŠ¤íŠ¸", [])
            # ì•ˆì „ì¥ì¹˜: í˜¹ì‹œë¼ë„ ë¬¸ìì—´ì´ë©´ íŒŒì‹±
            if not isinstance(tags, list):
                tags = _parse_taglist_cell(tags)
            if not tags:
                tags = _parse_tags_from_slash(r.get("íƒœê·¸(ì˜ì–‘)", ""))

            agg_grade = _worse_grade(agg_grade, grade)
            matched_names.append(name)
            for t in tags:
                if t:
                    tag_union.append(t)
                    nutrient_counts[t] += float(qty or 1.0)  # ìˆ˜ëŸ‰ ë°˜ì˜

        per_item_rows.append({
            "ìŠ¬ë¡¯": slot,
            "ì…ë ¥í•­ëª©": raw,
            "ìˆ˜ëŸ‰": qty,
            "ë§¤ì¹­ì‹í’ˆ": ", ".join(dict.fromkeys(matched_names)),
            "ë“±ê¸‰": agg_grade,
            "íƒœê·¸": ", ".join(dict.fromkeys(tag_union))
        })
        log_rows.append({
            "timestamp": timestamp,
            "date": date.today().isoformat(),
            "time": timestamp.split("T")[1],
            "slot": slot,
            "ì…ë ¥í•­ëª©": raw,
            "ìˆ˜ëŸ‰": qty,
            "ë§¤ì¹­ì‹í’ˆ": ", ".join(dict.fromkeys(matched_names)),
            "ë“±ê¸‰": agg_grade,
            "íƒœê·¸": ", ".join(dict.fromkeys(tag_union))
        })

    return (
        pd.DataFrame(per_item_rows),
        dict(nutrient_counts),
        pd.DataFrame(log_rows),
        unmatched_names
    )


def summarize_nutrients(nutrient_counts: Dict[str, float], df_food: pd.DataFrame, nutrient_desc: Dict[str, str], threshold: int = 1) -> pd.DataFrame:
    all_tags = sorted({t for tlist in df_food["íƒœê·¸ë¦¬ìŠ¤íŠ¸"].apply(_parse_taglist_cell) for t in tlist})
    rows = []
    for tag in all_tags:
        cnt = float(nutrient_counts.get(tag, 0))
        rows.append({
            "ì˜ì–‘ì†Œ": tag,
            "ìˆ˜ëŸ‰í•©": cnt,
            "ìƒíƒœ": "ì¶©ì¡±" if cnt >= threshold else "ë¶€ì¡±",
            "í•œì¤„ì„¤ëª…": nutrient_desc.get(tag, "")
        })
    return pd.DataFrame(rows).sort_values(["ìƒíƒœ", "ìˆ˜ëŸ‰í•©", "ì˜ì–‘ì†Œ"], ascending=[True, False, True])


def recommend_next_meal(nutrient_counts: Dict[str, float], df_food: pd.DataFrame, nutrient_desc: Dict[str, str],
                        top_nutrients: int = 2, per_food: int = 4):
    """ë¶€ì¡± ì˜ì–‘ì†Œ ì¤‘ì‹¬ ì¶”ì²œ: Safe ì‹í’ˆ ìš°ì„  + ê°„ë‹¨ ì¡°í•©"""
    # íƒœê·¸ ìš°ì£¼ ìƒì„± ì‹œì—ë„ ì•ˆì •ì ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ íŒŒì‹±
    tag_universe = {tt for lst in df_food["íƒœê·¸ë¦¬ìŠ¤íŠ¸"].apply(_parse_taglist_cell) for tt in lst}
    tag_totals = {t: float(nutrient_counts.get(t, 0)) for t in tag_universe}
    lacking = [t for t, v in sorted(tag_totals.items(), key=lambda x: x[1]) if v < 1.0]
    lacking = lacking[:top_nutrients]

    suggestions = []
    for tag in lacking:
        pool = df_food[
            (df_food["ë“±ê¸‰"] == "Safe") &
            (df_food["íƒœê·¸ë¦¬ìŠ¤íŠ¸"].apply(lambda lst: tag in _parse_taglist_cell(lst)))
        ]
        foods = pool["ì‹í’ˆ"].dropna().astype(str).head(per_food).tolist()
        suggestions.append({
            "ë¶€ì¡±ì˜ì–‘ì†Œ": tag,
            "ì„¤ëª…": nutrient_desc.get(tag, ""),
            "ì¶”ì²œì‹í’ˆ": foods
        })

    combo = []
    for s in suggestions:
        for f in s["ì¶”ì²œì‹í’ˆ"]:
            if f not in combo:
                combo.append(f)
            if len(combo) >= 4:
                break
        if len(combo) >= 4:
            break

    return suggestions, combo


def append_unmatched_to_food_db(df_food: pd.DataFrame, unmatched_names: List[str]) -> pd.DataFrame:
    """ë§¤ì¹­ ì•ˆ ëœ ì‹í’ˆëª…ì„ ì‹í’ˆ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€(ë“±ê¸‰/íƒœê·¸ ë¹„ì›Œë‘ ). ì´ë¯¸ ì¡´ì¬í•˜ë©´ ê±´ë„ˆëœ€."""
    to_add = []
    existing = set(df_food["ì‹í’ˆ"].astype(str).str.strip().tolist())
    for name in unmatched_names:
        if not name:
            continue
        if name in existing:
            continue
        to_add.append({"ì‹í’ˆ": name, "ë“±ê¸‰": "", "íƒœê·¸(ì˜ì–‘)": "", "íƒœê·¸ë¦¬ìŠ¤íŠ¸": []})
        existing.add(name)
    if to_add:
        df_new = pd.concat([df_food, pd.DataFrame(to_add)], ignore_index=True)
    else:
        df_new = df_food.copy()
    return df_new


# ==================== Streamlit UI ====================
def main():
    try:
        import streamlit as st
    except Exception as e:
        print("This script requires Streamlit to run the UI. Install with: pip install streamlit")
        sys.exit(1)

    st.set_page_config(page_title="ìŠ¬ë¡¯ë³„ ì‹ë‹¨ ë¶„ì„ Â· ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ", page_icon="ğŸ¥—", layout="centered")
    st.title("ğŸ¥— ìŠ¬ë¡¯ë³„ ì‹ë‹¨ ë¶„ì„ Â· ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ")

    # íŒŒì¼ ë¡œë”©
    with st.expander("ë°ì´í„° íŒŒì¼ ê²½ë¡œ ì„¤ì •", expanded=False):
        food_path = st.text_input("food_db.csv ê²½ë¡œ", value=FOOD_DB_CSV)
        nutri_path = st.text_input("nutrient_dict.csv ê²½ë¡œ", value=NUTRIENT_DICT_CSV)
        load_btn = st.button("íŒŒì¼ ë‹¤ì‹œ ë¡œë“œ")

    if load_btn:
        st.experimental_rerun()

    # ì‹¤ì œ ë¡œë”©
    try:
        df_food = load_food_db_simple(food_path if 'food_path' in locals() else FOOD_DB_CSV)
        nutrient_desc = load_nutrient_dict_simple(nutri_path if 'nutri_path' in locals() else NUTRIENT_DICT_CSV)
    except Exception as e:
        st.error(f"CSV ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        st.stop()

    st.caption("ì…ë ¥ ì˜ˆ: ì†Œê³ ê¸° ë¯¸ì—­êµ­, ì°¹ìŒ€ë°¥, ì´ê°ê¹€ì¹˜1, ë¬´ìŒˆ, ìš°ë©”ë³´ì‹œ2, ë‹­ê³ ê¸°2, ë“¤ê¸°ë¦„, ì˜¬ë¦¬ë¸Œìœ  ì‚¬ê³¼+ì‹œë‚˜ëª¬ê°€ë£¨, ë¸”ë™ì»¤í”¼1")

    # ë‚ ì§œ + ìŠ¬ë¡¯ë³„ ì…ë ¥
    d = st.date_input("ê¸°ë¡ ë‚ ì§œ", value=date.today())
    inputs = {}
    cols = st.columns(1)
    with st.container():
        for slot in SLOTS:
            inputs[slot] = st.text_area(f"{slot}", height=70, placeholder=f"{slot}ì— ë¨¹ì€ ê²ƒ ì…ë ¥")

    c1, c2, c3 = st.columns([1,1,1])
    with c1:
        threshold = st.number_input("ì¶©ì¡± ì„ê³„(ìˆ˜ëŸ‰í•©)", min_value=1, max_value=5, value=1, step=1)
    with c2:
        export_flag = st.checkbox("log.csv ì €ì¥", value=True)
    with c3:
        analyze_clicked = st.button("ë¶„ì„í•˜ê¸°", type="primary")

    if analyze_clicked:
        try:
            all_items_df_list = []
            total_counts = defaultdict(float)
            all_logs = []
            all_unmatched = []

            for slot in SLOTS:
                items_df, counts, log_df, unmatched = analyze_items_for_slot(inputs.get(slot, ""), slot, df_food, nutrient_desc)
                if not items_df.empty:
                    items_df["ë‚ ì§œ"] = d.isoformat()
                if not log_df.empty:
                    log_df["date"] = d.isoformat()
                all_items_df_list.append(items_df)
                for k, v in counts.items():
                    total_counts[k] += float(v or 0)
                all_logs.append(log_df)
                all_unmatched += unmatched

            items_df_all = pd.concat(all_items_df_list, ignore_index=True) if all_items_df_list else pd.DataFrame(columns=["ìŠ¬ë¡¯","ì…ë ¥í•­ëª©","ìˆ˜ëŸ‰","ë§¤ì¹­ì‹í’ˆ","ë“±ê¸‰","íƒœê·¸","ë‚ ì§œ"])
            logs_all = pd.concat(all_logs, ignore_index=True) if all_logs else pd.DataFrame(columns=["timestamp","date","time","slot","ì…ë ¥í•­ëª©","ìˆ˜ëŸ‰","ë§¤ì¹­ì‹í’ˆ","ë“±ê¸‰","íƒœê·¸"])

            st.markdown("### ğŸ± ìŠ¬ë¡¯ë³„ ë§¤ì¹­ ê²°ê³¼")
            if items_df_all.empty:
                st.info("ë§¤ì¹­ëœ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.dataframe(items_df_all[["ë‚ ì§œ","ìŠ¬ë¡¯","ì…ë ¥í•­ëª©","ìˆ˜ëŸ‰","ë§¤ì¹­ì‹í’ˆ","ë“±ê¸‰","íƒœê·¸"]], use_container_width=True, height=min(420, 36 * (len(items_df_all) + 1)))

            st.markdown("### ğŸ§­ ì˜ì–‘ íƒœê·¸ ìš”ì•½ (ì¶©ì¡±/ë¶€ì¡± + í•œì¤„ì„¤ëª…)")
            nutri_df = summarize_nutrients(dict(total_counts), df_food, nutrient_desc, threshold=int(threshold))
            if nutri_df.empty:
                st.info("ì˜ì–‘ì†Œ ì‚¬ì „ ë˜ëŠ” íƒœê·¸ ì •ë³´ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            else:
                st.dataframe(nutri_df, use_container_width=True, height=min(420, 36 * (len(nutri_df) + 1)))

            st.markdown("### ğŸ½ ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ (ë¶€ì¡± ë³´ì™„ìš©)")
            recs, combo = recommend_next_meal(dict(total_counts), df_food, nutrient_desc, top_nutrients=2, per_food=4)
            if not recs:
                st.success("í•µì‹¬ ë¶€ì¡± ì˜ì–‘ì†Œê°€ ì—†ìŠµë‹ˆë‹¤. ê· í˜•ì´ ì˜ ë§ì•˜ì–´ìš”!")
            else:
                for r in recs:
                    foods_text = ", ".join(r["ì¶”ì²œì‹í’ˆ"]) if r["ì¶”ì²œì‹í’ˆ"] else "(ì¶”ì²œ ì‹í’ˆ ì—†ìŒ)"
                    st.write(f"- **{r['ë¶€ì¡±ì˜ì–‘ì†Œ']}**: {r['ì„¤ëª…']}")
                    st.caption(f"  ì¶”ì²œ ì‹í’ˆ: {foods_text}")
                if combo:
                    st.info("ê°„ë‹¨ ì¡°í•© ì œì•ˆ: " + " / ".join(combo[:4]))

            # ===== log.csv ì €ì¥ & ë‹¤ìš´ë¡œë“œ =====
            if export_flag and not logs_all.empty:
                try:
                    # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ append, ì—†ìœ¼ë©´ ìƒì„±
                    try:
                        prev = pd.read_csv(LOG_CSV)
                        merged = pd.concat([prev, logs_all], ignore_index=True)
                    except Exception:
                        merged = logs_all.copy()
                    merged.to_csv(LOG_CSV, index=False, encoding="utf-8-sig")
                    st.success(f"'{LOG_CSV}' ì €ì¥ ì™„ë£Œ")
                    with open(LOG_CSV, "rb") as f:
                        st.download_button("â¬‡ï¸ log.csv ë‹¤ìš´ë¡œë“œ", data=f.read(), file_name="log.csv", mime="text/csv")
                except Exception as ex:
                    st.error(f"log.csv ì €ì¥/ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {ex}")

            # ===== food_db ì—…ë°ì´íŠ¸ (ë¯¸ë§¤ì¹­ ì¬ë£Œ ì¶”ê°€) =====
            df_food_updated = append_unmatched_to_food_db(df_food, all_unmatched)
            try:
                # íƒœê·¸ë¦¬ìŠ¤íŠ¸ë¥¼ ì›ë˜ CSV í¬ë§·ìœ¼ë¡œ ë˜ëŒë¦¬ê¸° (ë³´ê¸°ìš© 'íƒœê·¸(ì˜ì–‘)'ë„ ë™ê¸°í™”)
                df_export = df_food_updated.copy()
                df_export["íƒœê·¸ë¦¬ìŠ¤íŠ¸"] = df_export["íƒœê·¸ë¦¬ìŠ¤íŠ¸"].apply(_parse_taglist_cell)
                df_export["íƒœê·¸(ì˜ì–‘)"] = df_export["íƒœê·¸ë¦¬ìŠ¤íŠ¸"].apply(lambda lst: "/".join(lst))
                df_export.to_csv(FOOD_DB_UPDATED_CSV, index=False, encoding="utf-8-sig")
                st.success("ë¯¸ë§¤ì¹­ ì¬ë£Œë¥¼ í¬í•¨í•œ 'food_db_updated.csv' ìƒì„± ì™„ë£Œ")
                with open(FOOD_DB_UPDATED_CSV, "rb") as f:
                    st.download_button("â¬‡ï¸ food_db_updated.csv ë‹¤ìš´ë¡œë“œ", data=f.read(), file_name="food_db_updated.csv", mime="text/csv")
            except Exception as ex:
                st.error(f"food_db ì—…ë°ì´íŠ¸/ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {ex}")

        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")


if __name__ == "__main__":
    if st is None:
        pass
    else:
        main()
