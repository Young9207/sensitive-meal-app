
import streamlit as st
import pandas as pd
import json, re, random, time, os, io, zipfile, math
from datetime import date, time as dtime, datetime

st.set_page_config(page_title="ë¯¼ê°ë„ ì‹ì‚¬ ë¡œê·¸ â€¢ í˜„ì‹¤í˜• ì œì•ˆ (ì•ˆì •í™”)", page_icon="ğŸ¥£", layout="wide")

def _force_rerun():
    try:
        st.rerun()
    except Exception:
        try:
            st.experimental_rerun()
        except Exception:
            pass



# === nutrient_dict.csv ì—°ë™ ===
NUTRIENT_TIPS = dict(globals().get("NUTRIENT_TIPS", {}))  # ì§§ì€ í•œì¤„ì„¤ëª…
NUTRIENT_TIPS_LONG = dict(globals().get("NUTRIENT_TIPS_LONG", {}))  # ìì„¸í•œì„¤ëª…
BENEFIT_MAP = dict(globals().get("BENEFIT_MAP", {}))  # íƒœê·¸ â†’ ë² ë„¤í• ë¼ë²¨/ì„¤ëª…
NUTRIENT_EXAMPLES = dict(globals().get("NUTRIENT_EXAMPLES", {}))  # ì˜ì–‘ì†Œ â†’ ëŒ€í‘œì‹í’ˆ ì˜ˆì‹œ ë¦¬ìŠ¤íŠ¸

def _load_nutrient_dict_csv(paths=("data/nutrient_dict.csv", "/mnt/data/nutrient_dict.csv")):
    """
    nutrient_dict.csv ìŠ¤í‚¤ë§ˆ:
      - ì˜ì–‘ì†Œ
      - í•œì¤„ì„¤ëª…
      - ìì„¸í•œì„¤ëª…
      - í˜œíƒë¼ë²¨(ìš”ì•½)
      - ëŒ€í‘œì‹í’ˆ(ì‰¼í‘œë¡œêµ¬ë¶„)
    """
    import pandas as _pd, os as _os
    for _p in paths:
        try:
            if _os.path.exists(_p):
                _df = _pd.read_csv(_p)
                for _, _r in _df.iterrows():
                    key = str(_r.get("ì˜ì–‘ì†Œ") or "").strip()
                    if not key:
                        continue
                    short = str(_r.get("í•œì¤„ì„¤ëª…") or "").strip()
                    long = str(_r.get("ìì„¸í•œì„¤ëª…") or "").strip()
                    label = str(_r.get("í˜œíƒë¼ë²¨(ìš”ì•½)") or "").strip()
                    examples = str(_r.get("ëŒ€í‘œì‹í’ˆ(ì‰¼í‘œë¡œêµ¬ë¶„)") or "").strip()

                    if short:
                        NUTRIENT_TIPS[key] = short
                    if long:
                        NUTRIENT_TIPS_LONG[key] = long
                    # BENEFIT_MAPì€ ê°€ëŠ¥í•œ ê°„ê²°í•œ ë¼ë²¨ì„ ìš°ì„ 
                    if label:
                        BENEFIT_MAP[key] = label
                    elif short:
                        BENEFIT_MAP[key] = short

                    if examples:
                        NUTRIENT_EXAMPLES[key] = [x.strip() for x in examples.split(",") if x.strip()]
                return True
        except Exception:
            pass
    return False

# ìµœì´ˆ ë¡œë“œ ì‹œë„
try:
    _nd_ok = _load_nutrient_dict_csv()
    if _nd_ok:
        if debug:
            st.caption("âœ… nutrient_dict.csv ë¡œë“œë¨")
    else:
        if debug:
            st.caption("â„¹ï¸ nutrient_dict.csvë¥¼ ì°¾ì§€ ëª»í–ˆê±°ë‚˜ ì»¬ëŸ¼ì´ ë§ì§€ ì•ŠìŠµë‹ˆë‹¤.")
except Exception as _e:
    if 'st' in globals() and debug:
        st.warning("nutrient_dict.csv ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
        st.exception(_e)
FOOD_DB_PATH = "food_db.csv"
LOG_PATH = "log.csv"
USER_RULES_PATH = "user_rules.json"

SLOTS = ["ì˜¤ì „","ì˜¤ì „ ê°„ì‹","ì ì‹¬","ì˜¤í›„","ì˜¤í›„ ê°„ì‹","ì €ë…"]
EVENT_TYPES = ["food","supplement","symptom"]  # ë‹¨ìˆœí™”

CORE_NUTRIENTS = ["Protein","LightProtein","ComplexCarb","HealthyFat","Fiber",
                  "A","B","C","D","E","K","Fe","Mg","Omega3","K_potassium",
                  "Iodine","Ca","Hydration","Circulation"]

ESSENTIALS = ["Protein","ComplexCarb","Fiber","B","C","A","K","Mg","Omega3","K_potassium","HealthyFat","D"]

SUGGEST_MODES = ["ê¸°ë³¸","ë‹¬ë‹¤êµ¬ë¦¬(ë‹¹ê¹€)","ì—­ë¥˜","ë”ë¶€ë£©","ë¶“ê¸°","í”¼ê³¤í•¨","ë³€ë¹„"]

SUPP_ALERT_KEYWORDS = {
    "íš¨ëª¨": ("Avoid","íš¨ëª¨ ë°˜ì‘ â†‘: ë¹µ/ë§¥ì£¼/ë§¥ì£¼íš¨ëª¨ ì£¼ì˜"),
    "ë§¥ì£¼íš¨ëª¨": ("Avoid","íš¨ëª¨ ë°˜ì‘ â†‘: ë§¥ì£¼íš¨ëª¨ íšŒí”¼ ê¶Œì¥"),
    "ì¹´ì œì¸": ("Avoid","ìœ ì œí’ˆÂ·ì¹´ì œì¸ ë°˜ì‘ â†‘"),
    "ìœ ì²­": ("Avoid","ìœ ì œí’ˆê³„ ë‹¨ë°±(ìœ ì²­) ì£¼ì˜"),
    "whey": ("Avoid","ìœ ì œí’ˆê³„ ë‹¨ë°±(ìœ ì²­) ì£¼ì˜"),
    "casein": ("Avoid","ìœ ì œí’ˆÂ·ì¹´ì œì¸ ë°˜ì‘ â†‘"),
    "gluten": ("Avoid","ê¸€ë£¨í… íšŒí”¼ ê¶Œì¥(ê¸€ë¦¬ì•„ë”˜ ë°˜ì‘ â†‘)"),
    "corn": ("Caution","ì˜¥ìˆ˜ìˆ˜ ê²½ê³„: í´ë Œíƒ€/ì½˜ê°€ê³µí’ˆ ì£¼ì˜"),
}

KEYWORD_MAP = {
    "ë¸”ë™ì»¤í”¼": "ì»¤í”¼", "ì»¤í”¼": "ì»¤í”¼",
    "ë…¹ì°¨": "ë…¹ì°¨", "í™ì°¨": "í™ì°¨",
    "ì‚¬ê³¼": "ì‚¬ê³¼", "ë°”ë‚˜ë‚˜": "ë°”ë‚˜ë‚˜", "í‚¤ìœ„": "í‚¤ìœ„",
    "ì½”ì½”ë„› ì¼€í”¼ì–´": "__VIRTUAL_COCONUT_KEFIR__", "ì¼€í”¼ì–´": "__VIRTUAL_COCONUT_KEFIR__",
    "ë¹„ê±´ì¹˜ì¦ˆ": "__VIRTUAL_VEGAN_CHEESE__", "ë² ê°„ì¹˜ì¦ˆ": "__VIRTUAL_VEGAN_CHEESE__",
    "í–„": "__VIRTUAL_HAM__", "ë¹µ": "__VIRTUAL_BREAD__",
    "í˜„ë¯¸": "__VIRTUAL_BROWN_RICE__", "í˜„ë¯¸ë°¥": "__VIRTUAL_BROWN_RICE__", "brown rice": "__VIRTUAL_BROWN_RICE__",
}

VIRTUAL_RULES = {
    "__VIRTUAL_BREAD__": {"grade":"Avoid","flags":"ê¸€ë£¨í…/íš¨ëª¨ ê°€ëŠ¥ì„±","tags":["ComplexCarb"]},
    "__VIRTUAL_HAM__": {"grade":"Caution","flags":"ê°€ê³µìœ¡/ì—¼ë¶„","tags":["Protein"]},
    "__VIRTUAL_VEGAN_CHEESE__": {"grade":"Caution","flags":"ê°€ê³µ ëŒ€ì²´ì‹","tags":["HealthyFat"]},
    "__VIRTUAL_COCONUT_KEFIR__": {"grade":"Caution","flags":"ë°œíš¨(í”„ë¡œë°”ì´ì˜¤í‹±)","tags":["Probiotic"]},
    "__VIRTUAL_BROWN_RICE__": {"grade":"Avoid","flags":"ê°œì¸ íšŒí”¼: í˜„ë¯¸","tags":["ComplexCarb"]},
}

# ---------- ìœ í‹¸
def safe_json_loads(x):
    if isinstance(x, list): return x
    if x is None: return []
    if isinstance(x, (int, float)): return []
    s = str(x).strip()
    if s == "": return []
    # normalize single quotes to double
    if s.startswith("[") and "'" in s and '"' not in s:
        s = s.replace("'", '"')
    try:
        return json.loads(s)
    except Exception:
        # fallback: split by comma
        return [t.strip() for t in s.split(",") if t.strip()]

def safe_isnan(x):
    try:
        return math.isnan(x)
    except Exception:
        return False

# ---------- ê°œì¸ ê·œì¹™
def load_user_rules():
    defaults = {"avoid_keywords": ["í˜„ë¯¸","í˜„ë¯¸ë°¥","brown rice"], "allow_keywords": ["ì»¤í”¼"]}
    if os.path.exists(USER_RULES_PATH):
        try:
            with open(USER_RULES_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
            for k,v in defaults.items():
                if k not in data: data[k]=v
            return data
        except Exception:
            return defaults
    return defaults

def save_user_rules(rules: dict):
    with open(USER_RULES_PATH, "w", encoding="utf-8") as f:
        json.dump(rules, f, ensure_ascii=False, indent=2)

# ---------- I/O
def ensure_log():
    cols = ["date","weekday","time","slot","type","item","qty","food_norm","grade","flags","tags","source"]
    if not os.path.exists(LOG_PATH):
        pd.DataFrame(columns=cols).to_csv(LOG_PATH, index=False)
    try:
        log = pd.read_csv(LOG_PATH)
    except Exception:
        log = pd.DataFrame(columns=cols)
    for c in cols:
        if c not in log.columns:
            log[c] = "" if c != "qty" else 0
    log = log[cols]
    # best-effort types
    log["qty"] = pd.to_numeric(log["qty"], errors="coerce").fillna(1.0)
    log.to_csv(LOG_PATH, index=False)
    return log

def load_food_db():
    base_cols = ["ì‹í’ˆ","ì‹í’ˆêµ°","ë“±ê¸‰","íƒœê·¸(ì˜ì–‘)"]
    if not os.path.exists(FOOD_DB_PATH):
        pd.DataFrame(columns=base_cols).to_csv(FOOD_DB_PATH, index=False)
    try:
        df = pd.read_csv(FOOD_DB_PATH, encoding="utf-8", engine="python")
    except Exception:
        df = pd.DataFrame(columns=base_cols)
    for c in base_cols:
        if c not in df.columns: df[c] = "" if c!="íƒœê·¸(ì˜ì–‘)" else "[]"
    # parse tags flexibly
    df["íƒœê·¸(ì˜ì–‘)"] = df["íƒœê·¸(ì˜ì–‘)"].apply(safe_json_loads)
    if "ë“±ê¸‰" not in df.columns: df["ë“±ê¸‰"] = "Safe"
    if "ì‹í’ˆêµ°" not in df.columns: df["ì‹í’ˆêµ°"] = ""
    return df[base_cols]

def save_food_db(df: pd.DataFrame):
    def to_jsonish(v):
        if isinstance(v, list): return json.dumps(v, ensure_ascii=False)
        return json.dumps(safe_json_loads(v), ensure_ascii=False)
    if "íƒœê·¸(ì˜ì–‘)" in df.columns:
        df["íƒœê·¸(ì˜ì–‘)"] = df["íƒœê·¸(ì˜ì–‘)"].apply(to_jsonish)
    df.to_csv(FOOD_DB_PATH, index=False, encoding="utf-8")

def weekday_ko(dt: date):
    return ["MON","TUE","WED","THU","FRI","SAT","SUN"][dt.weekday()]

def add_log_row(log, date_str, t_str, slot, typ, item, qty, food_norm, grade, flags, tags, source="manual"):
    try:
        weekday = weekday_ko(datetime.strptime(date_str,"%Y-%m-%d").date())
    except Exception:
        weekday = ""
    new = pd.DataFrame([{
        "date": date_str,
        "weekday": weekday,
        "time": t_str,
        "slot": slot,
        "type": typ,
        "item": item,
        "qty": float(qty) if pd.notnull(qty) else 1.0,
        "food_norm": food_norm,
        "grade": grade,
        "flags": flags,
        "tags": json.dumps(tags, ensure_ascii=False) if isinstance(tags, list) else (tags or ""),
        "source": source
    }])
    # align columns
    cols = ["date","weekday","time","slot","type","item","qty","food_norm","grade","flags","tags","source"]
    for c in cols:
        if c not in log.columns: log[c] = "" if c != "qty" else 0
    new = new[cols]
    out = pd.concat([log[cols], new], ignore_index=True)
    out.to_csv(LOG_PATH, index=False)
    return out

# --------- ììœ ì…ë ¥ íŒŒì‹±
def split_free_text(s: str):
    if not s: return []
    extra = []
    for m in re.findall(r"\((.*?)\)", s):
        extra += re.split(r"[,+/ ]+", m)
    s2 = re.sub(r"\(.*?\)", "", s)
    tokens = re.split(r"[+/,]", s2)
    tokens = [t.strip() for t in tokens if t.strip()]
    tokens += [t.strip() for t in extra if t.strip()]
    return tokens

def parse_qty(token: str):
    m = re.search(r"([0-9]+(\.[0-9]+)?)", token)
    qty = float(m.group(1)) if m else 1.0
    name = re.sub(r"[0-9]+(\.[0-9]+)?", "", token).strip()
    name = name.replace("ê°œ","").replace("P","").replace("p","").strip()
    return name, qty

def match_food(name: str, food_db: pd.DataFrame):
    orig = name
    if name in KEYWORD_MAP:
        mapped = KEYWORD_MAP[name]
        return mapped, True
    recs = food_db[food_db["ì‹í’ˆ"]==name]
    if not recs.empty:
        return name, True
    try:
        candidates = food_db[food_db["ì‹í’ˆ"].str.contains(name, case=False, na=False)]
        if not candidates.empty:
            return candidates.iloc[0]["ì‹í’ˆ"], True
    except Exception:
        pass
    candidates = food_db[food_db["ì‹í’ˆ"].apply(lambda x: name in str(x))]
    if not candidates.empty:
        return candidates.iloc[0]["ì‹í’ˆ"], True
    return orig, False

def contains_any(text, keywords):
    t = str(text)
    for k in keywords:
        if k and k in t:
            return True
    return False

def log_free_foods(log, when_date, when_time, slot, memo, food_db, user_rules):
    tokens = split_free_text(memo)
    saved = []
    for tok in tokens:
        name_raw, qty = parse_qty(tok)
        name_norm = name_raw.strip()
        if not name_norm: continue
        if contains_any(name_norm, user_rules.get("avoid_keywords", [])):
            log = add_log_row(log, when_date, when_time, slot, "food", name_raw, qty, "", "Avoid", "ê°œì¸ íšŒí”¼ë¦¬ìŠ¤íŠ¸", [""], source="memo(personal_avoid)")
            saved.append((name_raw, qty)); continue
        mapped, matched = match_food(name_norm, food_db)
        if matched:
            if mapped in VIRTUAL_RULES:
                vr = VIRTUAL_RULES[mapped]
                grade = vr["grade"]; flags = vr["flags"]; tags = vr["tags"]
                if contains_any(name_norm, user_rules.get("allow_keywords", [])):
                    grade = "Safe"; flags = "ê°œì¸ í—ˆìš©"
                log = add_log_row(log, when_date, when_time, slot, "food", name_raw, qty, name_norm, grade, flags, tags, source="memo")
            else:
                rec = food_db[food_db["ì‹í’ˆ"]==mapped].iloc[0]
                grade = rec.get("ë“±ê¸‰","Safe")
                tags = rec.get("íƒœê·¸(ì˜ì–‘)",[])
                if contains_any(name_norm, user_rules.get("allow_keywords", [])) and grade!="Avoid":
                    grade = "Safe"
                log = add_log_row(log, when_date, when_time, slot, "food", name_raw, qty, mapped, grade, "", tags, source="memo")
        else:
            grade, flags, tags = "", "", []
            if "ë¹µ" in name_norm: grade, flags = "Avoid", "ê¸€ë£¨í…/íš¨ëª¨ ê°€ëŠ¥ì„±"; tags=["ComplexCarb"]
            if "í–„" in name_norm: grade, flags = "Caution", "ê°€ê³µìœ¡/ì—¼ë¶„"; tags=["Protein"]
            if "ì¹˜ì¦ˆ" in name_norm and ("ë¹„ê±´" in name_norm or "ë² ê°„" in name_norm): grade, flags = "Caution","ê°€ê³µ ëŒ€ì²´ì‹"; tags=["HealthyFat"]
            if contains_any(name_norm, user_rules.get("allow_keywords", [])): grade="Safe"
            if contains_any(name_norm, user_rules.get("avoid_keywords", [])): grade="Avoid"; flags="ê°œì¸ íšŒí”¼ë¦¬ìŠ¤íŠ¸"
            log = add_log_row(log, when_date, when_time, slot, "food", name_raw, qty, "", grade, flags, tags, source="memo(unmatched)")
        saved.append((name_raw, qty))
    return log, saved

# ---------- ì ìˆ˜
def score_day(df_log, df_food, date_str):
    if df_log.empty: return {k:0.0 for k in CORE_NUTRIENTS}
    day = df_log[(df_log["date"]==date_str) & (df_log["type"]=="food")].copy()
    score = {k:0.0 for k in CORE_NUTRIENTS}
    for _, row in day.iterrows():
        fn = row.get("food_norm") or row.get("item")
        try: qty = float(row.get("qty") or 1.0)
        except Exception: qty = 1.0
        recs = df_food[df_food["ì‹í’ˆ"]==fn]
        if recs.empty:
            tags_val = row.get("tags")
            tags = safe_json_loads(tags_val)
            for t in tags:
                if t in score: score[t] += qty
            continue
        tags = recs.iloc[0]["íƒœê·¸(ì˜ì–‘)"]
        for t in tags:
            if t in score: score[t] += qty
    return score

# ---------- í˜„ì‹¤í˜• PANTRY

# --- Mode-specific anchor food pools (clearly different per condition) ---
MODE_ANCHORS = {
    "ê¸°ë³¸": {
        "protein": ["ë‹­ê°€ìŠ´ì‚´","ì—°ì–´","ëŒ€êµ¬","ë¼ì§€ê³ ê¸°"],
        "veg": ["ì–‘ë°°ì¶”","ë‹¹ê·¼","ë¸Œë¡œì½œë¦¬","ì• í˜¸ë°•","ì˜¤ì´","ì‹œê¸ˆì¹˜"],
        "carb": ["ìŒ€ë°¥","ê³ êµ¬ë§ˆ","ê°ì","í€´ë…¸ì•„","íƒ€í”¼ì˜¤ì¹´"],
        "fat": ["ì˜¬ë¦¬ë¸Œìœ ","ë“¤ê¸°ë¦„"],
        "fruit": ["ì‚¬ê³¼","ë°”ë‚˜ë‚˜","í‚¤ìœ„"]
    },
    "ë‹¬ë‹¤êµ¬ë¦¬(ë‹¹ê¹€)": {
        "protein": ["ë‹­ê°€ìŠ´ì‚´","ëŒ€êµ¬"],
        "veg": ["ì˜¤ì´","ì‹œê¸ˆì¹˜","ë‹¹ê·¼"],
        "carb": ["í€´ë…¸ì•„","íƒ€í”¼ì˜¤ì¹´"],  # ê¸‰ê²©í˜ˆë‹¹ í”¼í•˜ê¸°
        "fat": ["ì˜¬ë¦¬ë¸Œìœ ","ì•„ë³´ì¹´ë„(ê°€ëŠ¥ì‹œ)"],
        "fruit": ["ë¸”ë£¨ë² ë¦¬","ë”¸ê¸°","ì‚¬ê³¼"]
    },
    "ì—­ë¥˜": {
        "protein": ["ëŒ€êµ¬","ë‹­ê°€ìŠ´ì‚´"],
        "veg": ["ì˜¤ì´","ì• í˜¸ë°•","ì‹œê¸ˆì¹˜","ë‹¹ê·¼"],
        "carb": ["ìŒ€ì£½","ìŒ€ë°¥","ê°ì"],  # ë¶€ë“œëŸ¬ìš´ íƒ„ìˆ˜í™”ë¬¼
        "fat": ["ì˜¬ë¦¬ë¸Œìœ "],
        "fruit": ["ë°”ë‚˜ë‚˜","ì‚¬ê³¼"]
    },
    "ë”ë¶€ë£©": {
        "protein": ["ëŒ€êµ¬","ë‹­ê°€ìŠ´ì‚´"],
        "veg": ["ì˜¤ì´","ì• í˜¸ë°•","ì‹œê¸ˆì¹˜","ë‹¹ê·¼"],  # ì € FODMAP ìœ„ì£¼
        "carb": ["ìŒ€ë°¥","ê°ì","íƒ€í”¼ì˜¤ì¹´"],
        "fat": ["ì˜¬ë¦¬ë¸Œìœ "],
        "fruit": ["ë°”ë‚˜ë‚˜","í‚¤ìœ„"]
    },
    "ë¶“ê¸°": {
        "protein": ["ëŒ€êµ¬","ë‹­ê°€ìŠ´ì‚´","ì—°ì–´"],
        "veg": ["ì˜¤ì´","ì‹œê¸ˆì¹˜","ë‹¹ê·¼"],
        "carb": ["ê³ êµ¬ë§ˆ","ê°ì","í€´ë…¸ì•„"],
        "fat": ["ì˜¬ë¦¬ë¸Œìœ "],
        "fruit": ["ë°”ë‚˜ë‚˜","í‚¤ìœ„"]  # ì¹¼ë¥¨
    },
    "í”¼ê³¤í•¨": {
        "protein": ["ì†Œê³ ê¸°","ë¼ì§€ê³ ê¸°","ì—°ì–´"],  # ì² /ë¹„íƒ€ë¯¼B, ì˜¤ë©”ê°€3
        "veg": ["ì‹œê¸ˆì¹˜","ë¸Œë¡œì½œë¦¬","ì–‘ë°°ì¶”"],
        "carb": ["ê³ êµ¬ë§ˆ","í€´ë…¸ì•„","ìŒ€ë°¥"],
        "fat": ["ì˜¬ë¦¬ë¸Œìœ ","ë“¤ê¸°ë¦„"],
        "fruit": ["í‚¤ìœ„","ì˜¤ë Œì§€(í—ˆìš©ì‹œ)","ì‚¬ê³¼"]
    },
    "ë³€ë¹„": {
        "protein": ["ì—°ì–´","ë‹­ê°€ìŠ´ì‚´"],
        "veg": ["ì–‘ë°°ì¶”","ë¸Œë¡œì½œë¦¬","ì‹œê¸ˆì¹˜","ë‹¹ê·¼"],
        "carb": ["í€´ë…¸ì•„","ê³ êµ¬ë§ˆ","ìŒ€ë°¥"],
        "fat": ["ì˜¬ë¦¬ë¸Œìœ ","ë“¤ê¸°ë¦„","ì°¸ê¹¨"],
        "fruit": ["í‚¤ìœ„","ì‚¬ê³¼","ë°”ë‚˜ë‚˜"]
    }
}


# ---- Availability filters ----
RARE_BLACKLIST = {
    # ë„ˆë¬´ êµ¬í•˜ê¸° í˜ë“¤ê±°ë‚˜ ë¹„í˜„ì‹¤ì ì¸ ê²ƒë“¤
    "ë”°ê°œë¹„","ë©§ë¼ì§€","íƒ€ì¡°","ë§ê³ ê¸°","ì‚¬ìŠ´ê³ ê¸°","í™©ìƒˆì¹˜","ê³ ë‘¥","ìºë¹„ì–´",
    "í¼ì¸ ","ê°ì‹œì„œëŒ€ì† ì–´ë¥˜","ì°¸ë”","ë¨¹ë„ë¯¸ë¥˜","ë°”í‹€í”¼ì‹œ","í•´ë•","ë†ì–´",
}

COMMON_WHITELIST = {
    "protein": {"ë‹­ê°€ìŠ´ì‚´","ëŒ€êµ¬","ì—°ì–´","ë¼ì§€ê³ ê¸°","ì†Œê³ ê¸°","ê³„ë€(ì•Œë ˆë¥´ê¸° ì—†ì„ ë•Œ)","ê³ ë“±ì–´","ì°¸ì¹˜(ìº”)"},
    "veg": {"ì–‘ë°°ì¶”","ë‹¹ê·¼","ë¸Œë¡œì½œë¦¬","ì• í˜¸ë°•","ì˜¤ì´","ì‹œê¸ˆì¹˜","ìƒì¶”","ë¬´","ê°ì","ê³ êµ¬ë§ˆ","íŒŒí”„ë¦¬ì¹´","í† ë§ˆí† "},
    "carb": {"ìŒ€ë°¥","ìŒ€ì£½","ê³ êµ¬ë§ˆ","ê°ì","í€´ë…¸ì•„","íƒ€í”¼ì˜¤ì¹´","ì˜¥ìˆ˜ìˆ˜ì£½(ê°€ëŠ¥ì‹œ)"},
    "fat": {"ì˜¬ë¦¬ë¸Œìœ ","ë“¤ê¸°ë¦„","ì°¸ê¸°ë¦„","ì•„ë³´ì¹´ë„(ê°€ëŠ¥ì‹œ)","ì°¸ê¹¨"},
    "fruit": {"ì‚¬ê³¼","ë°”ë‚˜ë‚˜","í‚¤ìœ„","ë¸”ë£¨ë² ë¦¬","ë”¸ê¸°","ë°°"}
}

def apply_availability_filter(items, role_key, allow_rare=False):
    if allow_rare:
        # ê·¸ë˜ë„ í¬ê·€ ë¸”ë™ë¦¬ìŠ¤íŠ¸ëŠ” ì œì™¸
        return [x for x in items if x not in RARE_BLACKLIST]
    common = COMMON_WHITELIST.get(role_key, set())
    return [x for x in items if (x in common) and (x not in RARE_BLACKLIST)]

PANTRY = {
    "protein": ["ëŒ€êµ¬","ì—°ì–´","ë‹­ê°€ìŠ´ì‚´","ë¼ì§€ê³ ê¸°","ì†Œê³ ê¸°","ê³„ë€(ì•Œë ˆë¥´ê¸° ì—†ì„ ë•Œ)"],
    "veg": ["ì–‘ë°°ì¶”","ë‹¹ê·¼","ë¸Œë¡œì½œë¦¬","ì• í˜¸ë°•","ì˜¤ì´","ì‹œê¸ˆì¹˜","ìƒì¶”","ë¬´"],
    "carb": ["ìŒ€ë°¥","ê³ êµ¬ë§ˆ","ê°ì","íƒ€í”¼ì˜¤ì¹´","í€´ë…¸ì•„","ì˜¥ìˆ˜ìˆ˜ì£½(ê°€ëŠ¥ì‹œ)"],
    "fat": ["ì˜¬ë¦¬ë¸Œìœ ","ë“¤ê¸°ë¦„","ì•„ë³´ì¹´ë„(ê°€ëŠ¥ì‹œ)","ì°¸ê¹¨"],
    "fruit": ["ì‚¬ê³¼","ë°”ë‚˜ë‚˜","í‚¤ìœ„","ë¸”ë£¨ë² ë¦¬","ë”¸ê¸°"]
}

def build_baskets(df, include_caution=False):
    pool = df.copy()
    pool = pool[pool["ë“±ê¸‰"].isin(["Safe","Caution"])] if include_caution else pool[pool["ë“±ê¸‰"]=="Safe"]
    def pick(cond):
        try: return pool[cond]["ì‹í’ˆ"].tolist()
        except Exception: return []
    proteins = pick((pool["ì‹í’ˆêµ°"].isin(["ìƒì„ /í•´ì‚°ë¬¼","ìœ¡ë¥˜"])) & (pool["íƒœê·¸(ì˜ì–‘)"].apply(lambda t: "Protein" in t)))
    vegs = pick((pool["ì‹í’ˆêµ°"]=="ì±„ì†Œ") & (pool["íƒœê·¸(ì˜ì–‘)"].apply(lambda t: "Fiber" in t)))
    carbs = pick((pool["íƒœê·¸(ì˜ì–‘)"].apply(lambda t: "ComplexCarb" in t)))
    fats = pick((pool["íƒœê·¸(ì˜ì–‘)"].apply(lambda t: "HealthyFat" in t)))
    fruits = pick((pool["ì‹í’ˆêµ°"]=="ê³¼ì¼"))
    def ensure(lst, pantry_list):
        return list(dict.fromkeys(lst + [x for x in pantry_list if x not in lst]))
    return {
        "protein": ensure(proteins, PANTRY["protein"]),
        "veg": ensure(vegs, PANTRY["veg"]),
        "carb": ensure(carbs, PANTRY["carb"]),
        "fat": ensure(fats, PANTRY["fat"]),
        "fruit": ensure(fruits, PANTRY["fruit"]),
    }

def mode_filters(mode, user_rules):
    """Return (avoid_keywords, composition, favor_tags, human_avoid_note)"""
    avoid_keywords = []
    comp = {"protein":1,"veg":2,"carb":1,"fat":1,"fruit":0}
    favor = []
    note = []
    if mode=="ê¸°ë³¸":
        pass
    elif mode=="ë‹¬ë‹¤êµ¬ë¦¬(ë‹¹ê¹€)":
        note += ["ì •ì œë‹¹/ë””ì €íŠ¸ë¥˜ ì œì™¸"]
        comp = {"protein":1,"veg":1,"carb":0,"fat":1,"fruit":1}
        avoid_keywords += ["ì´ˆì½œë¦¿","ì¼€ì´í¬","í¬ë¦¼","íŠ€ê¹€"]
        favor += ["C","Fiber","K_potassium","HealthyFat"]
    elif mode=="ì—­ë¥˜":
        note += ["ì‹œíŠ¸ëŸ¬ìŠ¤/ë§¤ìš´ë¥˜/ê¸°ë¦„ì§„ ì¡°ë¦¬ë²• ì œì™¸"]
        avoid_keywords += ["í™ì°¨","ì´ˆì½œë¦¿","ì˜¤ë Œì§€","ë ˆëª¬","ë¼ì„","ë¶‰ì€ ê³ ì¶”","ìŠ¤íŒŒì´ì‹œ","íŠ€ê¹€","í¬ë¦¼","í† ë§ˆí†  ì†ŒìŠ¤"]
        if "ì»¤í”¼" not in user_rules.get("allow_keywords", []):
            avoid_keywords += ["ì»¤í”¼"]
        comp = {"protein":1,"veg":2,"carb":1,"fat":1}
        favor += ["LightProtein","Fiber"]
    elif mode=="ë”ë¶€ë£©":
        note += ["ê³ FODMAP ì¬ë£Œ(ì–‘íŒŒ/ë§ˆëŠ˜/ì½©ë¥˜/ì–‘ë°°ì¶”/ë¸Œë¡œì½œë¦¬) ì œì™¸"]
        avoid_keywords += ["ì–‘íŒŒ","ë§ˆëŠ˜","ê°•ë‚­ì½©","ë Œí‹¸","ì™„ë‘","ì½©","ë¸Œë¡œì½œë¦¬","ì–‘ë°°ì¶”","ë¶‰ì€ ì–‘ë°°ì¶”","ìš°ìœ ","ìš”ê±°íŠ¸","ì¹˜ì¦ˆ"]
        comp = {"protein":1,"veg":2,"carb":1,"fat":1}
        favor += ["LightProtein","Fiber"]
    elif mode=="ë¶“ê¸°":
        note += ["ì—¼ë¶„/ì ˆì„/ê°€ê³µìœ¡/ê°„ì¥ ë² ì´ìŠ¤ ì œì™¸"]
        avoid_keywords += ["ì ˆì„","ì “ê°ˆ","ìš°ë©”ë³´ì‹œ","ê¹€ì¹˜","í–„","ë² ì´ì»¨","ê°€ê³µ","ìŠ¤í†¡","ê°„ì¥"]
        comp = {"protein":1,"veg":2,"carb":1,"fat":1,"fruit":0}
        favor += ["K_potassium","Fiber","Hydration"]
    elif mode=="í”¼ê³¤í•¨":
        note += ["íŠ€ê¹€/í¬ë¦¼/ê³¼ìŒ ì œì™¸"]
        avoid_keywords += ["íŠ€ê¹€","í¬ë¦¼","ê³¼ìŒ"]
        comp = {"protein":1,"veg":2,"carb":1,"fat":1}
        favor += ["B","Fe","Mg","ComplexCarb"]
    elif mode=="ë³€ë¹„":
        note += ["ìœ ì œí’ˆ/íŠ€ê¹€/ì €ìˆ˜ë¶„ ì‹ë‹¨ ì œì™¸"]
        comp = {"protein":1,"veg":2,"carb":1,"fat":1,"fruit":1}
        avoid_keywords += ["ì¹˜ì¦ˆ","í¬ë¦¼","íŠ€ê¹€"]
        favor += ["Fiber","Hydration","K_potassium","HealthyFat"]
    return avoid_keywords, comp, favor, ", ".join(note)

def filter_keywords(items, kws):
    return [it for it in items if not any(k in it for k in kws)]

def filter_personal(items, user_rules):
    avoid = user_rules.get("avoid_keywords", [])
    return [it for it in items if not any(k in it for k in avoid)]

def pick_diverse(candidates, recent, need, rng):
    pool = [c for c in candidates if c not in recent]
    if len(pool) >= need:
        rng.shuffle(pool); return pool[:need]
    left = need - len(pool)
    rng.shuffle(pool)
    repeat_pool = [c for c in candidates if c in recent]
    rng.shuffle(repeat_pool)
    return pool + repeat_pool[:left]

def gen_meal(df_food, include_caution, mode, recent_items, favor_tags, rng, user_rules, allow_rare=False):
    """Return (title, items, explain)
    - items are built from MODE_ANCHORS[mode] prioritized, then general baskets
    - explain shows what was avoided (mode note and personal rules)
    """
    baskets = build_baskets(df_food, include_caution=include_caution)
    avoid_kws, comp, favor_extra, mode_note = mode_filters(mode, user_rules)
    anchors = MODE_ANCHORS.get(mode, {})
    for k in list(baskets.keys()):
        baskets[k] = filter_keywords(baskets[k], avoid_kws)
        baskets[k] = filter_personal(baskets[k], user_rules)
    local_favor = list(dict.fromkeys(list(favor_tags) + list(favor_extra)))
    def favor(lst):
        if not lst: return lst
        scored = []
        for name in lst:
            recs = df_food[df_food["ì‹í’ˆ"]==name]
            tags = recs.iloc[0]["íƒœê·¸(ì˜ì–‘)"] if not recs.empty else []
            score = sum(1 for t in local_favor if t in tags)
            scored.append((score, name))
        scored.sort(key=lambda x: (-x[0], random.random()))
        return [n for _, n in scored]
    for key in baskets.keys():
        # 1) ìš°ì„  ì•µì»¤ ë³‘í•©
        if key in anchors:
            front = [x for x in anchors[key] if x in baskets[key]]
            rest = [x for x in baskets[key] if x not in front]
            merged = favor(front) + favor(rest)
        else:
            merged = favor(baskets[key])
        # 2) ê°€ìš©ì„± í•„í„° ì ìš©
        baskets[key] = apply_availability_filter(merged, key, allow_rare=allow_rare)
    meal = []
    for key, need in comp.items():
        chosen = pick_diverse(baskets[key], recent_items, need, rng)
        meal += chosen
    title = build_meal_title(mode, meal)
    explain = mode_note
    # Personal avoids surfaced
    pa = user_rules.get("avoid_keywords", [])
    if pa:
        explain = (explain + " | ê°œì¸ íšŒí”¼: " + ", ".join(pa)).strip(' |')
    return title, meal, explain

def build_meal_title(mode, items):
    if not items: return f"{mode} ì œì•ˆ"
    proteins = [x for x in items if any(k in x for k in ["ëŒ€êµ¬","ì—°ì–´","ë‹­","ì†Œê³ ê¸°","ë¼ì§€ê³ ê¸°","ê³„ë€"])]
    main = proteins[0] if proteins else items[0]
    return f"{mode} â€¢ {main}"

def supplement_flag(text):
    if not text: return ("","")
    t = text.lower()
    for key, (grade,msg) in SUPP_ALERT_KEYWORDS.items():
        if key in t: return (grade, msg)
    return ("","")

# ---------- ì•± ----------
food_db = load_food_db()
log = ensure_log()
user_rules = load_user_rules()

st.title("ğŸ¥£ ë¯¼ê°ë„ ì‹ì‚¬ ë¡œê·¸ â€¢ í˜„ì‹¤í˜• ì œì•ˆ (ì•ˆì •í™”)")

with st.sidebar:
    st.subheader("ê°œì¸ ê·œì¹™")
    allow_rare = st.checkbox("í¬ê·€ ì‹ì¬ë£Œ í¬í•¨", value=False, help="ì²´í¬ í•´ì œ ì‹œ êµ¬í•˜ê¸° ì‰¬ìš´ ì¬ë£Œë§Œ ì œì•ˆí•©ë‹ˆë‹¤.")
    avoid_str = st.text_input("íšŒí”¼ í‚¤ì›Œë“œ(ì‰¼í‘œ)", value=", ".join(user_rules.get("avoid_keywords", [])))
    allow_str = st.text_input("í—ˆìš© í‚¤ì›Œë“œ(ì‰¼í‘œ)", value=", ".join(user_rules.get("allow_keywords", [])))
    debug = st.checkbox("ë””ë²„ê·¸ ì •ë³´ í‘œì‹œ", value=False)
    if st.button("ê·œì¹™ ì €ì¥"):
        user_rules["avoid_keywords"] = [s.strip() for s in avoid_str.split(",") if s.strip()]
        user_rules["allow_keywords"] = [s.strip() for s in allow_str.split(",") if s.strip()]
        save_user_rules(user_rules)
        st.success("ê·œì¹™ ì €ì¥ë¨. ì œì•ˆ/íŒŒì„œ ì¦‰ì‹œ ë°˜ì˜.")

tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“ ê¸°ë¡","ğŸ“Š ìš”ì•½/ì œì•ˆ","ğŸ“¤ ë‚´ë³´ë‚´ê¸°","ğŸ›  ê´€ë¦¬(í¸ì§‘/ì‚­ì œ)"])

with tab1:
    st.subheader("ì˜¤ëŠ˜ ê¸°ë¡")
    d = st.date_input("ë‚ ì§œ", value=date.today())
    slot = st.selectbox("ìŠ¬ë¡¯(ì‹œê°„ëŒ€)", SLOTS, index=2)
    t_input = st.time_input("ì‹œê°", value=dtime(hour=12, minute=0))
    typ = st.radio("ê¸°ë¡ ì¢…ë¥˜", EVENT_TYPES, horizontal=True, index=0)
    if typ=="food":
        memo = st.text_area("ë©”ëª¨ í•œ ì¤„ë¡œ ì…ë ¥", height=100, placeholder="ì˜ˆ: ìŒ€ë°¥1, ëŒ€êµ¬êµ¬ì´1, ì–‘ë°°ì¶”ì°œ1, ë‹¹ê·¼1, ì˜¬ë¦¬ë¸Œìœ 0.5")
        if st.button("â• íŒŒì‹±í•´ì„œ ëª¨ë‘ ì €ì¥", type="primary"):
            try:
                ds = d.strftime("%Y-%m-%d"); ts = t_input.strftime("%H:%M")
                log, saved = log_free_foods(log, ds, ts, slot, memo, food_db, user_rules)
                st.success(f"{len(saved)}ê°œ í•­ëª© ì €ì¥: " + ", ".join([f"{n}Ã—{q}" for n,q in saved])); _force_rerun()
            except Exception as e:
                st.error("íŒŒì‹±/ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                if debug: st.exception(e)
    elif typ=="supplement":
        text = st.text_area("ë³´ì¶©ì œ/ì•½/ìŒë£Œ", height=80)
        g, flags = supplement_flag(text)
        if g=="Avoid": st.error(flags or "ì£¼ì˜ ë³´ì¶©ì œ")
        elif g=="Caution": st.warning(flags or "ê²½ê³„ ë³´ì¶©ì œ")
        if st.button("â• ì €ì¥", type="primary"):
            try:
                ds = d.strftime("%Y-%m-%d"); ts = t_input.strftime("%H:%M")
                log = add_log_row(log, ds, ts, slot, "supplement", text, 1.0, "", g, flags, [], source="manual")
                st.success("ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."); _force_rerun()
            except Exception as e:
                st.error("ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                if debug: st.exception(e)
    else:
        text = st.text_area("ì¦ìƒ(ì˜ˆ: ì†ì“°ë¦¼2, ë”ë¶€ë£©1)", height=80)
        if st.button("â• ì €ì¥", type="primary"):
            try:
                ds = d.strftime("%Y-%m-%d"); ts = t_input.strftime("%H:%M")
                log = add_log_row(log, ds, ts, slot, "symptom", text, 1.0, "", "", "", [], source="manual")
                st.success("ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤."); _force_rerun()
            except Exception as e:
                st.error("ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                if debug: st.exception(e)
    st.markdown("---")
    st.caption("ìµœê·¼ ê¸°ë¡")
    try:
        fresh = ensure_log()
        tmp = fresh.copy()
        tmp["date"] = tmp["date"].astype(str)
        tmp["time"] = tmp["time"].astype(str)
        st.dataframe(tmp.sort_values(['date','time']).tail(20), use_container_width=True, height=240)
    except Exception as e:
        st.error("ìµœê·¼ ê¸°ë¡ í‘œì‹œ ì¤‘ ì˜¤ë¥˜")
        if debug: st.exception(e)

with tab2:
    st.subheader("ìš”ì•½ & ë‹¤ìŒ ë¼ë‹ˆ ì œì•ˆ(3ê°€ì§€)")

    # === ì˜ì–‘ ì„¤ëª…/ë³´ê°• ì œì•ˆ ===
    with st.expander("ì˜ì–‘ ì„¤ëª…ê³¼ ë³´ê°• ì•„ì´ë””ì–´ ë³´ê¸°", expanded=False):
        try:
            low_keys = [k for k, v in sorted(scores.items(), key=lambda x: x[1]) if v < 1.0]
            if not low_keys:
                st.markdown("- ì˜¤ëŠ˜ì€ í•µì‹¬ ì˜ì–‘ì†Œ ì»¤ë²„ê°€ ì „ë°˜ì ìœ¼ë¡œ **ì–‘í˜¸**í•©ë‹ˆë‹¤.")
            else:
                st.markdown("ë¶€ì¡±/ë¯¸ë‹¬ ì˜ì–‘ì†Œì™€ ê°„ë‹¨ ì„¤ëª…:")
                rows = []
                for k in low_keys:
                    tip = _lookup_tip(k)
                    rows.append(f"- **{_friendly_label(k)}**: {tip}")
                st.markdown("\\n".join(rows))

                # ì˜ˆì‹œ ì‹í’ˆ ì¶”ì²œ (food_dbì˜ íƒœê·¸ ê¸°ë°˜)
                try:
                    eg_lines = []
                    # íƒœê·¸ì— k ë˜ëŠ” í•´ë‹¹ í•œê¸€ëª…ì´ í¬í•¨ëœ ì‹í’ˆ ì˜ˆì‹œ ì¶”ì¶œ
                    for k in low_keys[:5]:
                        tag_candidates = {k, _nut_ko(k), _nut_en(k)}
                        cand = []
                        for _, r in food_db.iterrows():
                            tags = r.get("íƒœê·¸(ì˜ì–‘)", [])
                            if not isinstance(tags, list):
                                continue
                            tset = set(map(str, tags))
                            if tset & tag_candidates:
                                cand.append(str(r.get("ì‹í’ˆ")))
                            if len(cand) >= 6:
                                break
                        if cand:
                            eg_lines.append(f"  â€¢ **{_friendly_label(k)}** ì˜ˆì‹œ: " + ", ".join(sorted(set(cand))[:6]))
                    if eg_lines:
                        st.markdown("ë³´ê°•ì— ë„ì›€ì´ ë˜ëŠ” ì‹í’ˆ ì˜ˆì‹œ:")
                        st.markdown("\\n".join(eg_lines))
                except Exception as _e:
                    pass
        except Exception as e:
            st.info("ì„¤ëª… ìƒì„± ì¤‘ ë¬¸ì œê°€ ìˆì—ˆìŠµë‹ˆë‹¤.")
            if debug: st.exception(e)

    dsum = st.date_input("ê¸°ì¤€ ë‚ ì§œ", value=date.today(), key="sumdate_2")
    date_str = dsum.strftime("%Y-%m-%d")
    try:
        scores = score_day(log, food_db, date_str)
        score_df = pd.DataFrame([scores]).T.reset_index()
        score_df.columns = ["ì˜ì–‘ì†Œ","ì ìˆ˜"]
        st.dataframe(score_df, use_container_width=True, height=260)
    except Exception as e:
        st.error("ì ìˆ˜ ê³„ì‚° ì¤‘ ì˜¤ë¥˜")
        if debug: st.exception(e)

    favor_tags = [n for n in ESSENTIALS if scores.get(n,0)<1] if 'scores' in locals() else []
    include_caution = st.checkbox("ê²½ê³„(Caution) í¬í•¨", value=False)
    diversity_n = st.slider("ë‹¤ì–‘í™”(ìµœê·¼ NíšŒ ì¤‘ë³µ íšŒí”¼)", min_value=0, max_value=10, value=5, step=1)
    recent_items = []
    try:
        if diversity_n>0:
            r = ensure_log()
            r = r[r["type"]=="food"].copy()
            r["date"] = r["date"].astype(str)
            r["time"] = r["time"].astype(str)
            recent_df = r.sort_values(["date","time"]).tail(diversity_n*5)
            recent_items = (recent_df["food_norm"].fillna("") + "|" + recent_df["item"].fillna("")).tolist()
            recent_items = [x.split("|")[0] for x in recent_items if x]
    except Exception as e:
        if debug: st.exception(e)

    mode = st.selectbox("ì œì•ˆ ëª¨ë“œ", SUGGEST_MODES, index=0)
    if "suggest_seed" not in st.session_state:
        st.session_state.suggest_seed = 0
    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
        st.session_state.suggest_seed += 1
    rng = random.Random(hash((mode, st.session_state.suggest_seed)) % (10**9))

    cols = st.columns(3)
    for idx in range(3):
        try:
            title, meal, explain = gen_meal(
                food_db,
                include_caution,
                mode,
                recent_items,
                favor_tags,
                rng,
                user_rules,
                allow_rare=allow_rare
            )
            with cols[idx]:
                st.markdown(f"**{title}**")
                if meal:
                    st.write("â€¢ " + " / ".join(meal))
                    if favor_tags: st.caption("ë¶€ì¡± ë³´ì™„ ìš°ì„  íƒœê·¸: " + ", ".join(favor_tags))
                    if explain:
                        st.caption("ëª¨ë“œ ì ìš©: " + explain)
                    if st.button(f"ğŸ’¾ ì´ ì¡°í•© ì €ì¥ (ì ì‹¬) â€” {idx+1}"):
                        now = datetime.now().strftime("%H:%M")
                        for token in meal:
                            grade=""; tags=[]
                            rec = food_db[food_db["ì‹í’ˆ"]==token]
                            if not rec.empty:
                                grade = rec.iloc[0].get("ë“±ê¸‰","Safe"); tags = rec.iloc[0].get("íƒœê·¸(ì˜ì–‘)",[])
                            add_log_row(log, date_str, now, "ì ì‹¬", "food", token, 1.0, token, grade, "", tags, source="suggested")
                        st.success("ì €ì¥ ì™„ë£Œ! ê¸°ë¡ íƒ­ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
                else:
                    st.info("ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì‹í’ˆ í’€ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ê°œì¸ íšŒí”¼ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” FoodDBë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        except Exception as e:
            with cols[idx]:
                st.error("ì œì•ˆ ìƒì„± ì¤‘ ì˜¤ë¥˜")
                if debug: st.exception(e)
                
with tab3:
    st.subheader("ë‚´ë³´ë‚´ê¸°/ë°±ì—…")
    try:
        # ê°œë³„ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (ì¡´ì¬í•  ë•Œë§Œ ë…¸ì¶œ)
        if os.path.exists(LOG_PATH):
            with open(LOG_PATH, "rb") as f:
                st.download_button(
                    "â¬‡ï¸ log.csv ë‹¤ìš´ë¡œë“œ",
                    data=f.read(),
                    file_name="log.csv",
                    mime="text/csv"
                )
        if os.path.exists(FOOD_DB_PATH):
            with open(FOOD_DB_PATH, "rb") as f:
                st.download_button(
                    "â¬‡ï¸ food_db.csv ë‹¤ìš´ë¡œë“œ",
                    data=f.read(),
                    file_name="food_db.csv",
                    mime="text/csv"
                )
        if os.path.exists(USER_RULES_PATH):
            with open(USER_RULES_PATH, "rb") as f:
                st.download_button(
                    "â¬‡ï¸ user_rules.json ë‹¤ìš´ë¡œë“œ",
                    data=f.read(),
                    file_name="user_rules.json",
                    mime="application/json"
                )

        # ZIP ë°±ì—… ë§Œë“¤ê¸°
        if st.button("ğŸ“¦ ì „ì²´ ë°±ì—… ZIP ë§Œë“¤ê¸°"):
            mem_zip = io.BytesIO()
            with zipfile.ZipFile(mem_zip, mode="w", compression=zipfile.ZIP_DEFLATED) as zf:
                for p in [LOG_PATH, FOOD_DB_PATH, USER_RULES_PATH]:
                    if p and os.path.exists(p):
                        # íŒŒì¼ì„ ë©”ëª¨ë¦¬ì— ì½ì§€ ì•Šê³  ë°”ë¡œ ì¶”ê°€
                        zf.write(p, arcname=os.path.basename(p))
            mem_zip.seek(0)
            st.download_button(
                "â¬‡ï¸ ë°±ì—… ZIP ë‹¤ìš´ë¡œë“œ",
                data=mem_zip,
                file_name="meal_app_backup.zip",
                mime="application/zip"
            )
    except Exception as e:
        st.error("ë‚´ë³´ë‚´ê¸° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        if debug:
            st.exception(e)

with tab4:
    st.subheader("ğŸ›  ê¸°ë¡/DB í¸ì§‘ & ë³µêµ¬")
    # --- ë¡œê·¸ í¸ì§‘ ---
    min_d = st.date_input("ì‹œì‘ì¼", value=date.today())
    max_d = st.date_input("ì¢…ë£Œì¼", value=date.today())
    try:
        df = pd.read_csv(LOG_PATH)
    except Exception:
        df = pd.DataFrame(columns=["date","weekday","time","slot","type","item","qty","food_norm","grade","flags","tags","source"])
        df.to_csv(LOG_PATH, index=False)
    if not df.empty:
        try:
            # normalize types for view only
            dfv = df.copy()
            dfv["date"] = pd.to_datetime(dfv["date"], errors="coerce").dt.date
            mask = (dfv["date"]>=min_d) & (dfv["date"]<=max_d)
            view = dfv[mask].copy()
            view = view.reset_index()  # keep original index
            st.caption("ì…€ ìˆ˜ì • í›„ 'ë³€ê²½ ì €ì¥'ì„ ëˆŒëŸ¬ ë°˜ì˜í•˜ì„¸ìš”. í–‰ ì¶”ê°€ëŠ” ì•„ë˜ ê·œì¹™ìœ¼ë¡œ ì €ì¥ë˜ë©°, ì‚­ì œëŠ” ì˜¤ë¥¸ìª½ ê¸°ëŠ¥ ì‚¬ìš©.")
            edited = st.data_editor(view.drop(columns=["index"]), num_rows="dynamic", use_container_width=True, key="edit_log")

            c1,c2,c3 = st.columns(3)
            with c1:
                if st.button("ë³€ê²½ ì €ì¥"):
                    try:
                        # 1) update existing rows (by original index)
                        min_len = min(len(edited), len(view))
                        for col in edited.columns:
                            df.loc[view.iloc[:min_len]["index"], col] = edited.iloc[:min_len][col].values
                        # 2) append new rows if any
                        if len(edited) > len(view):
                            extra = edited.iloc[len(view):].copy()
                            # ensure required columns exist
                            for c in df.columns:
                                if c not in extra.columns:
                                    extra[c] = "" if c != "qty" else 1.0
                            # convert date to str
                            if "date" in extra.columns:
                                extra["date"] = extra["date"].astype(str)
                            df = pd.concat([df, extra[df.columns]], ignore_index=True)
                        # 3) finalize types & save
                        df["qty"] = pd.to_numeric(df["qty"], errors="coerce").fillna(1.0)
                        df["date"] = df["date"].astype(str)
                        df.to_csv(LOG_PATH, index=False)
                        st.success("ë¡œê·¸ ì €ì¥ë¨."); _force_rerun()
                    except Exception as e:
                        st.error("ë¡œê·¸ ì €ì¥ ì¤‘ ì˜¤ë¥˜")
                        if debug: st.exception(e)
            with c2:
                del_idx = st.multiselect("ì‚­ì œí•  í–‰(ë·° ì¸ë±ìŠ¤)", options=list(range(len(view))))
                if st.button("ì„ íƒ í–‰ ì‚­ì œ"):
                    try:
                        to_drop = view.iloc[del_idx]["index"].tolist()
                        df = df.drop(index=to_drop).reset_index(drop=True)
                        df.to_csv(LOG_PATH, index=False)
                        st.success(f"{len(del_idx)}ê°œ í–‰ ì‚­ì œë¨."); _force_rerun()
                    except Exception as e:
                        st.error("í–‰ ì‚­ì œ ì¤‘ ì˜¤ë¥˜")
                        if debug: st.exception(e)
            with c3:
                if st.button("íŒŒì¼ ë³µêµ¬(ê¹¨ì¡Œì„ ë•Œ ì´ˆê¸°í™”)"):
                    try:
                        backup_name = f"log_backup_{int(time.time())}.csv"
                        if os.path.exists(LOG_PATH):
                            os.replace(LOG_PATH, backup_name)
                        pd.DataFrame(columns=["date","weekday","time","slot","type","item","qty","food_norm","grade","flags","tags","source"]).to_csv(LOG_PATH, index=False)
                        st.success(f"ë³µêµ¬ ì™„ë£Œ. ê¸°ì¡´ íŒŒì¼ì€ {backup_name} ë¡œ ë°±ì—…ë¨."); _force_rerun()
                    except Exception as e:
                        st.error("ë³µêµ¬ ì‹¤íŒ¨")
                        if debug: st.exception(e)
        except Exception as e:
            st.error("ë¡œê·¸ í¸ì§‘ UI êµ¬ì„± ì¤‘ ì˜¤ë¥˜")
            if debug: st.exception(e)
    else:
        st.info("ì•„ì§ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("---")
    # --- user_rules ê°€ì ¸ì˜¤ê¸° ---
    uploaded = st.file_uploader("user_rules.json ì—…ë¡œë“œ(ë®ì–´ì“°ê¸°)", type=["json"])
    if uploaded is not None:
        try:
            rules = json.load(uploaded)
            save_user_rules(rules)
            st.success("user_rules.json ì—…ë°ì´íŠ¸ ì™„ë£Œ. ì‚¬ì´ë“œë°” í™•ì¸."); _force_rerun()
        except Exception as e:
            st.error(f"ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

# ==== [ADDON] ì¦‰ì„ ì‹ë‹¨ í‰ê°€ + ì˜ì–‘ í•œì¤„ ì½”ë©˜íŠ¸ ===============================
try:
    import streamlit as st
    import pandas as pd
    import re
    import random
    from difflib import get_close_matches
except Exception:
    pass

if 'CORE_NUTRIENTS' not in globals():
    CORE_NUTRIENTS = [
        "ë‹¨ë°±ì§ˆ", "ì‹ì´ì„¬ìœ ", "ì² ", "ì¹¼ìŠ˜", "ë§ˆê·¸ë„¤ìŠ˜", "ì¹¼ë¥¨",
        "ì˜¤ë©”ê°€3", "ë¹„íƒ€ë¯¼A", "ë¹„íƒ€ë¯¼B", "ë¹„íƒ€ë¯¼C", "ë¹„íƒ€ë¯¼D", "ë¹„íƒ€ë¯¼E",
        "ì €ë‹¹", "ì €ì—¼", "ê±´ê°•í•œì§€ë°©"
    ]

if 'ESSENTIALS' not in globals():
    ESSENTIALS = ["ë‹¨ë°±ì§ˆ", "ì‹ì´ì„¬ìœ ", "ë¹„íƒ€ë¯¼C", "ì¹¼ìŠ˜"]

if 'food_db' not in globals():
    FOOD_ROWS = [
        ("ë‹­ê°€ìŠ´ì‚´", "Safe", ["ë‹¨ë°±ì§ˆ", "ì €ì§€ë°©"]),
        ("ë‘ë¶€", "Safe", ["ë‹¨ë°±ì§ˆ", "ì¹¼ìŠ˜"]),
        ("ì—°ì–´", "Safe", ["ë‹¨ë°±ì§ˆ", "ì˜¤ë©”ê°€3", "ê±´ê°•í•œì§€ë°©"]),
        ("ê³„ë€", "Safe", ["ë‹¨ë°±ì§ˆ", "ë¹„íƒ€ë¯¼D"]),
        ("ëŒ€êµ¬êµ¬ì´", "Safe", ["ë‹¨ë°±ì§ˆ"]),
        ("í˜„ë¯¸ë°¥", "Safe", ["ì‹ì´ì„¬ìœ ", "ë§ˆê·¸ë„¤ìŠ˜"]),
        ("ê·€ë¦¬", "Safe", ["ì‹ì´ì„¬ìœ ", "ì² "]),
        ("í†µë°€ë¹µ", "Caution", ["ì‹ì´ì„¬ìœ "]),
        ("ìŒ€ë°¥", "Safe", []),
        ("ì‹œê¸ˆì¹˜", "Safe", ["ì² ", "ë¹„íƒ€ë¯¼A", "ë§ˆê·¸ë„¤ìŠ˜"]),
        ("ë¸Œë¡œì½œë¦¬", "Safe", ["ë¹„íƒ€ë¯¼C", "ì‹ì´ì„¬ìœ ", "ì¹¼ìŠ˜"]),
        ("ì–‘ë°°ì¶”", "Safe", ["ë¹„íƒ€ë¯¼C", "ì‹ì´ì„¬ìœ "]),
        ("ë‹¹ê·¼", "Safe", ["ë¹„íƒ€ë¯¼A"]),
        ("ë²„ì„¯", "Safe", ["ë¹„íƒ€ë¯¼B", "ì‹ì´ì„¬ìœ "]),
        ("ì˜¬ë¦¬ë¸Œìœ ", "Safe", ["ê±´ê°•í•œì§€ë°©", "ë¹„íƒ€ë¯¼E"]),
        ("ì•„ë³´ì¹´ë„", "Safe", ["ê±´ê°•í•œì§€ë°©", "ì¹¼ë¥¨", "ì‹ì´ì„¬ìœ "]),
        ("ì•„ëª¬ë“œ", "Caution", ["ê±´ê°•í•œì§€ë°©", "ë¹„íƒ€ë¯¼E", "ì¹¼ìŠ˜"]),
        ("ìš”ê±°íŠ¸", "Caution", ["ì¹¼ìŠ˜", "ë‹¨ë°±ì§ˆ"]),
    ]
    food_db = pd.DataFrame(FOOD_ROWS, columns=["ì‹í’ˆ", "ë“±ê¸‰", "íƒœê·¸(ì˜ì–‘)"])

if 'NUTRIENT_TIPS' not in globals():
    NUTRIENT_TIPS = {
        "ë‹¨ë°±ì§ˆ": "ê·¼ìœ¡ ìœ ì§€Â·í¬ë§Œê° ë„ì›€â€”ì‹ì‚¬ í›„ í—ˆê¸° ê°ì†Œ.",
        "ì‹ì´ì„¬ìœ ": "ë°°ë³€ ë¦¬ë“¬Â·í¬ë§Œê°, ë‹¹ í¡ìˆ˜ ì™„ë§Œ.",
        "ì² ": "í”¼ë¡œê° ê°ì†ŒÂ·ì§‘ì¤‘ ë„ì›€(ì‚°ì†Œ ìš´ë°˜).",
        "ì¹¼ìŠ˜": "ë¼ˆÂ·ì¹˜ì•„ ê¸°ë³¸, ê·¼ìœ¡ ìˆ˜ì¶•ì—ë„ í•„ìš”.",
        "ë§ˆê·¸ë„¤ìŠ˜": "ê¸´ì¥ ì™„í™”Â·ìˆ˜ë©´Â·ê·¼ìœ¡ ê¸°ëŠ¥ ë„ì›€.",
        "ì¹¼ë¥¨": "ë‚˜íŠ¸ë¥¨ ë°°ì¶œë¡œ ë¶“ê¸°Â·í˜ˆì•• ê´€ë¦¬ì— ìœ ë¦¬.",
        "ì˜¤ë©”ê°€3": "ì‹¬í˜ˆê´€Â·ì—¼ì¦ ê· í˜• ë„ì›€(ë“±í‘¸ë¥¸ ìƒì„ ).",
        "ë¹„íƒ€ë¯¼A": "ëˆˆÂ·í”¼ë¶€ ì ë§‰ ë³´í˜¸(ìƒ‰ ì§„í•œ ì±„ì†Œ).",
        "ë¹„íƒ€ë¯¼B": "ì—ë„ˆì§€ ëŒ€ì‚¬ ì„œí¬íŠ¸, í”¼ë¡œ ì™„í™”.",
        "ë¹„íƒ€ë¯¼C": "ë©´ì—­Â·ì²  í¡ìˆ˜ UP(ê°€ì—´ ëœ í•œ ì±„ì†Œ/ê³¼ì¼).",
        "ë¹„íƒ€ë¯¼D": "ë¼ˆ ê±´ê°•Â·ë©´ì—­ ë„ì›€(í–‡ë¹›Â·ê³„ë€Â·ìƒì„ ).",
        "ë¹„íƒ€ë¯¼E": "í•­ì‚°í™”ë¡œ ì„¸í¬ ë³´í˜¸Â·í”¼ë¶€ ì»¨ë””ì…˜.",
        "ì €ë‹¹": "ì‹í›„ í˜ˆë‹¹ ì¶œë ì„ ì™„í™”.",
        "ì €ì—¼": "ë¶“ê¸°Â·í˜ˆì•• ê´€ë¦¬ì— ë„ì›€.",
        "ê±´ê°•í•œì§€ë°©": "í¬ë§Œê°Â·ì§€ìš©ì„± ë¹„íƒ€ë¯¼ í¡ìˆ˜ì— ë„ì›€.",
        "ì €ì§€ë°©": "ì—´ëŸ‰ ëŒ€ë¹„ ë‹¨ë°±ì§ˆ í™•ë³´ì— ìœ ë¦¬."
    }

if 'NUTRIENT_TIPS_LONG' not in globals():
    NUTRIENT_TIPS_LONG = {
        "ë‹¨ë°±ì§ˆ": "ê·¼ìœ¡ ìœ ì§€, ìƒì²˜ íšŒë³µ, í¬ë§Œê° ìœ ì§€ì— í•µì‹¬.",
        "ì‹ì´ì„¬ìœ ": "ë°°ë³€ ê·œì¹™ì„±, í¬ë§Œê°, í˜ˆë‹¹ ê¸‰ìƒìŠ¹ ì™„í™”ì— ë„ì›€.",
        "ì² ": "í”¼ë¡œê°Â·ì–´ì§€ëŸ¬ì›€ ì˜ˆë°©(ì‚°ì†Œ ìš´ë°˜). ë¹„íƒ€ë¯¼ Cì™€ í•¨ê»˜ ì„­ì·¨í•˜ë©´ í¡ìˆ˜â†‘",
        "ì¹¼ìŠ˜": "ë¼ˆÂ·ì¹˜ì•„ ê±´ê°•, ì‹ ê²½Â·ê·¼ìœ¡ ê¸°ëŠ¥.",
        "ë§ˆê·¸ë„¤ìŠ˜": "ê·¼ìœ¡ ì´ì™„, ìˆ˜ë©´Â·ê¸´ì¥ ì™„í™”, ì—ë„ˆì§€ ëŒ€ì‚¬.",
        "ì¹¼ë¥¨": "ë‚˜íŠ¸ë¥¨ ë°°ì¶œì„ ë„ì™€ ë¶“ê¸°Â·í˜ˆì•• ì¡°ì ˆ.",
        "ì˜¤ë©”ê°€3": "ì‹¬í˜ˆê´€Â·ë‡Œ ê±´ê°•, ì—¼ì¦ ê· í˜•.",
        "ë¹„íƒ€ë¯¼A": "ì•¼ê°„ ì‹œë ¥Â·í”¼ë¶€Â·ì ë§‰ ë³´í˜¸.",
        "ë¹„íƒ€ë¯¼B": "ì—ë„ˆì§€ ìƒì„±Â·í”¼ë¡œ ì™„í™”(ë³µí•©êµ°).",
        "ë¹„íƒ€ë¯¼C": "ë©´ì—­, ì²  í¡ìˆ˜, í•­ì‚°í™”.",
        "ë¹„íƒ€ë¯¼D": "ì¹¼ìŠ˜ í¡ìˆ˜Â·ë¼ˆ ê±´ê°•, ë©´ì—­ ì¡°ì ˆ.",
        "ë¹„íƒ€ë¯¼E": "í•­ì‚°í™”(ì„¸í¬ ë³´í˜¸), í”¼ë¶€ ì»¨ë””ì…˜.",
        "ì €ë‹¹": "ì‹í›„ í˜ˆë‹¹ ì¶œë ì„ ê°ì†Œ.",
        "ì €ì—¼": "ë¶“ê¸° ì™„í™”Â·í˜ˆì•• ê´€ë¦¬.",
        "ê±´ê°•í•œì§€ë°©": "í¬ë§Œê°Â·ì§€ìš©ì„± ë¹„íƒ€ë¯¼ í¡ìˆ˜ ë„ìš°ë¯¸."
    }

if 'NUTRIENT_SOURCES' not in globals():
    NUTRIENT_SOURCES = {
        "ë‹¨ë°±ì§ˆ": ["ë‹­ê°€ìŠ´ì‚´", "ë‘ë¶€", "ì—°ì–´", "ê³„ë€", "ëŒ€êµ¬êµ¬ì´", "ìš”ê±°íŠ¸"],
        "ì‹ì´ì„¬ìœ ": ["í˜„ë¯¸ë°¥", "ê·€ë¦¬", "ë¸Œë¡œì½œë¦¬", "ì–‘ë°°ì¶”", "ì•„ë³´ì¹´ë„", "ë²„ì„¯"],
        "ì² ": ["ì‹œê¸ˆì¹˜", "ê·€ë¦¬", "ë¶‰ì€ì‚´ ìƒì„ ", "ì½©ë¥˜"],
        "ì¹¼ìŠ˜": ["ë‘ë¶€", "ë¸Œë¡œì½œë¦¬", "ìš”ê±°íŠ¸", "ì•„ëª¬ë“œ"],
        "ë§ˆê·¸ë„¤ìŠ˜": ["í˜„ë¯¸ë°¥", "ì‹œê¸ˆì¹˜", "ê²¬ê³¼ë¥˜"],
        "ì¹¼ë¥¨": ["ì•„ë³´ì¹´ë„", "ë°”ë‚˜ë‚˜", "ê°ì", "ì‹œê¸ˆì¹˜"],
        "ì˜¤ë©”ê°€3": ["ì—°ì–´", "ë“±í‘¸ë¥¸ ìƒì„ ", "í˜¸ë‘"],
        "ë¹„íƒ€ë¯¼A": ["ë‹¹ê·¼", "ì‹œê¸ˆì¹˜", "í˜¸ë°•"],
        "ë¹„íƒ€ë¯¼B": ["ë²„ì„¯", "í†µê³¡ë¬¼", "ë‹¬ê±€"],
        "ë¹„íƒ€ë¯¼C": ["ë¸Œë¡œì½œë¦¬", "ì–‘ë°°ì¶”", "í‚¤ìœ„", "íŒŒí”„ë¦¬ì¹´"],
        "ë¹„íƒ€ë¯¼D": ["ê³„ë€", "ì—°ì–´", "ë²„ì„¯(ì¼ê´‘ ê±´ì¡°)"],
        "ë¹„íƒ€ë¯¼E": ["ì˜¬ë¦¬ë¸Œìœ ", "ì•„ëª¬ë“œ", "ì•„ë³´ì¹´ë„"],
        "ì €ë‹¹": ["ì±„ì†Œ ìœ„ì£¼ ë°˜ì°¬", "í†µê³¡ë¬¼ ì†ŒëŸ‰", "ë¬´ê°€ë‹¹ ìš”ê±°íŠ¸"],
        "ì €ì—¼": ["êµ¬ìš´/ì° ì¡°ë¦¬", "ì–‘ë…ì ˆì œ", "í—ˆë¸ŒÂ·ë ˆëª¬ í™œìš©"],
        "ê±´ê°•í•œì§€ë°©": ["ì˜¬ë¦¬ë¸Œìœ ", "ì•„ë³´ì¹´ë„", "ê²¬ê³¼ë¥˜"]
    }

if 'BENEFIT_MAP' not in globals():
    BENEFIT_MAP = {
        "ë‹¨ë°±ì§ˆ": "ê·¼ìœ¡Â·í¬ë§Œê°",
        "ì‹ì´ì„¬ìœ ": "ì¥ê±´ê°•Â·í¬ë§Œê°Â·í˜ˆë‹¹ì™„í™”",
        "ì¹¼ìŠ˜": "ë¼ˆÂ·ì¹˜ì•„",
        "ë¹„íƒ€ë¯¼D": "ë¼ˆÂ·ë©´ì—­",
        "ë¹„íƒ€ë¯¼C": "ë©´ì—­Â·ì² í¡ìˆ˜",
        "ì˜¤ë©”ê°€3": "ì‹¬í˜ˆê´€Â·ì—¼ì¦ì™„í™”",
        "ì¹¼ë¥¨": "ë¶“ê¸°Â·í˜ˆì••",
        "ë§ˆê·¸ë„¤ìŠ˜": "ê¸´ì¥ì™„í™”Â·ìˆ˜ë©´",
        "ë¹„íƒ€ë¯¼E": "í•­ì‚°í™”Â·í”¼ë¶€",
        "ë¹„íƒ€ë¯¼A": "ëˆˆÂ·í”¼ë¶€",
        "ë¹„íƒ€ë¯¼B": "ì—ë„ˆì§€ëŒ€ì‚¬"
    }

if 'VIRTUAL_RULES' not in globals():
    VIRTUAL_RULES = {}

def _split_free_text(text: str):
    if not text:
        return []
    return [p.strip() for p in re.split(r"[,|\n]+", text) if p.strip()]

def _parse_qty(token: str):
    m = re.search(r"([0-9]+(?:\.[0-9]+)?)\s*$", token)
    if m:
        qty = float(m.group(1))
        name = token[:m.start()].strip()
        return name, qty
    return token.strip(), 1.0

def _contains_any(text: str, keywords):
    t = (text or "").lower()
    for k in (keywords or []):
        if k.lower() in t:
            return True
    return False

def _match_food(name: str, df):
    names = df["ì‹í’ˆ"].tolist()
    if name in names:
        return name, True
    cand = get_close_matches(name, names, n=1, cutoff=0.6)
    if cand:
        return cand[0], True
    base = re.sub(r"(êµ¬ì´|ë³¶ìŒ|ì°œ|ìƒëŸ¬ë“œ|ìˆ˜í”„|ì¡°ë¦¼|êµ¬ìš´|ìƒ)", "", name).strip()
    if base and base != name:
        cand = get_close_matches(base, names, n=1, cutoff=0.6)
        if cand:
            return cand[0], True
    return name, False

def _score_tokens(free_text, df_food, user_rules):
    tokens = _split_free_text(free_text)
    rows = []
    score = {k: 0.0 for k in CORE_NUTRIENTS}
    for tok in tokens:
        name_raw, qty = _parse_qty(tok)
        name_norm = (name_raw or "").strip()
        if not name_norm:
            continue
        if _contains_any(name_norm, user_rules.get("avoid_keywords", [])):
            rows.append({"ì‹í’ˆ": name_raw, "ì •ê·œí™”": name_norm, "ìˆ˜ëŸ‰": qty,
                         "ë“±ê¸‰": "Avoid", "ì‚¬ìœ ": "ê°œì¸ íšŒí”¼ë¦¬ìŠ¤íŠ¸", "íƒœê·¸(ì˜ì–‘)": []})
            continue
        mapped, matched = _match_food(name_norm, df_food)
        tags, grade, flags = [], "Safe", ""
        if matched:
            if mapped in VIRTUAL_RULES:
                vr = VIRTUAL_RULES[mapped]
                grade, flags, tags = vr.get("grade", "Safe"), vr.get("flags", ""), vr.get("tags", [])
                if _contains_any(name_norm, user_rules.get("allow_keywords", [])):
                    grade, flags = "Safe", "ê°œì¸ í—ˆìš©"
            else:
                rec = df_food[df_food["ì‹í’ˆ"] == mapped].iloc[0]
                grade = rec.get("ë“±ê¸‰", "Safe")
                tags = rec.get("íƒœê·¸(ì˜ì–‘)", [])
                if _contains_any(name_norm, user_rules.get("allow_keywords", [])) and grade != "Avoid":
                    grade = "Safe"
        else:
            grade, flags, tags = "Unknown", "DB ë¯¸ë“±ì¬", []
        for t in tags:
            if t in score:
                score[t] += float(qty or 1.0)
        rows.append({
            "ì‹í’ˆ": name_raw,
            "ì •ê·œí™”": mapped if matched else name_norm,
            "ìˆ˜ëŸ‰": qty,
            "ë“±ê¸‰": grade,
            "ì‚¬ìœ ": flags,
            "íƒœê·¸(ì˜ì–‘)": tags
        })
    return score, pd.DataFrame(rows)

def _ensure_log():
    try:
        return ensure_log()
    except Exception:
        return pd.DataFrame(columns=["type", "date", "time", "food_norm", "item"])

def _tokens_from_today_log():
    import datetime as _dt
    df = _ensure_log()
    if df is None or df.empty:
        return []
    today = _dt.datetime.now().date()
    try:
        df['date'] = pd.to_datetime(df['date']).dt.date
    except Exception:
        return []
    df_today = df[(df['type'] == 'food') & (df['date'] == today)].copy()
    now_time = _dt.datetime.now().time()
    try:
        df_today['time'] = pd.to_datetime(df_today['time'].astype(str), errors='coerce').dt.time
        df_today = df_today[df_today['time'].isna() | (df_today['time'] <= now_time)]
    except Exception:
        pass
    tokens = []
    for _, r in df_today.iterrows():
        token = (str(r.get('item') or '')).strip() or (str(r.get('food_norm') or '')).strip()
        if token:
            tokens.append(token)
    return tokens

def _today_food_log_df():
    import datetime as _dt
    df = _ensure_log()
    if df is None or df.empty:
        return pd.DataFrame(columns=["type","date","time","food_norm","item","_dt","ì‹œê°„ëŒ€"])
    try:
        df = df[df["type"] == "food"].copy()
        df["date"] = pd.to_datetime(df["date"], errors="coerce")
        df = df.dropna(subset=["date"])
    except Exception:
        return pd.DataFrame(columns=["type","date","time","food_norm","item","_dt","ì‹œê°„ëŒ€"])
    today = pd.Timestamp.now().normalize()
    df = df[df["date"].dt.normalize() == today]
    def _parse_dt(row):
        try:
            t = pd.to_datetime(str(row.get("time") or ""), errors="coerce").time()
        except Exception:
            t = None
        d = row["date"].date()
        if t is None:
            return pd.Timestamp.combine(d, pd.Timestamp.now().time())
        return pd.Timestamp.combine(d, t)
    if not df.empty:
        df["_dt"] = df.apply(_parse_dt, axis=1)
        def _tod_label(ts):
            h = ts.hour
            if 5 <= h < 11: return "ì•„ì¹¨"
            if 11 <= h < 16: return "ì ì‹¬"
            if 16 <= h < 21: return "ì €ë…"
            return "ê°„ì‹"
        df["ì‹œê°„ëŒ€"] = df["_dt"].apply(_tod_label)
        df = df.sort_values("_dt")
    else:
        df["_dt"] = pd.NaT
        df["ì‹œê°„ëŒ€"] = ""
    return df

def _per_meal_breakdown(df_food, df_today):
    rows = []
    for _, r in df_today.iterrows():
        raw = str(r.get("item") or "").strip() or str(r.get("food_norm") or "").strip()
        if not raw:
            continue
        mapped, matched = _match_food(raw, df_food)
        tags, benefits = [], []
        if matched:
            try:
                rec = df_food[df_food["ì‹í’ˆ"] == mapped].iloc[0]
                tags = _parse_tags_flexible(rec.get("íƒœê·¸(ì˜ì–‘)", []))
            except Exception:
                tags = []
        for t in tags:
            b = (_benefit_from_tag(t) or _lookup_tip(t))
            if b and b not in benefits:
                benefits.append(b)
        rows.append({
            "ì‹œê°„ëŒ€": r.get("ì‹œê°„ëŒ€", ""),
            "ì‹œê°": r.get("_dt"),
            "ì…ë ¥í•­ëª©": raw,
            "ë§¤ì¹­ì‹í’ˆ": mapped if matched else raw,
            "ì±„ì›Œì§„íƒœê·¸": ", ".join(tags[:5]),
            "ì§ê´€ì„¤ëª…": (" Â· ".join([x for x in benefits if x][:3]) or "ê· í˜• ì¡íŒ ì„ íƒ")
        })
    df_out = pd.DataFrame(rows)
    if not df_out.empty:
        df_out = df_out.sort_values(["ì‹œê°„ëŒ€","ì‹œê°"])
    return df_out

def _make_intuitive_summary(scores: dict, threshold: float = 1.0) -> str:
    filled_benefits = []
    low_benefits = []
    ordered_keys = list(ESSENTIALS) + [k for k in BENEFIT_MAP.keys() if k not in ESSENTIALS]
    for k in ordered_keys:
        val = float(scores.get(k, 0) or 0)
        benefit = BENEFIT_MAP.get(k)
        if not benefit:
            continue
        if val >= threshold:
            if benefit not in filled_benefits:
                filled_benefits.append(benefit)
        else:
            if benefit not in low_benefits:
                low_benefits.append(benefit)
    left = " Â· ".join(filled_benefits[:3]) if filled_benefits else ""
    right = " Â· ".join(low_benefits[:3]) if low_benefits else ""
    if left and right:
        return f"ì˜¤ëŠ˜ í•œ ì¤„ ìš”ì•½: {left}ëŠ” ê½¤ ì±„ì›Œì¡Œê³ , {right}ëŠ” ë³´ì¶©ì´ í•„ìš”í•´ìš”."
    elif left:
        return f"ì˜¤ëŠ˜ í•œ ì¤„ ìš”ì•½: {left}ëŠ” ì˜ ì±™ê²¨ì¡Œì–´ìš”."
    elif right:
        return f"ì˜¤ëŠ˜ í•œ ì¤„ ìš”ì•½: {right} ë³´ì¶©ì´ í•„ìš”í•´ìš”."
    else:
        return "ì˜¤ëŠ˜ í•œ ì¤„ ìš”ì•½: ë¶„ì„í•  í•­ëª©ì´ ì—†ì–´ìš”."

try:
    st.divider()
    with st.container():
        st.header("âš¡ ì¦‰ì„ ì‹ë‹¨ í‰ê°€ (ì €ì¥ ì—†ì´ ë¶„ì„)")

        with st.expander("ğŸ“˜ ì˜ì–‘ì†Œ í•œëˆˆ ìš”ì•½ (ë¬´ì—‡ì— ì¢‹ì€ê°€ + ëŒ€í‘œ ì‹í’ˆ)", expanded=False):
            df_gloss = pd.DataFrame([
                {
                    "ì˜ì–‘ì†Œ": k,
                    "ë¬´ì—‡ì— ì¢‹ì€ê°€(ì‰½ê²Œ)": NUTRIENT_TIPS_LONG.get(k, NUTRIENT_TIPS.get(k, "")),
                    "ëŒ€í‘œ ì‹í’ˆ": ", ".join(NUTRIENT_SOURCES.get(k, [])[:4])
                }
                for k in CORE_NUTRIENTS if (k in NUTRIENT_TIPS or k in NUTRIENT_TIPS_LONG)
            ])
            st.dataframe(df_gloss, use_container_width=True, height=380)
            st.caption("â€¢ ë¶€ì¡± íƒœê·¸ê°€ ëœ¨ë©´ ëŒ€í‘œ ì‹í’ˆì„ ì°¸ê³ í•´ ë‹¤ìŒ ì‹ì‚¬ë¥¼ êµ¬ì„±í•´ë³´ì„¸ìš”.")

        colA, colB, colC, colD = st.columns([1.2, 1.2, 1, 1])
        with colA:
            avoid = st.text_input("íšŒí”¼ í‚¤ì›Œë“œ(ì‰¼í‘œ)", value="")
        with colB:
            allow = st.text_input("í—ˆìš© í‚¤ì›Œë“œ(ì‰¼í‘œ)", value="")
        with colC:
            include_caution = st.checkbox("Caution í¬í•¨", value=False)
        with colD:
            diversity_n = st.slider("ë‹¤ì–‘í™”(ìµœê·¼ NíšŒ)", 0, 10, 5, 1)

        user_rules_local = {
            "avoid_keywords": [x.strip() for x in avoid.split(",") if x.strip()],
            "allow_keywords": [x.strip() for x in allow.split(",") if x.strip()],
        }

        source_mode = st.radio("ë¶„ì„ ì†ŒìŠ¤", ["ì˜¤ëŠ˜ ê¸°ë¡ ì‚¬ìš©", "ì§ì ‘ ì…ë ¥"], horizontal=True, index=0)
        sample = "ìŒ€ë°¥1, ëŒ€êµ¬êµ¬ì´1, ì–‘ë°°ì¶”1, ë‹¹ê·¼1, ì˜¬ë¦¬ë¸Œìœ 0.5"
        text_in = st.text_area(
            "ì‹ë‹¨ í…ìŠ¤íŠ¸ (ì‰¼í‘œ/ì¤„ë°”ê¿ˆ êµ¬ë¶„)",
            height=120,
            placeholder=sample,
            disabled=(source_mode == "ì˜¤ëŠ˜ ê¸°ë¡ ì‚¬ìš©")
        )

        if source_mode == "ì˜¤ëŠ˜ ê¸°ë¡ ì‚¬ìš©":
            _toks = _tokens_from_today_log()
            if _toks:
                st.caption("ì˜¤ëŠ˜ ê¸°ë¡ì—ì„œ ë¶ˆëŸ¬ì˜¨ í•­ëª©: " + ", ".join(_toks))
                text_in = ", ".join(_toks)
            else:
                st.info("ì˜¤ëŠ˜ ë‚ ì§œì˜ ìŒì‹ ê¸°ë¡ì´ ì—†ì–´ìš”. ì§ì ‘ ì…ë ¥ìœ¼ë¡œ ì „í™˜í•´ ì£¼ì„¸ìš”.")

        analyze = st.button("ë¶„ì„í•˜ê¸°", type="primary")
        if analyze:
            try:
                scores, items_df = _score_tokens(text_in, food_db, user_rules_local)

                st.markdown("#### ğŸ± íŒŒì‹± ê²°ê³¼")
                if items_df.empty:
                    st.info("í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤. ì‹ë‹¨ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
                else:
                    st.dataframe(items_df, use_container_width=True, height=260)

                st.markdown("#### ğŸ§­ íƒœê·¸ ì ìˆ˜ + í•œì¤„ ì„¤ëª…")
                score_df = (
                    pd.DataFrame([scores]).T
                    .reset_index().rename(columns={"index": "ì˜ì–‘ì†Œ", 0: "ì ìˆ˜"})
                    .sort_values("ì ìˆ˜", ascending=False)
                )
                score_df["ì˜ì–‘ì†Œ(ë³´ê¸°)"] = score_df["ì˜ì–‘ì†Œ"].map(_friendly_label)
                score_df["í•œì¤„ì„¤ëª…"] = score_df["ì˜ì–‘ì†Œ"].map(lambda x: _lookup_tip(x))
                st.dataframe(score_df, use_container_width=True, height=320)

                missing = [n for n in ESSENTIALS if scores.get(n, 0) < 1]
                if missing:
                    tips_list = [f"- **{_friendly_label(n)}**: {(BENEFIT_MAP.get(_canon_key(n)) or NUTRIENT_TIPS.get(_canon_key(n), ''))}
   ì˜ˆì‹œ: {', '.join(_example_foods_for(n))}" for n in missing]
                    st.warning("ë¶€ì¡± íƒœê·¸:\n" + "\n".join(tips_list))
                else:
                    st.success("í•µì‹¬ íƒœê·¸ ì¶©ì¡±! (ESSENTIALS ê¸°ì¤€)")

                try:
                    summary_line = _make_intuitive_summary(scores, threshold=1.0)
                    st.info(summary_line)
                except Exception:
                    pass

                # --- Per-meal breakdown ---
                try:
                    if source_mode == "ì˜¤ëŠ˜ ê¸°ë¡ ì‚¬ìš©":
                        _df_today = _today_food_log_df()
                        df_meal = _per_meal_breakdown(food_db, _df_today)
                        if not df_meal.empty:
                            st.markdown("#### ğŸ½ï¸ ì‹ì‚¬ë³„ ë³´ì¶© í¬ì¸íŠ¸ (ì˜¤ëŠ˜)")
                            for label in ["ì•„ì¹¨","ì ì‹¬","ì €ë…","ê°„ì‹"]:
                                sub = df_meal[df_meal["ì‹œê°„ëŒ€"] == label]
                                if sub.empty:
                                    continue
                                st.markdown(f"**{label}**")
                                st.dataframe(
                                    sub[["ì‹œê°","ì…ë ¥í•­ëª©","ë§¤ì¹­ì‹í’ˆ","ì±„ì›Œì§„íƒœê·¸","ì§ê´€ì„¤ëª…"]]
                                      .rename(columns={
                                          "ì‹œê°":"ì‹œê°„", "ì…ë ¥í•­ëª©":"ë¨¹ì€ ê²ƒ",
                                          "ë§¤ì¹­ì‹í’ˆ":"ë§¤ì¹­", "ì±„ì›Œì§„íƒœê·¸":"íƒœê·¸", "ì§ê´€ì„¤ëª…":"í•œì¤„ì„¤ëª…"
                                      }),
                                    use_container_width=True, height=min(300, 60+28*len(sub))
                                )
                                uniq_benefits = []
                                for s in sub["ì§ê´€ì„¤ëª…"].tolist():
                                    for part in [x.strip() for x in s.split("Â·")]:
                                        if part and part not in uniq_benefits:
                                            uniq_benefits.append(part)
                                if uniq_benefits:
                                    st.caption("ë³´ì¶©ëœ í¬ì¸íŠ¸: " + " Â· ".join(uniq_benefits[:6]))
                except Exception:
                    pass

                # ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ
                st.markdown("#### ğŸ½ï¸ ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ (3ê°€ì§€)")
                recent_items = []
                try:
                    if diversity_n > 0:
                        r = _ensure_log()
                        r = r[r["type"] == "food"].copy()
                        if not r.empty:
                            r["date"] = r["date"].astype(str)
                            r["time"] = r["time"].astype(str)
                            recent_df = r.sort_values(["date", "time"]).tail(diversity_n * 5)
                            recent_items = (recent_df["food_norm"].fillna("") + "|" + recent_df["item"].fillna("")).tolist()
                            recent_items = [x.split("|")[0] for x in recent_items if x]
                except Exception:
                    recent_items = []

                seed = hash(("quick-eval", text_in)) % (10**9)
                favor_tags = missing
                cols = st.columns(3)
                for i in range(3):
                    try:
                        try:
                            rng = random.Random(seed + i)
                            title, meal, explain = gen_meal(
                                food_db, include_caution, mode="ê¸°ë³¸",
                                recent_items=recent_items, favor_tags=favor_tags,
                                rng=rng, user_rules=user_rules_local, allow_rare=False
                            )
                        except Exception:
                            df2 = food_db.copy()
                            if not include_caution:
                                df2 = df2[df2["ë“±ê¸‰"] != "Caution"]
                            pool = df2["ì‹í’ˆ"].tolist()
                            rng = random.Random(seed + i)
                            meal = rng.sample(pool, k=min(3, len(pool))) if len(pool) >= 3 else pool
                            title, explain = "ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ", ("ë¶€ì¡± íƒœê·¸ ë³´ì™„ ì¤‘ì‹¬: " + ", ".join(favor_tags)) if favor_tags else ""
                        with cols[i]:
                            st.markdown(f"**{title} #{i+1}**")
                            st.write(" / ".join(meal))
                            if favor_tags:
                                why = [f"Â· {t}: {NUTRIENT_TIPS.get(t, '')}" for t in favor_tags[:2]]
                                st.caption("ë³´ì™„ í¬ì¸íŠ¸:\n" + "\n".join(why))
                            elif explain:
                                st.caption(explain)
                    except Exception as e:
                        st.error(f"ì œì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
            except Exception as e:
                st.error(f"ë¶„ì„ ì‹¤íŒ¨: {e}")
except Exception:
    pass

# ==== [END ADDON] =============================================================

# ==== [END ADDON] =============================================================

# =============================
# Compatibility Layer (app â†’ v9)
# =============================
# ì´ ì„¹ì…˜ì€ ê¸°ì¡´ app.pyì—ì„œ ì‚¬ìš©í•˜ë˜ í—¬í¼/í•¨ìˆ˜ëª…ì„ v9 ìŠ¤íƒ€ì¼ ë‚´ë¶€ êµ¬í˜„ìœ¼ë¡œ ì—°ê²°í•©ë‹ˆë‹¤.
# v9ì˜ êµ¬ì¡°/ìŠ¤íƒ€ì¼ì„ ìœ ì§€í•˜ë©´ì„œ, app ì½”ë“œì˜ í˜¸ì¶œë¶€ë¥¼ ìµœëŒ€í•œ ê·¸ëŒ€ë¡œ ë™ì‘í•˜ê²Œ ë§Œë“­ë‹ˆë‹¤.

try:
    import pandas as _pd
    import os as _os
    from datetime import datetime as _dt
except Exception:
    pass

def load_nutrient_dict(path: str = "data/nutrient_dict.csv"):
    """
    app.py í˜¸í™˜: ë³„ë„ì˜ nutrient_dict.csv ë¥¼ ë¡œë“œí•˜ë ¤ëŠ” ì‹œë„.
    v9ì—ì„œëŠ” ë‚´ì¥ëœ NUTRIENT_TIPS / NUTRIENT_SOURCES ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ,
    íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ì½ì–´ê°€ê³ , ì—†ìœ¼ë©´ v9ì˜ ì‚¬ì „ìœ¼ë¡œ graceful fallback í•©ë‹ˆë‹¤.
    """
    try:
        if _os.path.exists(path):
            df = _pd.read_csv(path)
            # ê¸°ëŒ€ í¬ë§·: key, short_tip, long_tip (ìˆë‹¤ë©´)
            tips = {}
            tips_long = {}
            for _, row in df.iterrows():
                key = str(row.get("key") or "").strip()
                if not key:
                    continue
                short_tip = str(row.get("short_tip") or "").strip()
                long_tip = str(row.get("long_tip") or short_tip).strip()
                tips[key] = short_tip or NUTRIENT_TIPS.get(key, "")
                tips_long[key] = long_tip or NUTRIENT_TIPS.get(key, "")
            return tips, tips_long
    except Exception:
        pass
    # fallback
    return dict(NUTRIENT_TIPS), dict(NUTRIENT_TIPS)

def save_log(df):
    """
    app.py í˜¸í™˜: ì „ì²´ ë¡œê·¸ DataFrameì„ ì €ì¥.
    v9ëŠ” add_log_row ë“± ë‹¨ìœ„ ì¶”ê°€ ìœ„ì£¼ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ì „ì²´ ì €ì¥ë„ ì§€ì›í•©ë‹ˆë‹¤.
    """
    try:
        if isinstance(LOG_PATH, str):
            df.to_csv(LOG_PATH, index=False)
        else:
            # LOG_PATHê°€ ê²½ë¡œ ê°ì²´ì¸ ê²½ìš°
            _pd.DataFrame(df).to_csv(str(LOG_PATH), index=False)
    except Exception:
        # ì‹¤íŒ¨ ì‹œì—ë„ ì•±ì´ ë©ˆì¶”ì§€ ì•Šë„ë¡ í•¨
        pass

def today_df():
    """
    app.py í˜¸í™˜: ì˜¤ëŠ˜ ë‚ ì§œì˜ ë¡œê·¸ë¥¼ DataFrameìœ¼ë¡œ ë°˜í™˜.
    v9 ë‚´ë¶€ í•¨ìˆ˜ _today_food_log_df() í˜¸ì¶œì„ ìš°ì„  ì‹œë„í•˜ê³ , ì—†ìœ¼ë©´ ì§ì ‘ í•„í„°ë§.
    """
    try:
        return _today_food_log_df()
    except Exception:
        try:
            if isinstance(LOG_PATH, str) and _os.path.exists(LOG_PATH):
                df = _pd.read_csv(LOG_PATH)
                today = _dt.now().strftime("%Y-%m-%d")
                if "date" in df.columns:
                    return df[df["date"].astype(str) == today].copy()
            return _pd.DataFrame()
        except Exception:
            return _pd.DataFrame()


def _parse_tags_flexible(v):
    """
    íƒœê·¸(ì˜ì–‘) ì»¬ëŸ¼ì´ list ë˜ëŠ” ë¬¸ìì—´("ë‹¨ë°±ì§ˆ, ì‹ì´ì„¬ìœ ") ë“± ë‹¤ì–‘í•œ í˜•íƒœë¡œ ì˜¬ ìˆ˜ ìˆì–´
    ì•ˆì „í•˜ê²Œ list[str]ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    if v is None:
        return []
    if isinstance(v, list):
        return [str(x).strip() for x in v if str(x).strip()]
    s = str(v)
    # ì½¤ë§ˆ/ìŠ¬ë˜ì‹œ/ê³µë°± êµ¬ë¶„ìë¥¼ ëª¨ë‘ í—ˆìš©
    parts = re.split(r"[,\u3001/;|]+|\s{2,}", s)
    out = []
    for p in parts:
        p = p.strip()
        if not p:
            continue
        # ê´„í˜¸ë‚˜ í•´ì‹œ ì œê±°
        p = re.sub(r"[#\[\]\(\)]+", "", p).strip()
        if p:
            out.append(p)
    return out


# === User-friendly nutrient mapping & synonyms ===
NUTRIENT_SYNONYMS = dict(globals().get("NUTRIENT_SYNONYMS", {}))
NUTRIENT_FRIENDLY = dict(globals().get("NUTRIENT_FRIENDLY", {}))
NUTRIENT_DEFAULT_EXAMPLES = dict(globals().get("NUTRIENT_DEFAULT_EXAMPLES", {}))

# Canonical â†’ friendly label (emoji + Korean)
NUTRIENT_FRIENDLY.update({
    "Protein": "ë‹¨ë°±ì§ˆ ğŸ—",
    "Fiber": "ì‹ì´ì„¬ìœ  ğŸ¥¦",
    "ComplexCarb": "ë³µí•©íƒ„ìˆ˜í™”ë¬¼ ğŸš",
    "HealthyFat": "ê±´ê°•í•œ ì§€ë°© ğŸ¥‘",
    "Omega3": "ì˜¤ë©”ê°€-3 ğŸŸ",
    "A": "ë¹„íƒ€ë¯¼ A ğŸ¥•",
    "B": "ë¹„íƒ€ë¯¼ Bêµ° ğŸ",
    "C": "ë¹„íƒ€ë¯¼ C ğŸŠ",
    "D": "ë¹„íƒ€ë¯¼ D â˜€ï¸",
    "E": "ë¹„íƒ€ë¯¼ E ğŸ¥œ",
    "K": "ë¹„íƒ€ë¯¼ K ğŸ¥¬",
    "Ca": "ì¹¼ìŠ˜ ğŸ¦´",
    "Mg": "ë§ˆê·¸ë„¤ìŠ˜ ğŸ˜Œ",
    "Fe": "ì² ë¶„ ğŸ’ª",
    "K_potassium": "ì¹¼ë¥¨(ë¶€ì¢…/í˜ˆì••) ğŸ§‚â†˜ï¸",
})

# Abbreviation & alias â†’ canonical key
NUTRIENT_SYNONYMS.update({
    "Protein":"Protein", "ë‹¨ë°±ì§ˆ":"Protein",
    "Fiber":"Fiber", "ì‹ì´ì„¬ìœ ":"Fiber",
    "ComplexCarb":"ComplexCarb","ë³µí•©íƒ„ìˆ˜í™”ë¬¼":"ComplexCarb","slowcarb":"ComplexCarb","slow_carb":"ComplexCarb",
    "HealthyFat":"HealthyFat","ê±´ê°•í•œì§€ë°©":"HealthyFat","goodfat":"HealthyFat",
    "Omega3":"Omega3","ì˜¤ë©”ê°€3":"Omega3","ì˜¤ë©”ê°€-3":"Omega3","EPA/DHA":"Omega3",
    "A":"A","ë¹„íƒ€ë¯¼A":"A",
    "B":"B","ë¹„íƒ€ë¯¼B":"B","ë¹„íƒ€ë¯¼Bêµ°":"B",
    "C":"C","ë¹„íƒ€ë¯¼C":"C",
    "D":"D","ë¹„íƒ€ë¯¼D":"D",
    "E":"E","ë¹„íƒ€ë¯¼E":"E",
    "K":"K","ë¹„íƒ€ë¯¼K":"K",
    "Ca":"Ca","ì¹¼ìŠ˜":"Ca",
    "Mg":"Mg","ë§ˆê·¸ë„¤ìŠ˜":"Mg",
    "Fe":"Fe","ì² ":"Fe","ì² ë¶„":"Fe",
    "K_potassium":"K_potassium","ì¹¼ë¥¨":"K_potassium","Potassium":"K_potassium",
})

# Fallback examples when none in CSV / food_db
NUTRIENT_DEFAULT_EXAMPLES.update({
    "Protein": ["ë‹­ê°€ìŠ´ì‚´","ë‘ë¶€","ì—°ì–´","ê³„ë€","ê·¸ë¦­ìš”ê±°íŠ¸"],
    "Fiber": ["í˜„ë¯¸ë°¥","ê·€ë¦¬","ì‚¬ê³¼","ë¸Œë¡œì½œë¦¬","ë Œí‹¸ì½©"],
    "ComplexCarb": ["í˜„ë¯¸ë°¥","ê·€ë¦¬","í†µë°€ë¹µ","ê³ êµ¬ë§ˆ","í€´ë…¸ì•„"],
    "HealthyFat": ["ì•„ë³´ì¹´ë„","ì˜¬ë¦¬ë¸Œìœ ","ì•„ëª¬ë“œ","í˜¸ë‘","ì°¸ì¹˜"],
    "Omega3": ["ì—°ì–´","ê³ ë“±ì–´","ì •ì–´ë¦¬","í˜¸ë‘","ì¹˜ì•„ì‹œë“œ"],
    "A": ["ë‹¹ê·¼","í˜¸ë°•","ì‹œê¸ˆì¹˜","ì¼€ì¼","ê°„"],
    "B": ["í˜„ë¯¸","ê·€ë¦¬","ë‹¬ê±€","ë²„ì„¯","ë¼ì§€ê³ ê¸°"],
    "C": ["í‚¤ìœ„","íŒŒí”„ë¦¬ì¹´","ë¸Œë¡œì½œë¦¬","ê·¤","ë”¸ê¸°"],
    "D": ["ì—°ì–´","ê³„ë€","ë²„ì„¯(ì¼ê´‘ê±´ì¡°)","ê°•í™”ìš°ìœ "],
    "E": ["ì•„ëª¬ë“œ","í•´ë°”ë¼ê¸°ì”¨","ì˜¬ë¦¬ë¸Œìœ ","ì•„ë³´ì¹´ë„"],
    "K": ["ì¼€ì¼","ì‹œê¸ˆì¹˜","ë¸Œë¡œì½œë¦¬","ìƒì¶”"],
    "Ca": ["ë‘ë¶€","ìš”ê±°íŠ¸","ë©¸ì¹˜","ë¸Œë¡œì½œë¦¬","ìš°ìœ "],
    "Mg": ["ì‹œê¸ˆì¹˜","í˜„ë¯¸","ì•„ëª¬ë“œ","í˜¸ë‘","ë‹¤í¬ì´ˆì½œë¦¿"],
    "Fe": ["ì†Œê°„","ì‹œê¸ˆì¹˜","í™í•©","ë Œí‹¸ì½©","ê°•í™”ì‹œë¦¬ì–¼"],
    "K_potassium": ["ë°”ë‚˜ë‚˜","ì•„ë³´ì¹´ë„","ê°ì","ê³ êµ¬ë§ˆ","ì‹œê¸ˆì¹˜"],
})

def _canon_key(k: str):
    k = str(k or "").strip()
    return NUTRIENT_SYNONYMS.get(k, k)

def _friendly_label(k: str):
    key = _canon_key(k)
    return NUTRIENT_FRIENDLY.get(key, key)


def _lookup_tip(key: str):
    """BENEFIT_MAP ìš°ì„ , ì—†ìœ¼ë©´ NUTRIENT_TIPS. í•œ/ì˜ ì–‘ìª½ í‚¤ ëª¨ë‘ ì‹œë„."""
    k = _canon_key(key)
    # canonical ë¨¼ì €
    v = (BENEFIT_MAP.get(k) or NUTRIENT_TIPS.get(k) or NUTRIENT_TIPS_LONG.get(k) if 'NUTRIENT_TIPS_LONG' in globals() else None)
    if v: return v
    # ì› í‚¤(í•œê¸€ì¼ ìˆ˜ ìˆìŒ)ë„ ì‹œë„
    return (BENEFIT_MAP.get(key) or NUTRIENT_TIPS.get(key) or (NUTRIENT_TIPS_LONG.get(key) if 'NUTRIENT_TIPS_LONG' in globals() else "")) or ""

def _harmonize_mappings():
    """í˜„ì¬ ë¡œë”©ëœ ì‚¬ì „ì˜ í‚¤ë“¤ì„ í•œ/ì˜ ëª¨ë‘ë¡œ ë³µì œí•˜ì—¬ ì¡°íšŒ ì‹¤íŒ¨ë¥¼ ë°©ì§€."""
    try:
        # ë³µì‚¬ë³¸ì—ì„œ ìˆœíšŒ
        for dname in ["NUTRIENT_TIPS", "NUTRIENT_TIPS_LONG", "BENEFIT_MAP", "NUTRIENT_EXAMPLES"]:
            if dname not in globals():
                continue
            d = globals()[dname]
            if not isinstance(d, dict):
                continue
            add_items = {}
            for k, v in list(d.items()):
                ck = _canon_key(k)
                if ck and ck not in d and v not in (None, ""):
                    add_items[ck] = v
                # ë°˜ëŒ€ë¡œ í•œê¸€ í‚¤ë„ í™•ë³´ (ì¹œì ˆ ë¼ë²¨ì—ì„œ í•œêµ­ì–´ ì¡°íšŒ ì‹œ)
                # ê°„ë‹¨ ë§¤í•‘: canonical â†’ friendly ë¼ë²¨ì—ì„œ í•œêµ­ì–´ ì¶”ì¶œ
                try:
                    # _friendly_label(ck) ë°˜í™˜ê°’ì´ "ë¹„íƒ€ë¯¼ C ğŸŠ" ê°™ì€ í˜•íƒœì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ í•œê¸€ë§Œ ì“°ì§€ ì•Šê³  ck ìì²´ ì‚¬ìš©
                    pass
                except Exception:
                    pass
            d.update(add_items)
    except Exception:
        pass

# ì‹¤í–‰ ì‹œì ì— í•œ ë²ˆ ì •í•©í™”
_harmonize_mappings()
def _example_foods_for(k: str, limit=6):
    key = _canon_key(k)
    ex = []
    try:
        ex = (NUTRIENT_EXAMPLES.get(key) if 'NUTRIENT_EXAMPLES' in globals() else None) or []
    except Exception:
        ex = []
    if not ex:
        ex = NUTRIENT_DEFAULT_EXAMPLES.get(key, [])
    return list(dict.fromkeys(ex))[:limit]
def _benefit_from_tag(tag):
    """
    ë‹¨ì¼ íƒœê·¸ì—ì„œ ë² ë„¤í• í•œì¤„ì„ ìƒì„±.
    1) BENEFIT_MAP â†’ 2) NUTRIENT_TIPS â†’ 3) ë™ì˜ì–´ ë§¤í•‘(_nut_ko/_nut_en) â†’ 4) ê¸°ë³¸ ë¬¸êµ¬
    """
    if 'BENEFIT_MAP' in globals() and tag in BENEFIT_MAP and BENEFIT_MAP.get(tag):
        return BENEFIT_MAP.get(tag)
    if 'NUTRIENT_TIPS' in globals() and tag in NUTRIENT_TIPS and NUTRIENT_TIPS.get(tag):
        return NUTRIENT_TIPS.get(tag)
    # ë™ì˜ì–´ ì‹œë„
    try:
        for alt in {tag, _nut_ko(tag), _nut_en(tag)}:
            if alt and 'BENEFIT_MAP' in globals() and BENEFIT_MAP.get(alt):
                return BENEFIT_MAP[alt]
            if alt and 'NUTRIENT_TIPS' in globals() and NUTRIENT_TIPS.get(alt):
                return NUTRIENT_TIPS[alt]
    except Exception:
        pass
    return ""
def _to_tags(text):
    """
    app.py í˜¸í™˜: ììœ  í…ìŠ¤íŠ¸ì—ì„œ ê°„ë‹¨í•œ íƒœê·¸ ì¶”ì¶œ.
    v9ì˜ í† í°/ìŠ¤ì½”ì–´ë§ ë¡œì§ì´ ë” í’ë¶€í•˜ë¯€ë¡œ, ì„ í–‰ ì‚¬ìš© í›„ ë³´ì¡°ì ìœ¼ë¡œ í‚¤ì›Œë“œ ë§¤í•‘ì„ ì ìš©.
    """
    try:
        toks = split_free_text(text)
    except Exception:
        toks = []
    tags = set()
    for t in toks:
        base = t.strip().lower()
        if not base:
            continue
        # ê°„ë‹¨ ë§¤í•‘: ì»¤í”¼/ì°¨/ê³¼ì¼ ë“±
        for k, v in KEYWORD_MAP.items():
            if k.lower() in base:
                tags.add(v)
    return sorted(tags)
