
import streamlit as st
import pandas as pd
import json, re, random, time
from datetime import date, time as dtime, datetime

st.set_page_config(page_title="ë¯¼ê°ë„ ì‹ì‚¬ ë¡œê·¸ â€¢ ììœ  ì…ë ¥", page_icon="ğŸ¥£", layout="wide")

FOOD_DB_PATH = "food_db.csv"
LOG_PATH = "log.csv"

SLOTS = ["ì˜¤ì „","ì˜¤ì „ ê°„ì‹","ì ì‹¬","ì˜¤í›„","ì˜¤í›„ ê°„ì‹","ì €ë…"]
EVENT_TYPES = ["food","supplement","symptom","sleep","stool","note"]

CORE_NUTRIENTS = ["Protein","LightProtein","ComplexCarb","HealthyFat","Fiber",
                  "A","B","C","D","E","K","Fe","Mg","Omega3","K_potassium",
                  "Iodine","Ca","Hydration","Circulation"]

ESSENTIALS = ["Protein","ComplexCarb","Fiber","B","C","A","K","Mg","Omega3","K_potassium","HealthyFat","D"]

SUGGEST_MODES = ["ê¸°ë³¸","ì €ìê·¹(ì—­ë¥˜/ë©”ìŠ¤êº¼ì›€)","ì €ì—¼(ë¶“ê¸°/ì ˆì„ í›„)","ìƒëŸ¬ë“œ","ì£½","ì™¸ì‹ìš©"]

SUPP_ALERT_KEYWORDS = {
    "íš¨ëª¨": ("Avoid","íš¨ëª¨ ë°˜ì‘ â†‘: ë¹µ/ë§¥ì£¼/ë§¥ì£¼íš¨ëª¨ ì£¼ì˜"),
    "ë§¥ì£¼íš¨ëª¨": ("Avoid","íš¨ëª¨ ë°˜ì‘ â†‘: ë§¥ì£¼íš¨ëª¨ íšŒí”¼ ê¶Œì¥"),
    "ì¹´ì œì¸": ("Avoid","ìœ ì œí’ˆÂ·ì¹´ì œì¸ ë°˜ì‘ â†‘"),
    "ìœ ì²­": ("Avoid","ìœ ì œí’ˆê³„ ë‹¨ë°±(ìœ ì²­) ì£¼ì˜"),
    "whey": ("Avoid","ìœ ì œí’ˆê³„ ë‹¨ë°±(ìœ ì²­) ì£¼ì˜"),
    "casein": ("Avoid","ìœ ì œí’ˆÂ·ì¹´ì œì¸ ë°˜ì‘ â†‘"),
    "gluten": ("Avoid","ê¸€ë£¨í… íšŒí”¼ ê¶Œì¥(ê¸€ë¦¬ì•„ë”˜ ë°˜ì‘ â†‘)"),
    "corn": ("Caution","ì˜¥ìˆ˜ìˆ˜ ê²½ê³„: í´ë Œíƒ€/ì½˜ê°€ê³µí’ˆ ì£¼ì˜"),
}

KEYWORD_MAP = {
    # free-text token -> canonical db name or virtual handling
    "ë¸”ë™ì»¤í”¼": "ì»¤í”¼",
    "ì»¤í”¼": "ì»¤í”¼",
    "ë…¹ì°¨": "ë…¹ì°¨",
    "í™ì°¨": "í™ì°¨",
    "ì‚¬ê³¼": "ì‚¬ê³¼",
    "ë°”ë‚˜ë‚˜": "ë°”ë‚˜ë‚˜",
    "í‚¤ìœ„": "í‚¤ìœ„",
    "ì½”ì½”ë„› ì¼€í”¼ì–´": "__VIRTUAL_COCONUT_KEFIR__",
    "ì¼€í”¼ì–´": "__VIRTUAL_COCONUT_KEFIR__",
    "ë¹„ê±´ì¹˜ì¦ˆ": "__VIRTUAL_VEGAN_CHEESE__",
    "ë² ê°„ì¹˜ì¦ˆ": "__VIRTUAL_VEGAN_CHEESE__",
    "í–„": "__VIRTUAL_HAM__",
    "ë¹µ": "__VIRTUAL_BREAD__",
}

VIRTUAL_RULES = {
    "__VIRTUAL_BREAD__": {"grade":"Avoid","flags":"ê¸€ë£¨í…/íš¨ëª¨ ê°€ëŠ¥ì„±","tags":["ComplexCarb"]},
    "__VIRTUAL_HAM__": {"grade":"Caution","flags":"ê°€ê³µìœ¡/ì—¼ë¶„","tags":["Protein"]},
    "__VIRTUAL_VEGAN_CHEESE__": {"grade":"Caution","flags":"ê°€ê³µ ëŒ€ì²´ì‹","tags":["HealthyFat"]},
    "__VIRTUAL_COCONUT_KEFIR__": {"grade":"Caution","flags":"ë°œíš¨(í”„ë¡œë°”ì´ì˜¤í‹±)","tags":["Probiotic"]},
}

def ensure_log():
    cols = ["date","weekday","time","slot","type","item","qty","food_norm","grade","flags","tags","source"]
    try:
        log = pd.read_csv(LOG_PATH)
        for c in cols:
            if c not in log.columns:
                log[c] = "" if c not in ["qty"] else 0
        log = log[cols]
        return log
    except Exception:
        log = pd.DataFrame(columns=cols)
        log.to_csv(LOG_PATH, index=False)
        return log

def load_food_db():
    df = pd.read_csv(FOOD_DB_PATH, encoding="utf-8", engine="python")
    if "íƒœê·¸(ì˜ì–‘)" in df.columns:
        def parse_tags(x):
            try:
                return json.loads(x)
            except Exception:
                return [t.strip() for t in str(x).split(",") if t.strip()]
        df["íƒœê·¸(ì˜ì–‘)"] = df["íƒœê·¸(ì˜ì–‘)"].apply(parse_tags)
    else:
        df["íƒœê·¸(ì˜ì–‘)"] = [[] for _ in range(len(df))]
    if "ë¯¼ê°_ì œì™¸_ê¶Œì¥" not in df.columns:
        df["ë¯¼ê°_ì œì™¸_ê¶Œì¥"] = False
    if "ë“±ê¸‰" not in df.columns:
        df["ë“±ê¸‰"] = df["ë¯¼ê°_ì œì™¸_ê¶Œì¥"].apply(lambda x: "Caution" if x else "Safe")
    if "ì‹í’ˆ" not in df.columns and "í•­ëª©_í•œê¸€" in df.columns:
        df = df.rename(columns={"í•­ëª©_í•œê¸€":"ì‹í’ˆ"})
    if "ì‹í’ˆêµ°" not in df.columns:
        df["ì‹í’ˆêµ°"] = ""
    return df

def weekday_ko(dt: date):
    return ["MON","TUE","WED","THU","FRI","SAT","SUN"][dt.weekday()]

def add_log_row(log, date_str, t_str, slot, typ, item, qty, food_norm, grade, flags, tags, source="manual"):
    new = pd.DataFrame([{
        "date": date_str,
        "weekday": weekday_ko(datetime.strptime(date_str,"%Y-%m-%d").date()),
        "time": t_str,
        "slot": slot,
        "type": typ,
        "item": item,
        "qty": qty,
        "food_norm": food_norm,
        "grade": grade,
        "flags": flags,
        "tags": json.dumps(tags, ensure_ascii=False) if isinstance(tags, list) else (tags or ""),
        "source": source
    }])
    log = pd.concat([log, new], ignore_index=True)
    log.to_csv(LOG_PATH, index=False)
    return log

# --------- Free-text parser ----------
def split_free_text(s: str):
    # Normalize delimiters: + and commas and parentheses content
    if not s: return []
    # extract inside parentheses as additional tokens
    extra = []
    for m in re.findall(r"\((.*?)\)", s):
        extra += re.split(r"[,+/ ]+", m)
    # remove parentheses
    s2 = re.sub(r"\(.*?\)", "", s)
    tokens = re.split(r"[+/,]", s2)
    tokens = [t.strip() for t in tokens if t.strip()]
    tokens += [t.strip() for t in extra if t.strip()]
    return tokens

def parse_qty(token: str):
    # pattern: <name><number> or "<name> <number>" ; default 1.0
    m = re.search(r"([0-9]+(\.[0-9]+)?)", token)
    qty = float(m.group(1)) if m else 1.0
    name = re.sub(r"[0-9]+(\.[0-9]+)?", "", token).strip()
    name = name.replace("ê°œ","").replace("P","").replace("p","").strip()
    return name, qty

def match_food(name: str, food_db: pd.DataFrame):
    orig = name
    # keyword map
    if name in KEYWORD_MAP:
        mapped = KEYWORD_MAP[name]
        return mapped, True
    # try exact match
    recs = food_db[food_db["ì‹í’ˆ"]==name]
    if not recs.empty:
        return name, True
    # substring match (both ways)
    candidates = food_db[food_db["ì‹í’ˆ"].str.contains(name, case=False, na=False)]
    if not candidates.empty:
        return candidates.iloc[0]["ì‹í’ˆ"], True
    candidates = food_db[food_db["ì‹í’ˆ"].apply(lambda x: name in str(x))]
    if not candidates.empty:
        return candidates.iloc[0]["ì‹í’ˆ"], True
    return orig, False  # unmatched

def log_free_foods(log, when_date, when_time, slot, memo, food_db):
    tokens = split_free_text(memo)
    saved = []
    for tok in tokens:
        name_raw, qty = parse_qty(tok)
        name_norm = name_raw.strip()
        if not name_norm: continue
        mapped, matched = match_food(name_norm, food_db)
        if matched:
            # mapped in DB or virtual
            if mapped in VIRTUAL_RULES:
                vr = VIRTUAL_RULES[mapped]
                grade = vr["grade"]; flags = vr["flags"]; tags = vr["tags"]
                log = add_log_row(log, when_date, when_time, slot, "food", name_raw, qty, name_norm, grade, flags, tags, source="memo")
            else:
                rec = food_db[food_db["ì‹í’ˆ"]==mapped].iloc[0]
                grade = rec.get("ë“±ê¸‰","Safe")
                tags = rec.get("íƒœê·¸(ì˜ì–‘)",[])
                log = add_log_row(log, when_date, when_time, slot, "food", name_raw, qty, mapped, grade, "", tags, source="memo")
        else:
            # unmatched: still log, with heuristic flags
            grade, flags, tags = "", "", []
            # heuristics
            if "ë¹µ" in name_norm: grade, flags = "Avoid", "ê¸€ë£¨í…/íš¨ëª¨ ê°€ëŠ¥ì„±"; tags=["ComplexCarb"]
            if "í–„" in name_norm: grade, flags = "Caution", "ê°€ê³µìœ¡/ì—¼ë¶„"; tags=["Protein"]
            if "ì¹˜ì¦ˆ" in name_norm and ("ë¹„ê±´" in name_norm or "ë² ê°„" in name_norm): grade, flags = "Caution","ê°€ê³µ ëŒ€ì²´ì‹"; tags=["HealthyFat"]
            if "ì»¤í”¼" in name_norm: mapped="ì»¤í”¼"; rec = food_db[food_db["ì‹í’ˆ"]==mapped]
            if grade=="" and flags=="":
                grade = ""
            log = add_log_row(log, when_date, when_time, slot, "food", name_raw, qty, "", grade, flags, tags, source="memo(unmatched)")
        saved.append((name_raw, qty))
    return log, saved

# ---------- Scoring ----------
def score_day(df_log, df_food, date_str):
    day = df_log[(df_log["date"]==date_str) & (df_log["type"]=="food")]
    score = {k:0.0 for k in CORE_NUTRIENTS}
    for _, row in day.iterrows():
        fn = row.get("food_norm") or row.get("item")
        try:
            qty = float(row.get("qty") or 1.0)
        except Exception:
            qty = 1.0
        recs = df_food[df_food["ì‹í’ˆ"]==fn]
        if recs.empty:
            # try to infer from virtual rules (if any tag matches CORE)
            if row.get("flags") and row.get("tags"):
                for t in json.loads(row["tags"]):
                    if t in score:
                        score[t] += qty
            continue
        tags = recs.iloc[0]["íƒœê·¸(ì˜ì–‘)"]
        for t in tags:
            if t in score:
                score[t] += qty
    return score

# ---------- Suggestion engine (same as before) ----------
def build_baskets(df, include_caution=False):
    pool = df.copy()
    if not include_caution:
        pool = pool[pool["ë“±ê¸‰"]=="Safe"]
    else:
        pool = pool[pool["ë“±ê¸‰"].isin(["Safe","Caution"])]
    proteins = pool[(pool["ì‹í’ˆêµ°"].isin(["ìƒì„ /í•´ì‚°ë¬¼","ìœ¡ë¥˜"])) & (pool["íƒœê·¸(ì˜ì–‘)"].apply(lambda t: "Protein" in t))]["ì‹í’ˆ"].tolist()
    vegs = pool[(pool["ì‹í’ˆêµ°"]=="ì±„ì†Œ") & (pool["íƒœê·¸(ì˜ì–‘)"].apply(lambda t: "Fiber" in t))]["ì‹í’ˆ"].tolist()
    carbs = pool[(pool["íƒœê·¸(ì˜ì–‘)"].apply(lambda t: "ComplexCarb" in t))]["ì‹í’ˆ"].tolist()
    fats = pool[(pool["íƒœê·¸(ì˜ì–‘)"].apply(lambda t: "HealthyFat" in t))]["ì‹í’ˆ"].tolist()
    return {"protein":proteins, "veg":vegs, "carb":carbs, "fat":fats}

def mode_filters(mode):
    avoid_keywords = []
    comp = {"protein":1,"veg":2,"carb":1,"fat":1}
    if mode=="ì €ìê·¹(ì—­ë¥˜/ë©”ìŠ¤êº¼ì›€)":
        avoid_keywords += ["ì»¤í”¼","í™ì°¨","ì´ˆì½œë¦¿","ì˜¤ë Œì§€","ë ˆëª¬","ë¼ì„","ë¶‰ì€ ê³ ì¶”","ìŠ¤íŒŒì´ì‹œ"]
    if mode=="ì €ì—¼(ë¶“ê¸°/ì ˆì„ í›„)":
        avoid_keywords += ["ì ˆì„","ì “ê°ˆ","ìš°ë©”ë³´ì‹œ","ê¹€ì¹˜","í–„"]
    if mode=="ìƒëŸ¬ë“œ":
        comp = {"protein":1,"veg":2,"fat":1}
    if mode=="ì£½":
        comp = {"protein":1,"veg":1,"carb":1,"fat":1}
    if mode=="ì™¸ì‹ìš©":
        avoid_keywords += ["íŠ€ê¹€","í”„ë¼ì´","í¬ë¦¼"]
    return avoid_keywords, comp

def filter_keywords(items, kws):
    res = []
    for it in items:
        if any(k in it for k in kws):
            continue
        res.append(it)
    return res

def pick_diverse(candidates, recent, need, rng):
    pool = [c for c in candidates if c not in recent]
    if len(pool) >= need:
        rng.shuffle(pool)
        return pool[:need]
    left = need - len(pool)
    rng.shuffle(pool)
    repeat_pool = [c for c in candidates if c in recent]
    rng.shuffle(repeat_pool)
    return pool + repeat_pool[:left]

def gen_meal(df_food, include_caution, mode, recent_items, favor_tags, rng):
    baskets = build_baskets(df_food, include_caution=include_caution)
    avoid_kws, comp = mode_filters(mode)
    for k in list(baskets.keys()):
        baskets[k] = filter_keywords(baskets[k], avoid_kws)
    def favor(lst, favor_tags):
        if not lst: return lst
        scored = []
        for name in lst:
            tags = df_food[df_food["ì‹í’ˆ"]==name].iloc[0]["íƒœê·¸(ì˜ì–‘)"]
            score = sum(1 for t in favor_tags if t in tags)
            scored.append((score, name))
        scored.sort(key=lambda x: (-x[0], rng.random()))
        return [n for _, n in scored]
    for key in ["protein","veg","carb","fat"]:
        baskets[key] = favor(baskets[key], favor_tags)
    meal = []
    for key, need in comp.items():
        chosen = pick_diverse(baskets[key], recent_items, need, rng)
        meal += chosen
    return meal

def supplement_flag(text):
    if not text: return ("","")
    t = text.lower()
    for key, (grade,msg) in SUPP_ALERT_KEYWORDS.items():
        if key in t:
            return (grade, msg)
    return ("","")

# ---------- App ----------
food_db = load_food_db()
log = ensure_log()

st.title("ğŸ¥£ ë¯¼ê°ë„ ì‹ì‚¬ ë¡œê·¸ â€¢ ììœ  ì…ë ¥")

tab1, tab2, tab3 = st.tabs(["ğŸ“ ê¸°ë¡","ğŸ“Š ìš”ì•½/ì œì•ˆ","ğŸ“¤ ë‚´ë³´ë‚´ê¸°"])

with tab1:
    st.subheader("ì˜¤ëŠ˜ ê¸°ë¡")
    colL, colR = st.columns([2,1])
    with colL:
        d = st.date_input("ë‚ ì§œ", value=date.today())
        slot = st.selectbox("ìŠ¬ë¡¯(ì‹œê°„ëŒ€)", SLOTS, index=2)
        t = st.time_input("ì‹œê°", value=dtime(hour=12, minute=0))
        typ = st.radio("ê¸°ë¡ ì¢…ë¥˜", EVENT_TYPES, horizontal=True, index=0)
        if typ=="food":
            memo = st.text_area("ë©”ëª¨ í•œ ì¤„ë¡œ ì…ë ¥ (ì˜ˆ: ë¹µ1, ë² ê°„ì¹˜ì¦ˆ ìŠ¬ë¼ì´ìŠ¤1, í–„1, ë¸”ë™ì»¤í”¼1, ì½”ì½”ë„› ì¼€í”¼ì–´+ê³¼ì¼í“¨ë ˆ(ì‚¬ê³¼, ë°”ë‚˜ë‚˜))", height=100)
            if st.button("â• íŒŒì‹±í•´ì„œ ëª¨ë‘ ì €ì¥", type="primary"):
                ds = d.strftime("%Y-%m-%d"); ts = t.strftime("%H:%M")
                log, saved = log_free_foods(log, ds, ts, slot, memo, food_db)
                st.success(f"{len(saved)}ê°œ í•­ëª© ì €ì¥: " + ", ".join([f"{n}Ã—{q}" for n,q in saved]))
        else:
            qty = 1.0
            text = st.text_area("ë‚´ìš© ì…ë ¥", height=80)
            if typ=="supplement":
                g, flags = supplement_flag(text)
                if g=="Avoid": st.error(flags or "ì£¼ì˜ ë³´ì¶©ì œ")
                elif g=="Caution": st.warning(flags or "ê²½ê³„ ë³´ì¶©ì œ")
            if st.button("â• ì €ì¥", type="primary"):
                ds = d.strftime("%Y-%m-%d"); ts = t.strftime("%H:%M")
                log = add_log_row(log, ds, ts, slot, typ, text, qty, "", "", "", [], source="manual")
                st.success("ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.markdown("---")
        st.caption("ìµœê·¼ ê¸°ë¡")
        st.dataframe(log.sort_values(["date","time"]).tail(20), use_container_width=True, height=240)
    with colR:
        st.subheader("ì˜¤ëŠ˜ ê²½ê³  ìš”ì•½")
        ds = d.strftime("%Y-%m-%d")
        day = log[(log["date"]==ds) & (log["type"]=="food")]
        avoid_ct = (day["grade"]=="Avoid").sum()
        caution_ct = (day["grade"]=="Caution").sum()
        st.write(f"ğŸ”´ íšŒí”¼: {int(avoid_ct)}  /  ğŸŸ¡ ê²½ê³„: {int(caution_ct)}")
        st.caption("ììœ ì…ë ¥ìœ¼ë¡œ ì €ì¥ëœ í•­ëª©ë„ ë“±ê¸‰/í‚¤ì›Œë“œì— ë§ì¶° ê²½ê³  ê³„ì‚°ì— í¬í•¨ë©ë‹ˆë‹¤.")

with tab2:
    st.subheader("ìš”ì•½ & ë‹¤ìŒ ë¼ë‹ˆ ì œì•ˆ(3ê°€ì§€)")
    dsum = st.date_input("ê¸°ì¤€ ë‚ ì§œ", value=date.today(), key="sumdate_2")
    date_str = dsum.strftime("%Y-%m-%d")
    scores = score_day(log, food_db, date_str)
    score_df = pd.DataFrame([scores]).T.reset_index()
    score_df.columns = ["ì˜ì–‘ì†Œ","ì ìˆ˜"]
    st.dataframe(score_df, use_container_width=True, height=260)
    favor_tags = [n for n in ESSENTIALS if scores.get(n,0)<1]
    day = log[log["date"]==date_str]
    sym_today = (day[day["type"]=="symptom"]["item"].str.cat(sep=" ") if not day[day["type"]=="symptom"].empty else "").lower()
    symptoms = []
    for key in ["ì—­ë¥˜","ì‹ ë¬¼","ë©”ìŠ¤êº¼ì›€","ë³µë¶€íŒ½ë§Œ","ë¶“ê¸°","í”¼ë¡œ"]:
        if key in sym_today:
            symptoms.append(key)
    # ìë™ ëª¨ë“œ ë³´ì •: ì˜¤ëŠ˜ Avoidê°€ ìˆì—ˆë‹¤ë©´ 'ì €ìê·¹' ê°€ì¤‘
    mode = st.selectbox("ì œì•ˆ ëª¨ë“œ", SUGGEST_MODES, index=0)
    include_caution = st.checkbox("ê²½ê³„(Caution) í¬í•¨", value=False)
    diversity_n = st.slider("ë‹¤ì–‘í™”(ìµœê·¼ NíšŒ ì¤‘ë³µ íšŒí”¼)", min_value=0, max_value=10, value=5, step=1)
    recent_items = []
    if diversity_n>0:
        recent_df = log[log["type"]=="food"].sort_values(["date","time"]).tail(diversity_n*5)
        recent_items = (recent_df["food_norm"].fillna("") + "|" + recent_df["item"].fillna("")).tolist()
        recent_items = [x.split("|")[0] for x in recent_items if x]
    if (day["grade"]=="Avoid").any() and mode=="ê¸°ë³¸":
        mode = "ì €ìê·¹(ì—­ë¥˜/ë©”ìŠ¤êº¼ì›€)"
    rng = random.Random(int(time.time()) % 10**9)
    cols = st.columns(3)
    for idx in range(3):
        meal = gen_meal(food_db, include_caution, mode, recent_items, favor_tags, rng)
        with cols[idx]:
            st.markdown(f"**ì œì•ˆ {idx+1} â€” {mode}**")
            if meal:
                st.write("â€¢ " + " / ".join(meal))
                if favor_tags:
                    st.caption("ë¶€ì¡± ë³´ì™„ ìš°ì„  íƒœê·¸: " + ", ".join(favor_tags))
                if st.button(f"ğŸ’¾ ì´ ì¡°í•© ì €ì¥ (ì ì‹¬) â€” {idx+1}"):
                    now = datetime.now().strftime("%H:%M")
                    for token in meal:
                        if token in food_db["ì‹í’ˆ"].values:
                            rec = food_db[food_db["ì‹í’ˆ"]==token].iloc[0]
                            add_log_row(log, date_str, now, "ì ì‹¬", "food", token, 1.0, token, rec.get("ë“±ê¸‰","Safe"), "", rec.get("íƒœê·¸(ì˜ì–‘)",[]), source="suggested")
                    st.success("ì €ì¥ ì™„ë£Œ! ê¸°ë¡ íƒ­ì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
            else:
                st.info("ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” ì‹í’ˆ í’€ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. FoodDBë¥¼ ë³´ê°•í•´ì£¼ì„¸ìš”.")

with tab3:
    st.subheader("ë‚´ë³´ë‚´ê¸°/ë°±ì—…")
    with open(LOG_PATH, "rb") as f:
        st.download_button("â¬‡ï¸ log.csv ë‹¤ìš´ë¡œë“œ", data=f, file_name="log.csv", mime="text/csv")
    with open(FOOD_DB_PATH, "rb") as f:
        st.download_button("â¬‡ï¸ food_db.csv ë‹¤ìš´ë¡œë“œ", data=f, file_name="food_db.csv", mime="text/csv")
    st.caption("êµ¬ê¸€ ë“œë¼ì´ë¸Œ ìë™ì—°ë™ì€ ë³´ì•ˆìƒ ë¹„ê¶Œì¥. í´ë” ë§í¬ë¥¼ ê¸°ì–µí•´ë‘ê³  ìˆ˜ë™ ì—…ë¡œë“œê°€ ê°€ì¥ ê°„ë‹¨/ì•ˆì „í•©ë‹ˆë‹¤.")
