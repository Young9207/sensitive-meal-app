# -*- coding: utf-8 -*-
"""
Nutrition Coach â€” Operational (fixed CSV paths, no uploader)
Run:
    streamlit run app_full_operational.py
Data folder:
    ./data/nutrient_dict.csv  (ì˜ì–‘ì‚¬ì „)
    ./data/food_db.csv        (ì‹í’ˆ DB)
    ./data/food_log.csv       (ì‹ì‚¬ ê¸°ë¡)
"""
import re, ast, random, os
from typing import List, Tuple, Dict, Any
from datetime import datetime, date, time

import pandas as pd
import streamlit as st
from difflib import get_close_matches
from pathlib import Path

# ---- Fixed data paths ----
BASE_DIR = Path(__file__).resolve().parent
DATA_DIR = BASE_DIR / "data"
NUTRI_CSV = DATA_DIR / "nutrient_dict.csv"
FOOD_CSV  = DATA_DIR / "food_db.csv"
LOG_CSV   = DATA_DIR / "food_log.csv"

# -----------------------------
# Defaults (used if CSV missing columns/keys)
# -----------------------------
CORE_NUTRIENTS = [
    "ë‹¨ë°±ì§ˆ", "ì‹ì´ì„¬ìœ ", "ì² ", "ì¹¼ìŠ˜", "ë§ˆê·¸ë„¤ìŠ˜", "ì¹¼ë¥¨",
    "ì˜¤ë©”ê°€3", "ë¹„íƒ€ë¯¼A", "ë¹„íƒ€ë¯¼B", "ë¹„íƒ€ë¯¼C", "ë¹„íƒ€ë¯¼D", "ë¹„íƒ€ë¯¼E",
    "ì €ë‹¹", "ì €ì—¼", "ê±´ê°•í•œì§€ë°©"
]
ESSENTIALS = ["ë‹¨ë°±ì§ˆ", "ì‹ì´ì„¬ìœ ", "ë¹„íƒ€ë¯¼C", "ì¹¼ìŠ˜"]

DEFAULT_TIPS = {
    "ë‹¨ë°±ì§ˆ": "ê·¼ìœ¡Â·í¬ë§Œê°", "ì‹ì´ì„¬ìœ ": "ì¥ê±´ê°•Â·í¬ë§Œê°Â·í˜ˆë‹¹ì™„í™”",
    "ì² ": "í”¼ë¡œÂ·ì§‘ì¤‘", "ì¹¼ìŠ˜": "ë¼ˆÂ·ì¹˜ì•„", "ë§ˆê·¸ë„¤ìŠ˜": "ê¸´ì¥ì™„í™”Â·ìˆ˜ë©´",
    "ì¹¼ë¥¨": "ë¶“ê¸°Â·í˜ˆì••", "ì˜¤ë©”ê°€3": "ì‹¬í˜ˆê´€Â·ì—¼ì¦ì™„í™”",
    "ë¹„íƒ€ë¯¼A": "ëˆˆÂ·í”¼ë¶€", "ë¹„íƒ€ë¯¼B": "ì—ë„ˆì§€ëŒ€ì‚¬", "ë¹„íƒ€ë¯¼C": "ë©´ì—­Â·ì² í¡ìˆ˜",
    "ë¹„íƒ€ë¯¼D": "ë¼ˆÂ·ë©´ì—­", "ë¹„íƒ€ë¯¼E": "í•­ì‚°í™”Â·í”¼ë¶€", "ì €ë‹¹": "í˜ˆë‹¹ì™„í™”",
    "ì €ì—¼": "ë¶“ê¸°Â·í˜ˆì••", "ê±´ê°•í•œì§€ë°©": "í¬ë§Œê°Â·í¡ìˆ˜", "ì €ì§€ë°©": "ê°€ë²¼ì›€Â·ë‹¨ë°±ì§ˆí™•ë³´"
}
DEFAULT_LONG = {
    "ë‹¨ë°±ì§ˆ": "ê·¼ìœ¡ ìœ ì§€Â·íšŒë³µ, í¬ë§Œê° ìœ ì§€ì— ë„ì›€.",
    "ì‹ì´ì„¬ìœ ": "ë°°ë³€ ê·œì¹™ì„±, í¬ë§Œê°, í˜ˆë‹¹ ê¸‰ìƒìŠ¹ ì™„í™”.",
    "ì² ": "ì‚°ì†Œ ìš´ë°˜ìœ¼ë¡œ í”¼ë¡œ/ì–´ì§€ëŸ¼ ì™„í™”, ë¹„íƒ€ë¯¼ Cì™€ í•¨ê»˜ í¡ìˆ˜â†‘",
    "ì¹¼ìŠ˜": "ë¼ˆÂ·ì¹˜ì•„ ê±´ê°•, ê·¼ìœ¡/ì‹ ê²½ ê¸°ëŠ¥.",
    "ë§ˆê·¸ë„¤ìŠ˜": "ê·¼ìœ¡ ì´ì™„, ìˆ˜ë©´Â·ê¸´ì¥ ì™„í™”, ì—ë„ˆì§€ ëŒ€ì‚¬.",
    "ì¹¼ë¥¨": "ë‚˜íŠ¸ë¥¨ ë°°ì¶œë¡œ ë¶“ê¸°Â·í˜ˆì•• ì¡°ì ˆ.",
    "ì˜¤ë©”ê°€3": "ì‹¬í˜ˆê´€Â·ë‡Œ ê±´ê°•, ì—¼ì¦ ê· í˜•.",
    "ë¹„íƒ€ë¯¼A": "ì•¼ê°„ ì‹œë ¥Â·í”¼ë¶€Â·ì ë§‰ ë³´í˜¸.",
    "ë¹„íƒ€ë¯¼B": "ì—ë„ˆì§€ ìƒì„±Â·í”¼ë¡œ ì™„í™”(ë³µí•©êµ°).",
    "ë¹„íƒ€ë¯¼C": "ë©´ì—­, ì²  í¡ìˆ˜, í•­ì‚°í™”.",
    "ë¹„íƒ€ë¯¼D": "ì¹¼ìŠ˜ í¡ìˆ˜Â·ë¼ˆ ê±´ê°•, ë©´ì—­ ì¡°ì ˆ.",
    "ë¹„íƒ€ë¯¼E": "í•­ì‚°í™”(ì„¸í¬ ë³´í˜¸), í”¼ë¶€ ì»¨ë””ì…˜.",
    "ì €ë‹¹": "ì‹í›„ í˜ˆë‹¹ ë³€ë™ ì™„í™”.", "ì €ì—¼": "ë¶“ê¸° ì™„í™”Â·í˜ˆì•• ê´€ë¦¬.",
    "ê±´ê°•í•œì§€ë°©": "í¬ë§Œê°Â·ì§€ìš©ì„± ë¹„íƒ€ë¯¼ í¡ìˆ˜."
}
DEFAULT_SOURCES = {
    "ë‹¨ë°±ì§ˆ": ["ë‹­ê°€ìŠ´ì‚´","ë‘ë¶€","ì—°ì–´","ê³„ë€"],
    "ì‹ì´ì„¬ìœ ": ["í˜„ë¯¸ë°¥","ê·€ë¦¬","ë¸Œë¡œì½œë¦¬","ì–‘ë°°ì¶”"],
    "ì¹¼ìŠ˜": ["ë‘ë¶€","ìš”ê±°íŠ¸","ë¸Œë¡œì½œë¦¬","ì•„ëª¬ë“œ"],
    "ë¹„íƒ€ë¯¼D": ["ê³„ë€","ì—°ì–´","ë²„ì„¯(ì¼ê´‘)"],
    "ë¹„íƒ€ë¯¼C": ["ë¸Œë¡œì½œë¦¬","ì–‘ë°°ì¶”","í‚¤ìœ„","íŒŒí”„ë¦¬ì¹´"],
    "ì˜¤ë©”ê°€3": ["ì—°ì–´","ê³ ë“±ì–´","í˜¸ë‘"],
    "ì¹¼ë¥¨": ["ì•„ë³´ì¹´ë„","ë°”ë‚˜ë‚˜","ê°ì","ì‹œê¸ˆì¹˜"],
    "ë§ˆê·¸ë„¤ìŠ˜": ["í˜„ë¯¸ë°¥","ì‹œê¸ˆì¹˜","ê²¬ê³¼ë¥˜"],
    "ë¹„íƒ€ë¯¼E": ["ì˜¬ë¦¬ë¸Œìœ ","ì•„ëª¬ë“œ","ì•„ë³´ì¹´ë„"],
    "ë¹„íƒ€ë¯¼A": ["ë‹¹ê·¼","ì‹œê¸ˆì¹˜","í˜¸ë°•"],
    "ë¹„íƒ€ë¯¼B": ["ë²„ì„¯","í†µê³¡ë¬¼","ë‹¬ê±€"],
    "ê±´ê°•í•œì§€ë°©": ["ì˜¬ë¦¬ë¸Œìœ ","ì•„ë³´ì¹´ë„","ê²¬ê³¼ë¥˜"]
}

# Will be filled from CSV
NUTRIENT_TIPS = dict(DEFAULT_TIPS)        # short line
NUTRIENT_TIPS_LONG = dict(DEFAULT_LONG)   # long
BENEFIT_MAP = dict(DEFAULT_TIPS)          # alias: label for one-liner
NUTRIENT_SOURCES = dict(DEFAULT_SOURCES)

# -----------------------------
# IO & helpers
# -----------------------------
def _to_tags(val):
    if val is None:
        return []
    if isinstance(val, list):
        return [str(x).strip() for x in val if str(x).strip()]
    s = str(val).strip()
    try:
        parsed = ast.literal_eval(s)
        if isinstance(parsed, list):
            return [str(x).strip() for x in parsed if str(x).strip()]
    except Exception:
        pass
    parts = [x.strip() for x in re.split(r'[\/,\|\;]+', s) if x.strip()]
    out = []
    for t in parts:
        t2 = t.strip().strip('"').strip("'")
        if t2 == "ì‹ì´ ì„¬ìœ ": t2 = "ì‹ì´ì„¬ìœ "
        out.append(t2)
    return out

def load_food_db() -> pd.DataFrame:
    if FOOD_CSV.exists():
        df = pd.read_csv(FOOD_CSV)
        if "íƒœê·¸(ì˜ì–‘)" in df.columns:
            df["íƒœê·¸(ì˜ì–‘)"] = df["íƒœê·¸(ì˜ì–‘)"].apply(_to_tags)
        return df
    return pd.DataFrame(columns=["ì‹í’ˆ","ë“±ê¸‰","íƒœê·¸(ì˜ì–‘)"])

def load_nutrient_dict():
    global NUTRIENT_TIPS, NUTRIENT_TIPS_LONG, BENEFIT_MAP, NUTRIENT_SOURCES
    if not NUTRI_CSV.exists():
        return
    try:
        df = pd.read_csv(NUTRI_CSV)
    except Exception:
        return
    # expected columns
    for _, r in df.iterrows():
        k = str(r.get("ì˜ì–‘ì†Œ") or "").strip()
        if not k: continue
        s = str(r.get("í•œì¤„ì„¤ëª…") or "").strip()
        l = str(r.get("ìì„¸í•œì„¤ëª…") or "").strip()
        b = str(r.get("í˜œíƒë¼ë²¨(ìš”ì•½)") or "").strip()
        src = str(r.get("ëŒ€í‘œì‹í’ˆ(ì‰¼í‘œë¡œêµ¬ë¶„)") or "").strip()
        if s: NUTRIENT_TIPS[k] = s
        if l: NUTRIENT_TIPS_LONG[k] = l
        if b: BENEFIT_MAP[k] = b
        if src:
            NUTRIENT_SOURCES[k] = [x.strip() for x in src.split(",") if x.strip()]

def ensure_log() -> pd.DataFrame:
    if LOG_CSV.exists():
        try:
            df = pd.read_csv(LOG_CSV)
            return df
        except Exception:
            pass
    return pd.DataFrame(columns=["date","time","item","food_norm","qty"])

def save_log(df: pd.DataFrame):
    DATA_DIR.mkdir(parents=True, exist_ok=True)
    df.to_csv(LOG_CSV, index=False)

def match_food(name: str, df_food: pd.DataFrame) -> Tuple[str, bool]:
    names = df_food["ì‹í’ˆ"].tolist() if "ì‹í’ˆ" in df_food.columns else []
    if name in names:
        return name, True
    cand = get_close_matches(name, names, n=1, cutoff=0.6)
    if cand:
        return cand[0], True
    base = re.sub(r"(êµ¬ì´|ë³¶ìŒ|ì°œ|ìƒëŸ¬ë“œ|ìˆ˜í”„|ì¡°ë¦¼|êµ¬ìš´|ìƒ)", "", name).strip()
    if base and base != name:
        cand = get_close_matches(base, names, n=1, cutoff=0.6)
        if cand:
            return cand[0], True
    return name, False

def split_free_text(text: str) -> List[str]:
    if not text: return []
    return [p.strip() for p in re.split(r"[,|\n]+", text) if p.strip()]

def parse_qty(token: str) -> Tuple[str, float]:
    m = re.search(r"([0-9]+(?:\.[0-9]+)?)\s*$", token)
    if m:
        qty = float(m.group(1))
        name = token[:m.start()].strip()
        return name, qty
    return token.strip(), 1.0

def score_tokens(free_text: str, df_food: pd.DataFrame):
    tokens = split_free_text(free_text)
    score = {k: 0.0 for k in CORE_NUTRIENTS}
    rows = []
    for tok in tokens:
        name_raw, qty = parse_qty(tok)
        mapped, matched = match_food(name_raw, df_food)
        tags = []
        if matched and "íƒœê·¸(ì˜ì–‘)" in df_food.columns:
            try:
                rec = df_food[df_food["ì‹í’ˆ"] == mapped].iloc[0]
                tags = _to_tags(rec.get("íƒœê·¸(ì˜ì–‘)", []))
            except Exception:
                tags = []
        for t in tags:
            if t in score:
                score[t] += float(qty or 1.0)
        rows.append({"ì‹í’ˆ": name_raw, "ë§¤ì¹­": mapped if matched else name_raw, "ìˆ˜ëŸ‰": qty, "íƒœê·¸": ", ".join(tags)})
    return score, pd.DataFrame(rows)

def make_intuitive_summary(scores: Dict[str, float], thr: float=1.0) -> str:
    filled, low = [], []
    ordered = list(ESSENTIALS) + [k for k in BENEFIT_MAP.keys() if k not in ESSENTIALS]
    for k in ordered:
        v = float(scores.get(k, 0) or 0)
        b = BENEFIT_MAP.get(k)
        if not b: continue
        if v >= thr:
            if b not in filled: filled.append(b)
        else:
            if b not in low: low.append(b)
    L = " Â· ".join(filled[:3])
    R = " Â· ".join(low[:3])
    if L and R: return f"ì˜¤ëŠ˜ í•œ ì¤„ ìš”ì•½: {L}ëŠ” ê½¤ ì±„ì›Œì¡Œê³ , {R}ëŠ” ë³´ì¶©ì´ í•„ìš”í•´ìš”."
    if L: return f"ì˜¤ëŠ˜ í•œ ì¤„ ìš”ì•½: {L}ëŠ” ì˜ ì±™ê²¨ì¡Œì–´ìš”."
    if R: return f"ì˜¤ëŠ˜ í•œ ì¤„ ìš”ì•½: {R} ë³´ì¶©ì´ í•„ìš”í•´ìš”."
    return "ì˜¤ëŠ˜ í•œ ì¤„ ìš”ì•½: ë¶„ì„í•  í•­ëª©ì´ ì—†ì–´ìš”."

def today_df(df_log: pd.DataFrame) -> pd.DataFrame:
    if df_log.empty: return df_log.copy()
    df = df_log.copy()
    try:
        df["date"] = pd.to_datetime(df["date"]).dt.date
    except Exception:
        return df.iloc[0:0]
    today = date.today()
    df = df[df["date"] == today]
    # time-of-day
    def _label(tstr):
        try:
            h = pd.to_datetime(str(tstr)).hour
        except Exception:
            return "ê°„ì‹"
        if 5 <= h < 11: return "ì•„ì¹¨"
        if 11 <= h < 16: return "ì ì‹¬"
        if 16 <= h < 21: return "ì €ë…"
        return "ê°„ì‹"
    df["ì‹œê°„ëŒ€"] = df["time"].apply(_label)
    return df

def per_meal_breakdown(df_food: pd.DataFrame, df_today: pd.DataFrame) -> pd.DataFrame:
    rows = []
    for _, r in df_today.iterrows():
        raw = str(r.get("item") or "").strip()
        if not raw:
            continue
        mapped, matched = match_food(raw, df_food)
        tags = []
        if matched and "íƒœê·¸(ì˜ì–‘)" in df_food.columns:
            try:
                rec = df_food[df_food["ì‹í’ˆ"] == mapped].iloc[0]
                tags = _to_tags(rec.get("íƒœê·¸(ì˜ì–‘)", []))
            except Exception:
                tags = []
        benefits = []
        for t in tags:
            b = BENEFIT_MAP.get(t) or NUTRIENT_TIPS.get(t) or ""
            if b and b not in benefits:
                benefits.append(b)
        rows.append({
            "ì‹œê°„ëŒ€": r.get("ì‹œê°„ëŒ€",""),
            "ì‹œê°„": r.get("time",""),
            "ë¨¹ì€ ê²ƒ": raw,
            "ë§¤ì¹­": mapped if matched else raw,
            "íƒœê·¸": ", ".join(tags[:5]),
            "í•œì¤„ì„¤ëª…": " Â· ".join(benefits[:3])
        })
    out = pd.DataFrame(rows)
    if not out.empty:
        out = out.sort_values(["ì‹œê°„ëŒ€","ì‹œê°„"])
    return out

def gen_meal(df_food: pd.DataFrame, missing_tags: List[str], k: int=3) -> List[List[str]]:
    df = df_food.copy()
    picks_all = []
    import random as _r
    for i in range(3):
        pool = []
        for _, r in df.iterrows():
            tags = _to_tags(r.get("íƒœê·¸(ì˜ì–‘)", []))
            overlap = len(set(tags) & set(missing_tags))
            pool.append((overlap, r["ì‹í’ˆ"]))
        pool.sort(key=lambda x: (-x[0], x[1]))
        cand = [n for ov, n in pool if ov > 0] or df["ì‹í’ˆ"].tolist()
        picks = _r.sample(cand, k=min(k, len(cand))) if len(cand) >= k else cand
        picks_all.append(picks)
    return picks_all

# -----------------------------
# Boot: load CSVs
# -----------------------------
DATA_DIR.mkdir(parents=True, exist_ok=True)
load_nutrient_dict()
food_db = load_food_db()
log_df = ensure_log()

# -----------------------------
# UI â€” Tabs
# -----------------------------
st.set_page_config(page_title="Nutrition Coach (Ops)", layout="wide")
st.title("ğŸ¥— Nutrition Coach â€” ìš´ì˜ìš©")

tabs = st.tabs(["ğŸ“ ê¸°ë¡", "ğŸ“Š ìš”ì•½/ì œì•ˆ", "âš¡ ì¦‰ì„ í‰ê°€", "ğŸ“¤ ë‚´ë³´ë‚´ê¸°", "ğŸ›  ê´€ë¦¬"])

# ---- ê¸°ë¡ ----
with tabs[0]:
    st.subheader("ì‹ì‚¬ ê¸°ë¡ ì¶”ê°€")
    col1, col2, col3 = st.columns([1.2,1,1])
    with col1:
        item = st.text_input("ë¨¹ì€ ê²ƒ (ì˜ˆ: ëŒ€êµ¬êµ¬ì´, ë¸Œë¡œì½œë¦¬ ë“±)")
    with col2:
        d = st.date_input("ë‚ ì§œ", value=date.today(), format="YYYY-MM-DD")
    with col3:
        t = st.time_input("ì‹œê°„", value=pd.Timestamp.now().time())
    qty = st.number_input("ìˆ˜ëŸ‰(ì„ íƒ)", min_value=0.0, value=1.0, step=0.5)
    if st.button("ê¸°ë¡ ì¶”ê°€", type="primary", use_container_width=True):
        log_df = ensure_log()
        new = pd.DataFrame([{"date": d, "time": t, "item": item, "food_norm": "", "qty": qty}])
        log_df = pd.concat([log_df, new], ignore_index=True)
        save_log(log_df)
        st.success("ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤. (data/food_log.csv)")
    st.divider()
    st.subheader("ìµœê·¼ ê¸°ë¡")
    st.dataframe(ensure_log().tail(50), use_container_width=True, height=300)

# ---- ìš”ì•½/ì œì•ˆ ----
with tabs[1]:
    st.subheader("ì˜¤ëŠ˜ ìš”ì•½ (ë‹¹ì¼ ê¸°ì¤€)")
    df_today = today_df(ensure_log())
    if df_today.empty:
        st.info("ì˜¤ëŠ˜ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        # Build text for scoring
        text_in = ", ".join(df_today["item"].dropna().astype(str).tolist())
        scores, parsed = score_tokens(text_in, food_db)
        st.markdown("**íŒŒì‹± ê²°ê³¼**")
        st.dataframe(parsed, use_container_width=True, height=240)

        st.markdown("**íƒœê·¸ ì ìˆ˜ + í•œì¤„ì„¤ëª…**")
        score_df = (
            pd.DataFrame([scores]).T.reset_index().rename(columns={"index":"ì˜ì–‘ì†Œ", 0:"ì ìˆ˜"})
            .sort_values("ì ìˆ˜", ascending=False)
        )
        score_df["í•œì¤„ì„¤ëª…"] = score_df["ì˜ì–‘ì†Œ"].map(lambda x: NUTRIENT_TIPS.get(x, ""))
        st.dataframe(score_df, use_container_width=True, height=320)

        # Missing essentials
        missing = [n for n in ESSENTIALS if scores.get(n, 0) < 1]
        if missing:
            st.warning("ë¶€ì¡± íƒœê·¸: " + ", ".join(missing))
        st.info(make_intuitive_summary(scores, thr=1.0))

        # Per meal breakdown
        st.markdown("**ğŸ½ï¸ ì‹ì‚¬ë³„ ë³´ì¶© í¬ì¸íŠ¸ (ì˜¤ëŠ˜)**")
        meal_df = per_meal_breakdown(food_db, df_today)
        if meal_df.empty:
            st.info("í‘œì‹œí•  ì‹ì‚¬ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for label in ["ì•„ì¹¨","ì ì‹¬","ì €ë…","ê°„ì‹"]:
                sub = meal_df[meal_df["ì‹œê°„ëŒ€"] == label]
                if sub.empty: continue
                st.markdown(f"**{label}**")
                st.dataframe(sub, use_container_width=True, height=min(300, 60+28*len(sub)))
                # badges
                uniq = []
                for s in sub["í•œì¤„ì„¤ëª…"].tolist():
                    for part in [x.strip() for x in s.split("Â·")]:
                        if part and part not in uniq:
                            uniq.append(part)
                if uniq:
                    st.caption("ë³´ì¶©ëœ í¬ì¸íŠ¸: " + " Â· ".join(uniq[:6]))

        # Suggestions
        st.markdown("**ğŸ½ï¸ ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ**")
        cols = st.columns(3)
        picks3 = gen_meal(food_db, missing_tags=missing, k=3)
        for i, picks in enumerate(picks3):
            with cols[i]:
                st.write(f"ì œì•ˆ #{i+1}: " + " / ".join(picks))

        # Glossary
        with st.expander("ğŸ“˜ ì˜ì–‘ì†Œ í•œëˆˆ ìš”ì•½ (CSV ê¸°ë°˜)", expanded=False):
            df_gloss = pd.DataFrame([
                {"ì˜ì–‘ì†Œ": k,
                 "ë¬´ì—‡ì— ì¢‹ì€ê°€(ì‰½ê²Œ)": NUTRIENT_TIPS_LONG.get(k, NUTRIENT_TIPS.get(k, "")),
                 "ëŒ€í‘œ ì‹í’ˆ": ", ".join(NUTRIENT_SOURCES.get(k, [])[:4])}
                for k in CORE_NUTRIENTS if (k in NUTRIENT_TIPS or k in NUTRIENT_TIPS_LONG)
            ])
            st.dataframe(df_gloss, use_container_width=True, height=360)

# ---- ì¦‰ì„ í‰ê°€ ----
with tabs[2]:
    st.subheader("ë¶™ì—¬ë„£ê¸° ë¶„ì„ (ì €ì¥ ì—†ì´)")
    sample = "ìŒ€ë°¥1, ëŒ€êµ¬êµ¬ì´1, ë¸Œë¡œì½œë¦¬1, ì˜¬ë¦¬ë¸Œìœ 0.5"
    text_in = st.text_area("ì‹ë‹¨ í…ìŠ¤íŠ¸", height=120, placeholder=sample)
    if st.button("ë¶„ì„í•˜ê¸°", type="primary"):
        scores, parsed = score_tokens(text_in, food_db)
        st.markdown("**íŒŒì‹± ê²°ê³¼**")
        st.dataframe(parsed, use_container_width=True, height=240)
        st.markdown("**íƒœê·¸ ì ìˆ˜ + í•œì¤„ì„¤ëª…**")
        score_df = (
            pd.DataFrame([scores]).T.reset_index().rename(columns={"index":"ì˜ì–‘ì†Œ", 0:"ì ìˆ˜"})
            .sort_values("ì ìˆ˜", ascending=False)
        )
        score_df["í•œì¤„ì„¤ëª…"] = score_df["ì˜ì–‘ì†Œ"].map(lambda x: NUTRIENT_TIPS.get(x, ""))
        st.dataframe(score_df, use_container_width=True, height=320)
        st.info(make_intuitive_summary(scores, thr=1.0))

# ---- ë‚´ë³´ë‚´ê¸° ----
with tabs[3]):
    st.subheader("CSV ë‚´ë³´ë‚´ê¸°")
    df_all = ensure_log()
    csv_all = df_all.to_csv(index=False).encode("utf-8")
    st.download_button("ì‹ì‚¬ ê¸°ë¡ CSV ë‹¤ìš´ë¡œë“œ", data=csv_all, file_name="food_log.csv", mime="text/csv")
    # ì¼ì¼ ìš”ì•½(ì˜¤ëŠ˜ë§Œ)
    df_today = today_df(df_all)
    text_in = ", ".join(df_today["item"].dropna().astype(str).tolist())
    scores, _ = score_tokens(text_in, food_db) if len(text_in) else ({}, pd.DataFrame())
    daily = pd.DataFrame([{"date": date.today().isoformat(), **scores}])
    st.download_button("ì˜¤ëŠ˜ ìš”ì•½ CSV ë‹¤ìš´ë¡œë“œ", data=daily.to_csv(index=False).encode("utf-8"),
                       file_name="daily_summary.csv", mime="text/csv")

# ---- ê´€ë¦¬ ----
with tabs[4]:
    st.subheader("ë°ì´í„° íŒŒì¼ ìœ„ì¹˜")
    st.code(f"ì˜ì–‘ì‚¬ì „: {NUTRI_CSV}\nì‹í’ˆDB:   {FOOD_CSV}\nê¸°ë¡:     {LOG_CSV}")
    if st.button("ì˜¤ëŠ˜ ê¸°ë¡ ì‚­ì œ"):
        df = ensure_log()
        df = df[df["date"] != date.today().isoformat()]
        save_log(df)
        st.success("ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ë¡ì„ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
    if st.button("ì „ì²´ ê¸°ë¡ ì‚­ì œ", type="secondary"):
        save_log(pd.DataFrame(columns=["date","time","item","food_norm","qty"]))
        st.warning("ì „ì²´ ê¸°ë¡ì„ ì´ˆê¸°í™”í–ˆìŠµë‹ˆë‹¤.")
