#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
diet_analyzer_v2.py
- ê° ì‹ì‚¬ë³„ ì…ë ¥ + ì»¨ë””ì…˜ ê¸°ë¡
- ì˜ì–‘ì†Œë³„ íƒœê·¸ ì§‘ê³„
- ë¶€ì¡± ì˜ì–‘ì†Œ ê¸°ë°˜ ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ (ìë™ threshold ë³´ì •)
- log.csv / food_db_updated.csv ìë™ ê´€ë¦¬
"""

from __future__ import annotations
import re, sys, ast, json, base64, zlib
from collections import defaultdict
from typing import List, Dict, Tuple, Any
from datetime import datetime, date, timedelta
from zoneinfo import ZoneInfo
import pandas as pd

try:
    import streamlit as st
except Exception:
    st = None

# ================= ì„¤ì • =================
FOOD_DB_CSV = "food_db.csv"
NUTRIENT_DICT_CSV = "nutrient_dict.csv"
LOG_CSV = "log.csv"
FOOD_DB_UPDATED_CSV = "food_db_updated.csv"
SLOTS = ["ì•„ì¹¨", "ì˜¤ì „ ê°„ì‹", "ì ì‹¬", "ì˜¤í›„ ê°„ì‹", "ì €ë…"]
TZ = ZoneInfo("Europe/Paris")


# ================= ë‚ ì§œ ê´€ë¦¬ =================
def today_str() -> str:
    return datetime.now(TZ).date().isoformat()


def next_midnight():
    now = datetime.now(TZ)
    return (now + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0, tzinfo=TZ)


def init_state():
    """ìì • ë‹¨ìœ„ ì´ˆê¸°í™”"""
    if "daily_date" not in st.session_state:
        st.session_state.daily_date = today_str()
    if st.session_state.daily_date != today_str():
        for k in ["inputs", "conditions", "last_items", "nutri_summary", "recs"]:
            st.session_state.pop(k, None)
        st.session_state.daily_date = today_str()
    st.session_state.setdefault("inputs", {s: "" for s in SLOTS})
    st.session_state.setdefault("conditions", {s: "" for s in SLOTS})
    st.session_state.setdefault("last_items", pd.DataFrame())
    st.session_state.setdefault("nutri_summary", pd.DataFrame())
    st.session_state.setdefault("recs", [])
    st.session_state.setdefault("threshold", 1)


# ================= ë°ì´í„° ë¡œë”© =================
def _parse_taglist_cell(cell) -> list[str]:
    if isinstance(cell, list):
        return cell
    if pd.isna(cell) or str(cell).strip() in ("", "[]"):
        return []
    s = str(cell).strip()
    try:
        v = ast.literal_eval(s)
        if isinstance(v, list):
            return [str(x).strip() for x in v]
    except Exception:
        pass
    s2 = s.strip("[]")
    return [p.strip().strip("'").strip('"') for p in re.split(r"[,/]", s2) if p.strip()]


def load_food_db(path=FOOD_DB_CSV) -> pd.DataFrame:
    df = pd.read_csv(path)
    if "íƒœê·¸ë¦¬ìŠ¤íŠ¸" not in df.columns:
        df["íƒœê·¸ë¦¬ìŠ¤íŠ¸"] = df["íƒœê·¸(ì˜ì–‘)"].apply(lambda x: _parse_taglist_cell(x))
    else:
        df["íƒœê·¸ë¦¬ìŠ¤íŠ¸"] = df["íƒœê·¸ë¦¬ìŠ¤íŠ¸"].apply(_parse_taglist_cell)
    return df


def load_nutrient_dict(path=NUTRIENT_DICT_CSV) -> dict:
    nd = pd.read_csv(path)
    return {str(r["ì˜ì–‘ì†Œ"]).strip(): str(r["í•œì¤„ì„¤ëª…"]).strip() for _, r in nd.iterrows()}


# ================= íŒŒì„œ =================
def split_items(text: str) -> list[str]:
    if not text:
        return []
    parts = re.split(r"[,|\n|(|)|+]+", text)
    return [p.strip() for p in parts if p.strip()]


def parse_qty(token: str) -> tuple[str, float]:
    m = re.search(r"(.*?)(\d+(?:\.\d+)?)$", token)
    return (m.group(1).strip(), float(m.group(2))) if m else (token.strip(), 1.0)


# ================= ë¶„ì„ =================
def match_item_to_foods(item, df):
    item_norm = item.strip()
    hits = df[df["ì‹í’ˆ"].apply(lambda x: item_norm in str(x) or str(x) in item_norm)]
    return hits


def analyze_items(inputs: dict, df_food, nutrient_desc):
    total_counts = defaultdict(float)
    rows, logs, unmatched = [], [], []

    for slot, text in inputs.items():
        tokens = [parse_qty(t) for t in split_items(text)]
        for name, qty in tokens:
            hits = match_item_to_foods(name, df_food)
            timestamp = datetime.now(TZ).isoformat(timespec="seconds")
            if hits.empty:
                unmatched.append(name)
                logs.append([timestamp, today_str(), slot, name, qty, "", "", ""])
                continue

            tag_union, matched_names = [], []
            agg_grade = "Safe"
            for _, r in hits.iterrows():
                grade = r.get("ë“±ê¸‰", "Safe")
                tags = _parse_taglist_cell(r["íƒœê·¸ë¦¬ìŠ¤íŠ¸"])
                matched_names.append(r["ì‹í’ˆ"])
                for t in tags:
                    total_counts[t] += qty
                    tag_union.append(t)
            rows.append([slot, name, qty, ", ".join(matched_names), agg_grade, ", ".join(set(tag_union))])
            logs.append([timestamp, today_str(), slot, name, qty, ", ".join(matched_names), agg_grade, ", ".join(set(tag_union))])
    return pd.DataFrame(rows, columns=["ìŠ¬ë¡¯","ì…ë ¥í•­ëª©","ìˆ˜ëŸ‰","ë§¤ì¹­ì‹í’ˆ","ë“±ê¸‰","íƒœê·¸"]), total_counts, unmatched, logs


# ================= ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ =================
def recommend_next_meal(total_counts, df_food, nutrient_desc, top_nutrients=3):
    """ìƒëŒ€ì  ë¶€ì¡± ì˜ì–‘ì†Œ ê¸°ë°˜ ì¶”ì²œ"""
    if not total_counts:
        return [{"ë¶€ì¡±ì˜ì–‘ì†Œ": "ë°ì´í„° ì—†ìŒ", "ì„¤ëª…": "ì‹ì‚¬ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.", "ì¶”ì²œì‹í’ˆ": []}]

    avg = sum(total_counts.values()) / (len(total_counts) or 1)
    deficits = {t: max(0.1, avg * 0.8 - v) for t, v in total_counts.items() if v < avg * 0.8}
    if not deficits:
        return [{"ë¶€ì¡±ì˜ì–‘ì†Œ": "ê· í˜• ìœ ì§€", "ì„¤ëª…": "ì˜ì–‘ ê· í˜•ì´ ì–‘í˜¸í•©ë‹ˆë‹¤.", "ì¶”ì²œì‹í’ˆ": []}]

    lacking_sorted = sorted(deficits.items(), key=lambda x: x[1], reverse=True)[:top_nutrients]
    focus_tags = [t for t, _ in lacking_sorted]

    recs = []
    for tag in focus_tags:
        foods = df_food[df_food["íƒœê·¸ë¦¬ìŠ¤íŠ¸"].apply(lambda lst: tag in lst and "Safe" in df_food["ë“±ê¸‰"].values)]
        foods = foods["ì‹í’ˆ"].head(5).tolist()
        recs.append({"ë¶€ì¡±ì˜ì–‘ì†Œ": tag, "ì„¤ëª…": nutrient_desc.get(tag, ""), "ì¶”ì²œì‹í’ˆ": foods})
    return recs


# ================= Streamlit UI =================
def main():
    st.set_page_config(page_title="ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ", page_icon="ğŸ¥—")
    st.title("ğŸ¥— ì‹ë‹¨ ë¶„ì„ + ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ")

    init_state()

    df_food = load_food_db()
    nutrient_desc = load_nutrient_dict()

    d = st.date_input("ê¸°ë¡ ë‚ ì§œ", value=date.today())
    st.caption("ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•´ ì…ë ¥í•˜ì„¸ìš”. ì˜ˆ: ë‹­ê°€ìŠ´ì‚´, í˜„ë¯¸ë°¥, ê¹€ì¹˜")

    for slot in SLOTS:
        st.session_state.inputs[slot] = st.text_area(slot, value=st.session_state.inputs.get(slot, ""), height=60)
        st.session_state.conditions[slot] = st.text_input(f"{slot} ì»¨ë””ì…˜", value=st.session_state.conditions.get(slot, ""), placeholder="ì˜ˆ: í”¼ê³¤í•¨, ë³µë¶€íŒ½ë§Œ")

    if st.button("ë¶„ì„í•˜ê¸°", type="primary"):
        items_df, counts, unmatched, logs = analyze_items(st.session_state.inputs, df_food, nutrient_desc)
        st.session_state.last_items = items_df

        # ì˜ì–‘ ìš”ì•½
        summary = pd.DataFrame([{"ì˜ì–‘ì†Œ": k, "ìˆ˜ëŸ‰í•©": v} for k, v in counts.items()]).sort_values("ìˆ˜ëŸ‰í•©", ascending=False)
        st.session_state.nutri_summary = summary

        # ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ
        recs = recommend_next_meal(counts, df_food, nutrient_desc)
        st.session_state.recs = recs

        # ë¡œê·¸ ì €ì¥
        log_df = pd.DataFrame(logs, columns=["timestamp","date","slot","ì…ë ¥í•­ëª©","ìˆ˜ëŸ‰","ë§¤ì¹­ì‹í’ˆ","ë“±ê¸‰","íƒœê·¸"])
        try:
            prev = pd.read_csv(LOG_CSV)
            merged = pd.concat([prev, log_df], ignore_index=True)
        except Exception:
            merged = log_df
        merged.to_csv(LOG_CSV, index=False, encoding="utf-8-sig")

        # ë¯¸ë§¤ì¹­ ì‹í’ˆ ì¶”ê°€
        if unmatched:
            new_rows = [{"ì‹í’ˆ": n, "ë“±ê¸‰": "", "íƒœê·¸(ì˜ì–‘)": "", "íƒœê·¸ë¦¬ìŠ¤íŠ¸": []} for n in unmatched]
            updated = pd.concat([df_food, pd.DataFrame(new_rows)], ignore_index=True)
            updated.to_csv(FOOD_DB_UPDATED_CSV, index=False, encoding="utf-8-sig")

    # ê²°ê³¼ í‘œì‹œ
    st.markdown("### ğŸ± ìŠ¬ë¡¯ë³„ ë§¤ì¹­ ê²°ê³¼")
    if not st.session_state.last_items.empty:
        st.dataframe(st.session_state.last_items, use_container_width=True)
    else:
        st.info("ì…ë ¥ëœ ì‹ì‚¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("### ğŸ§­ ì˜ì–‘ íƒœê·¸ ìš”ì•½")
    if not st.session_state.nutri_summary.empty:
        st.dataframe(st.session_state.nutri_summary, use_container_width=True)
    else:
        st.info("ì•„ì§ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("### ğŸ½ ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ")
    if st.session_state.recs:
        for r in st.session_state.recs:
            foods = ", ".join(r["ì¶”ì²œì‹í’ˆ"]) if r["ì¶”ì²œì‹í’ˆ"] else "(ì¶”ì²œ ì‹í’ˆ ì—†ìŒ)"
            st.write(f"- **{r['ë¶€ì¡±ì˜ì–‘ì†Œ']}** â†’ {r['ì„¤ëª…']}")
            st.caption(f"ì¶”ì²œ ì‹í’ˆ: {foods}")
    else:
        st.info("ë¶„ì„ í›„ ì œì•ˆì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")


if __name__ == "__main__":
    if st is None:
        print("Streamlit ì„¤ì¹˜ í•„ìš”: pip install streamlit")
        sys.exit(1)
    main()