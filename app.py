#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
diet_analyzer.py
----------------
Streamlit ê¸°ë°˜ ì‹ë‹¨ ë¶„ì„ & ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ ë„êµ¬
- ê° ì‹ì‚¬ ìŠ¬ë¡¯ë³„ ìŒì‹ ë° ì»¨ë””ì…˜ ì…ë ¥
- food_db.csv ê¸°ë°˜ ì˜ì–‘ íƒœê·¸ ë¶„ì„
- ë¶€ì¡±í•œ ì˜ì–‘ì†Œ ìë™ ê°ì§€ í›„ ë‹¤ìŒ ì‹ì‚¬ ì¶”ì²œ
- log.csv ìë™ ì €ì¥ ë° ìµœì‹  ì…ë ¥ ë³µì› (ë¬´í•œë³µì‚¬ ë°©ì§€)
"""

from __future__ import annotations
import re, sys, ast, json, base64, zlib
from collections import defaultdict
from typing import List, Dict, Tuple, Any
from datetime import datetime, date, timedelta
from zoneinfo import ZoneInfo
import pandas as pd

try:
    import streamlit as st
except Exception:
    st = None

# ====================== ì„¤ì • ======================
FOOD_DB_CSV = "food_db.csv"
NUTRIENT_DICT_CSV = "nutrient_dict.csv"
LOG_CSV = "log.csv"
FOOD_DB_UPDATED_CSV = "food_db_updated.csv"

SLOTS = [
    "ì•„ì¹¨", "ì•„ì¹¨ë³´ì¡°ì œ", "ì˜¤ì „ ê°„ì‹", "ì ì‹¬", "ì ì‹¬ë³´ì¡°ì œ",
    "ì˜¤í›„ ê°„ì‹", "ì €ë…", "ì €ë…ë³´ì¡°ì œ", "ì €ë… ê°„ì‹"
]
TZ = ZoneInfo("Europe/Paris")

# ==================== ë‚ ì§œ/ìƒíƒœ ê´€ë¦¬ ====================
def today_str() -> str:
    return datetime.now(TZ).date().isoformat()

def next_midnight():
    now = datetime.now(TZ)
    return (now + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0, tzinfo=TZ)

def init_daily_state():
    """ìì • ê¸°ì¤€ í•˜ë£¨ ë‹¨ìœ„ ìƒíƒœ ì´ˆê¸°í™” + log.csvì—ì„œ ìµœì‹  1ê±´ ë³µì›"""
    if "daily_date" not in st.session_state:
        st.session_state.daily_date = today_str()
    if st.session_state.daily_date != today_str():
        for k in ["inputs", "conditions", "last_items_df", "last_nutri_df", "last_recs", "last_combo"]:
            st.session_state.pop(k, None)
        st.session_state.daily_date = today_str()

    st.session_state.setdefault("inputs", {s: "" for s in SLOTS})
    st.session_state.setdefault("conditions", {s: "" for s in SLOTS})
    st.session_state.setdefault("last_items_df", None)
    st.session_state.setdefault("last_nutri_df", None)
    st.session_state.setdefault("last_recs", [])
    st.session_state.setdefault("last_combo", [])
    st.session_state.setdefault("threshold", 1)
    st.session_state.setdefault("export_flag", True)

    # ì˜¤ëŠ˜ ë‚ ì§œ ë¡œê·¸ ë³µì›
    try:
        df_log = pd.read_csv(LOG_CSV)
        today_logs = df_log[df_log["date"] == today_str()]
        if not today_logs.empty:
            for slot in SLOTS:
                slot_logs = today_logs[today_logs["slot"] == slot]
                if not slot_logs.empty:
                    latest = slot_logs.sort_values("timestamp").tail(1).iloc[0]
                    st.session_state.inputs[slot] = str(latest.get("ì…ë ¥í•­ëª©", "") or "")
                    st.session_state.conditions[slot] = str(latest.get("ì»¨ë””ì…˜", "") or "")
            st.session_state.last_items_df = today_logs.rename(columns={"slot": "ìŠ¬ë¡¯", "date": "ë‚ ì§œ"})
    except FileNotFoundError:
        pass

# ==================== CSV ìœ í‹¸ ====================
def _parse_tags_from_slash(cell) -> List[str]:
    if pd.isna(cell):
        return []
    return [t.strip() for t in str(cell).split('/') if t.strip()]

def _parse_taglist_cell(cell: Any) -> List[str]:
    if isinstance(cell, list):
        return [str(x).strip() for x in cell if str(x).strip()]
    s = "" if cell is None or (isinstance(cell, float) and pd.isna(cell)) else str(cell).strip()
    if not s or s == "[]":
        return []
    try:
        v = ast.literal_eval(s)
        if isinstance(v, list):
            return [str(x).strip() for x in v if str(x).strip()]
    except Exception:
        pass
    try:
        v = json.loads(s)
        if isinstance(v, list):
            return [str(x).strip() for x in v if str(x).strip()]
    except Exception:
        pass
    s2 = s.strip().strip("[]")
    parts = [p.strip().strip("'").strip('"') for p in re.split(r"[,/]", s2) if p.strip()]
    return [p for p in parts if p]

def load_food_db_simple(path: str = FOOD_DB_CSV) -> pd.DataFrame:
    df = pd.read_csv(path)
    for c in ["ì‹í’ˆ", "ë“±ê¸‰", "íƒœê·¸(ì˜ì–‘)"]:
        if c not in df.columns:
            df[c] = ""
    if "íƒœê·¸ë¦¬ìŠ¤íŠ¸" in df.columns:
        df["íƒœê·¸ë¦¬ìŠ¤íŠ¸"] = df["íƒœê·¸ë¦¬ìŠ¤íŠ¸"].apply(_parse_taglist_cell)
    else:
        df["íƒœê·¸ë¦¬ìŠ¤íŠ¸"] = df["íƒœê·¸(ì˜ì–‘)"].apply(_parse_tags_from_slash)
    return df[["ì‹í’ˆ", "ë“±ê¸‰", "íƒœê·¸(ì˜ì–‘)", "íƒœê·¸ë¦¬ìŠ¤íŠ¸"]]

def load_nutrient_dict_simple(path: str = NUTRIENT_DICT_CSV) -> Dict[str, str]:
    nd = pd.read_csv(path)
    for c in ["ì˜ì–‘ì†Œ", "í•œì¤„ì„¤ëª…"]:
        if c not in nd.columns:
            nd[c] = ""
    return {str(r["ì˜ì–‘ì†Œ"]).strip(): str(r["í•œì¤„ì„¤ëª…"]).strip() for _, r in nd.iterrows()}

# ==================== ë¶„ì„ ë¡œì§ ====================
def split_items(text: str) -> List[str]:
    if not text:
        return []
    first = [p.strip() for p in re.split(r"[,|\n|(|)]+", text) if p.strip()]
    final = []
    for part in first:
        final += [q.strip() for q in part.split('+') if q.strip()]
    return final

def parse_qty(token: str) -> Tuple[str, float]:
    m = re.search(r"(.*?)(\d+(?:\.\d+)?)\s*$", token)
    if m:
        return m.group(1).strip(), float(m.group(2))
    return token.strip(), 1.0

def match_item_to_foods(item: str, df_food: pd.DataFrame) -> pd.DataFrame:
    it = item.strip()
    hits = df_food[df_food["ì‹í’ˆ"].apply(lambda x: str(x).strip() in it or it in str(x).strip())].copy()
    hits = hits[hits["ì‹í’ˆ"].apply(lambda x: len(str(x).strip()) >= 1)]
    return hits

def analyze_items_for_slot(input_text: str, slot: str, df_food: pd.DataFrame,
                           nutrient_desc: Dict[str, str], condition: str = ""):
    raw_tokens = split_items(input_text)
    items = [parse_qty(tok) for tok in raw_tokens]

    per_item_rows, log_rows, unmatched_names = [], [], []
    nutrient_counts = defaultdict(float)

    for raw, qty in items:
        if not raw:
            continue
        matched = match_item_to_foods(raw, df_food)
        timestamp = datetime.now(TZ).isoformat(timespec="seconds")

        if matched.empty:
            per_item_rows.append({"ìŠ¬ë¡¯": slot, "ì…ë ¥í•­ëª©": raw, "ìˆ˜ëŸ‰": qty,
                                  "ë§¤ì¹­ì‹í’ˆ": "", "ë“±ê¸‰": "", "íƒœê·¸": "", "ì»¨ë””ì…˜": condition})
            log_rows.append({"timestamp": timestamp, "date": today_str(), "time": timestamp.split("T")[1],
                             "slot": slot, "ì…ë ¥í•­ëª©": raw, "ìˆ˜ëŸ‰": qty, "ë§¤ì¹­ì‹í’ˆ": "",
                             "ë“±ê¸‰": "", "íƒœê·¸": "", "ì»¨ë””ì…˜": condition})
            unmatched_names.append(raw)
            continue

        agg_grade, tag_union, matched_names = "Safe", [], []
        for _, r in matched.iterrows():
            name = str(r["ì‹í’ˆ"]).strip()
            grade = str(r["ë“±ê¸‰"]).strip() or "Safe"
            tags = r.get("íƒœê·¸ë¦¬ìŠ¤íŠ¸", [])
            if not isinstance(tags, list):
                tags = _parse_taglist_cell(tags)
            agg_grade = "Avoid" if grade == "Avoid" else agg_grade
            matched_names.append(name)
            for t in tags:
                nutrient_counts[t] += qty
                tag_union.append(t)

        per_item_rows.append({"ìŠ¬ë¡¯": slot, "ì…ë ¥í•­ëª©": raw, "ìˆ˜ëŸ‰": qty,
                              "ë§¤ì¹­ì‹í’ˆ": ", ".join(dict.fromkeys(matched_names)),
                              "ë“±ê¸‰": agg_grade, "íƒœê·¸": ", ".join(dict.fromkeys(tag_union)),
                              "ì»¨ë””ì…˜": condition})
        log_rows.append({"timestamp": timestamp, "date": today_str(), "time": timestamp.split("T")[1],
                         "slot": slot, "ì…ë ¥í•­ëª©": raw, "ìˆ˜ëŸ‰": qty,
                         "ë§¤ì¹­ì‹í’ˆ": ", ".join(dict.fromkeys(matched_names)),
                         "ë“±ê¸‰": agg_grade, "íƒœê·¸": ", ".join(dict.fromkeys(tag_union)),
                         "ì»¨ë””ì…˜": condition})
    return pd.DataFrame(per_item_rows), dict(nutrient_counts), pd.DataFrame(log_rows), unmatched_names

# ==================== ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ ====================
def recommend_next_meal(nutrient_counts: Dict[str, float],
                        df_food: pd.DataFrame,
                        nutrient_desc: Dict[str, str],
                        threshold: float = 1.0,
                        top_nutrients: int = 3):
    # ì „ì²´ íƒœê·¸ ë¦¬ìŠ¤íŠ¸
    all_tags = sorted({t for lst in df_food["íƒœê·¸ë¦¬ìŠ¤íŠ¸"] for t in lst})
    deficits = {t: max(0, threshold - nutrient_counts.get(t, 0)) for t in all_tags if nutrient_counts.get(t, 0) < threshold}
    if not deficits:
        return [], []
    focus_tags = sorted(deficits.items(), key=lambda x: x[1], reverse=True)[:top_nutrients]

    suggestions, combos = [], []
    for tag, lack in focus_tags:
        desc = nutrient_desc.get(tag, "")
        foods = df_food[df_food["íƒœê·¸ë¦¬ìŠ¤íŠ¸"].apply(lambda lst: tag in lst)]["ì‹í’ˆ"].head(5).tolist()
        suggestions.append({"ë¶€ì¡±ì˜ì–‘ì†Œ": tag, "ì„¤ëª…": desc, "ì¶”ì²œì‹í’ˆ": foods})
        combos += foods[:2]
    return suggestions, combos

# ==================== Streamlit UI ====================
def main():
    st.set_page_config(page_title="ìŠ¬ë¡¯ë³„ ì‹ë‹¨ ë¶„ì„ Â· ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ", page_icon="ğŸ¥—", layout="centered")
    st.title("ğŸ¥— ìŠ¬ë¡¯ë³„ ì‹ë‹¨ ë¶„ì„ Â· ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ")

    init_daily_state()
    remain = next_midnight() - datetime.now(TZ)
    st.caption(f"í˜„ì¬ ì…ë ¥/ê²°ê³¼ëŠ” ìì •ê¹Œì§€ ë³´ì¡´ë©ë‹ˆë‹¤. ë‚¨ì€ ì‹œê°„: {remain.seconds//3600}ì‹œê°„ {remain.seconds%3600//60}ë¶„")

    df_food = load_food_db_simple(FOOD_DB_CSV)
    nutrient_desc = load_nutrient_dict_simple(NUTRIENT_DICT_CSV)
    d = st.date_input("ê¸°ë¡ ë‚ ì§œ", value=date.today())

    # ìŠ¬ë¡¯ ì…ë ¥
    for slot in SLOTS:
        val = st.text_area(slot, height=70, placeholder=f"{slot}ì— ë¨¹ì€ ê²ƒ ì…ë ¥",
                           key=f"ta_{slot}", value=st.session_state.inputs.get(slot, ""))
        st.session_state.inputs[slot] = val
        cond = st.text_input(f"{slot} ì»¨ë””ì…˜", placeholder="ì˜ˆ: ì–‘í˜¸ / í”¼ê³¤í•¨ / ë³µë¶€íŒ½ë§Œ",
                             key=f"cond_{slot}", value=st.session_state.conditions.get(slot, ""))
        st.session_state.conditions[slot] = cond

    c1, c2, c3 = st.columns([1, 1, 1])
    with c1:
        st.number_input("ì¶©ì¡± ì„ê³„(ìˆ˜ëŸ‰í•©)", min_value=1, max_value=5,
                        value=st.session_state.get("threshold", 1),
                        step=1, key="threshold")
    with c2:
        st.checkbox("log.csv ì €ì¥", value=st.session_state.get("export_flag", True), key="export_flag")
    with c3:
        analyze_clicked = st.button("ë¶„ì„í•˜ê¸°", type="primary")

    if analyze_clicked:
        all_items, all_logs, total_counts, all_unmatched = [], [], defaultdict(float), []
        for slot in SLOTS:
            items_df, counts, log_df, unmatched = analyze_items_for_slot(
                st.session_state.inputs.get(slot, ""), slot, df_food, nutrient_desc,
                condition=st.session_state.conditions.get(slot, "")
            )
            if not items_df.empty:
                items_df["ë‚ ì§œ"] = d.isoformat()
            all_items.append(items_df)
            all_logs.append(log_df)
            all_unmatched += unmatched
            for k, v in counts.items():
                total_counts[k] += v

        items_df_all = pd.concat(all_items, ignore_index=True) if all_items else pd.DataFrame()
        logs_all = pd.concat(all_logs, ignore_index=True) if all_logs else pd.DataFrame()

        if st.session_state.export_flag and not logs_all.empty:
            try:
                try:
                    prev = pd.read_csv(LOG_CSV)
                    merged = pd.concat([prev, logs_all], ignore_index=True)
                except Exception:
                    merged = logs_all.copy()
                merged = merged.drop_duplicates(
                    subset=["date","slot","ì…ë ¥í•­ëª©","ë§¤ì¹­ì‹í’ˆ","ë“±ê¸‰","íƒœê·¸","ì»¨ë””ì…˜"], keep="last"
                )
                merged.to_csv(LOG_CSV, index=False, encoding="utf-8-sig")
                st.success(f"log.csv ì €ì¥ ì™„ë£Œ âœ…")
            except Exception as e:
                st.error(f"log.csv ì €ì¥ ì˜¤ë¥˜: {e}")

        # âœ… ë¶€ì¡± ì˜ì–‘ì†Œ ê¸°ë°˜ ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ
        recs, combos = recommend_next_meal(total_counts, df_food, nutrient_desc, threshold=float(st.session_state.threshold))
        st.session_state.last_recs = recs
        st.session_state.last_combo = combos
        st.session_state.last_items_df = items_df_all

    # ì¶œë ¥
    st.markdown("### ğŸ± ìŠ¬ë¡¯ë³„ ë§¤ì¹­ ê²°ê³¼")
    if st.session_state.last_items_df is None or st.session_state.last_items_df.empty:
        st.info("ë§¤ì¹­ëœ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        cols = ["ë‚ ì§œ","ìŠ¬ë¡¯","ì…ë ¥í•­ëª©","ìˆ˜ëŸ‰","ë§¤ì¹­ì‹í’ˆ","ë“±ê¸‰","íƒœê·¸","ì»¨ë””ì…˜"]
        st.dataframe(st.session_state.last_items_df[cols],
                     use_container_width=True,
                     height=min(420, 36*(len(st.session_state.last_items_df)+1)))

    st.markdown("### ğŸ½ ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ")
    recs = st.session_state.get("last_recs", [])
    if recs is None or len(recs) == 0:
        st.warning("ë¶€ì¡±í•œ ì˜ì–‘ì†Œê°€ ì—†ì–´ ì¶”ì²œì´ ì—†ìŠµë‹ˆë‹¤. thresholdë¥¼ ë†’ì—¬ë³´ì„¸ìš”.")
    else:
        for r in recs:
            st.write(f"- **{r['ë¶€ì¡±ì˜ì–‘ì†Œ']}** ({r['ì„¤ëª…']}) â†’ ì¶”ì²œì‹í’ˆ: {', '.join(r['ì¶”ì²œì‹í’ˆ'])}")
        if st.session_state.last_combo:
            st.info("ê°„ë‹¨ ì¡°í•© ì œì•ˆ: " + " / ".join(st.session_state.last_combo[:4]))

if __name__ == "__main__":
    if st is None:
        print("This script requires Streamlit. Install with: pip install streamlit")
        sys.exit(1)
    main()