# -*- coding: utf-8 -*-
"""
Instant Diet Evaluator (ì¦‰ì„ ì‹ë‹¨ í‰ê°€) â€” with Nutrient Tips
-----------------------------------------------------------
Paste your meal list, get tag scores, and see 1-line nutrient tips.
Also suggests the next meal (3 options) focusing on missing essentials.

Run:
    streamlit run instant_diet_eval_app.py
"""
import re
import random
from difflib import get_close_matches
from typing import List, Tuple, Dict, Any

import pandas as pd
import streamlit as st

# -----------------------------
# Minimal in-app "DB"
# -----------------------------
CORE_NUTRIENTS = [
    "ë‹¨ë°±ì§ˆ", "ì‹ì´ì„¬ìœ ", "ì² ", "ì¹¼ìŠ˜", "ë§ˆê·¸ë„¤ìŠ˜", "ì¹¼ë¥¨",
    "ì˜¤ë©”ê°€3", "ë¹„íƒ€ë¯¼A", "ë¹„íƒ€ë¯¼B", "ë¹„íƒ€ë¯¼C", "ë¹„íƒ€ë¯¼D", "ë¹„íƒ€ë¯¼E",
    "ì €ë‹¹", "ì €ì—¼", "ê±´ê°•í•œì§€ë°©"
]

# Essentials considered "must-have per day" (toy rule)
ESSENTIALS = ["ë‹¨ë°±ì§ˆ", "ì‹ì´ì„¬ìœ ", "ë¹„íƒ€ë¯¼C", "ì¹¼ìŠ˜"]

# NEW: 1-line tips per nutrient tag (plain-language, practical)
NUTRIENT_TIPS: Dict[str, str] = {
    "ë‹¨ë°±ì§ˆ": "ê·¼ìœ¡ ìœ ì§€ì™€ í¬ë§Œê°ì— ì¢‹ì•„ìš”â€”ì‹ì‚¬ í›„ í—ˆê¸°ë¥¼ ì¤„ì—¬ì¤˜ìš”.",
    "ì‹ì´ì„¬ìœ ": "ë°°ë³€ ë¦¬ë“¬ê³¼ í¬ë§Œê°ì— ë„ì›€â€”ë‹¹ í¡ìˆ˜ë„ ì™„ë§Œí•˜ê²Œ í•´ì¤˜ìš”.",
    "ì² ": "í”¼ë¡œê° ì¤„ì´ê³  ì§‘ì¤‘ì— ë„ì›€â€”í˜ˆì•¡ ì‚°ì†Œ ìš´ë°˜ì— í•„ìˆ˜ì˜ˆìš”.",
    "ì¹¼ìŠ˜": "ë¼ˆÂ·ì¹˜ì•„ ê±´ê°•ì— ê¸°ë³¸â€”ê·¼ìœ¡ ìˆ˜ì¶•ì—ë„ í•„ìš”í•´ìš”.",
    "ë§ˆê·¸ë„¤ìŠ˜": "ê¸´ì¥ ì™„í™”ì™€ ìˆ˜ë©´Â·ê·¼ìœ¡ ê¸°ëŠ¥ì— ë„ì›€ì„ ì¤˜ìš”.",
    "ì¹¼ë¥¨": "ë‚˜íŠ¸ë¥¨ ë°°ì¶œì„ ë„ì™€ ë¶“ê¸°Â·í˜ˆì•• ê´€ë¦¬ì— ì¢‹ì•„ìš”.",
    "ì˜¤ë©”ê°€3": "ì‹¬í˜ˆê´€ ê±´ê°•ê³¼ ì—¼ì¦ ê· í˜•ì— ë„ì›€â€”ê¸°ë¦„ì§„ ìƒì„ ì— ë§ì•„ìš”.",
    "ë¹„íƒ€ë¯¼A": "ëˆˆÂ·í”¼ë¶€ ì ë§‰ ë³´í˜¸â€”ìƒ‰ ì§„í•œ ì±„ì†Œì— í’ë¶€í•´ìš”.",
    "ë¹„íƒ€ë¯¼B": "ì—ë„ˆì§€ ëŒ€ì‚¬ ì„œí¬íŠ¸â€”í”¼ë¡œê° ë‚®ì¶”ëŠ” ë° ë„ì›€.",
    "ë¹„íƒ€ë¯¼C": "ë©´ì—­ê³¼ ì²  í¡ìˆ˜ UPâ€”ê°€ì—´ ëœ í•œ ì±„ì†ŒÂ·ê³¼ì¼ë¡œ.",
    "ë¹„íƒ€ë¯¼D": "ë¼ˆ ê±´ê°•ê³¼ ë©´ì—­ì— ë„ì›€â€”í–‡ë¹›Â·ë‹¬ê±€Â·ìƒì„ ì—ë„ ìˆì–´ìš”.",
    "ë¹„íƒ€ë¯¼E": "ì„¸í¬ ë³´í˜¸(í•­ì‚°í™”)ì™€ í”¼ë¶€ ì»¨ë””ì…˜ì— ë„ì›€.",
    "ì €ë‹¹": "ì‹í›„ í˜ˆë‹¹ ì¶œë ì„ì„ ì¤„ì´ëŠ” ì„ íƒì´ì—ìš”.",
    "ì €ì—¼": "ë¶“ê¸°Â·í˜ˆì•• ê´€ë¦¬ì— ìœ ë¦¬â€”ê°€ê³µì‹í’ˆ ì†Œê¸ˆ í™•ì¸!",
    "ê±´ê°•í•œì§€ë°©": "í¬ë§Œê°Â·ì§€ìš©ì„± ë¹„íƒ€ë¯¼ í¡ìˆ˜ ë„ìš°ë¯¸(ì•„ë³´ì¹´ë„Â·ê²¬ê³¼).",
    # Extra tags that may appear in sample DB
    "ì €ì§€ë°©": "ì—´ëŸ‰ ëŒ€ë¹„ ë‹¨ë°±ì§ˆ ì±„ìš°ê¸° ì¢‹ê³  ì†Œí™”ë„ ë¹„êµì  í¸í•´ìš”."
}

# Basic food DB for demo
FOOD_ROWS = [
    ("ë‹­ê°€ìŠ´ì‚´", "Safe", ["ë‹¨ë°±ì§ˆ", "ì €ì§€ë°©"]),
    ("ë‘ë¶€", "Safe", ["ë‹¨ë°±ì§ˆ", "ì¹¼ìŠ˜"]),
    ("ì—°ì–´", "Safe", ["ë‹¨ë°±ì§ˆ", "ì˜¤ë©”ê°€3", "ê±´ê°•í•œì§€ë°©"]),
    ("ê³„ë€", "Safe", ["ë‹¨ë°±ì§ˆ", "ë¹„íƒ€ë¯¼D"]),
    ("ëŒ€êµ¬êµ¬ì´", "Safe", ["ë‹¨ë°±ì§ˆ"]),
    ("í˜„ë¯¸ë°¥", "Safe", ["ì‹ì´ì„¬ìœ ", "ë§ˆê·¸ë„¤ìŠ˜"]),
    ("ê·€ë¦¬", "Safe", ["ì‹ì´ì„¬ìœ ", "ì² "]),
    ("í†µë°€ë¹µ", "Caution", ["ì‹ì´ì„¬ìœ "]),
    ("ìŒ€ë°¥", "Safe", []),
    ("ì‹œê¸ˆì¹˜", "Safe", ["ì² ", "ë¹„íƒ€ë¯¼A", "ë§ˆê·¸ë„¤ìŠ˜"]),
    ("ë¸Œë¡œì½œë¦¬", "Safe", ["ë¹„íƒ€ë¯¼C", "ì‹ì´ì„¬ìœ ", "ì¹¼ìŠ˜"]),
    ("ì–‘ë°°ì¶”", "Safe", ["ë¹„íƒ€ë¯¼C", "ì‹ì´ì„¬ìœ "]),
    ("ë‹¹ê·¼", "Safe", ["ë¹„íƒ€ë¯¼A"]),
    ("ë²„ì„¯", "Safe", ["ë¹„íƒ€ë¯¼B", "ì‹ì´ì„¬ìœ "]),
    ("ì˜¬ë¦¬ë¸Œìœ ", "Safe", ["ê±´ê°•í•œì§€ë°©", "ë¹„íƒ€ë¯¼E"]),
    ("ì•„ë³´ì¹´ë„", "Safe", ["ê±´ê°•í•œì§€ë°©", "ì¹¼ë¥¨", "ì‹ì´ì„¬ìœ "]),
    ("ì•„ëª¬ë“œ", "Caution", ["ê±´ê°•í•œì§€ë°©", "ë¹„íƒ€ë¯¼E", "ì¹¼ìŠ˜"]),
    ("ìš”ê±°íŠ¸", "Caution", ["ì¹¼ìŠ˜", "ë‹¨ë°±ì§ˆ"]),
]
food_db = pd.DataFrame(FOOD_ROWS, columns=["ì‹í’ˆ", "ë“±ê¸‰", "íƒœê·¸(ì˜ì–‘)"])

VIRTUAL_RULES: Dict[str, Dict[str, Any]] = {}
DEFAULT_USER_RULES = {"avoid_keywords": [], "allow_keywords": []}

# -----------------------------
# Helpers
# -----------------------------
def split_free_text(text: str) -> List[str]:
    if not text:
        return []
    parts = re.split(r"[,|\n]+", text)
    return [p.strip() for p in parts if p.strip()]

def parse_qty(token: str) -> Tuple[str, float]:
    m = re.search(r"([0-9]+(?:\.[0-9]+)?)\s*$", token)
    if m:
        qty = float(m.group(1))
        name = token[: m.start()].strip()
        return name, qty
    return token.strip(), 1.0

def contains_any(text: str, keywords: List[str]) -> bool:
    text = text.lower()
    for k in keywords or []:
        if k.lower() in text:
            return True
    return False

def match_food(name: str, df_food: pd.DataFrame) -> Tuple[str, bool]:
    names = df_food["ì‹í’ˆ"].tolist()
    if name in names:
        return name, True
    cand = get_close_matches(name, names, n=1, cutoff=0.6)
    if cand:
        return cand[0], True
    base = re.sub(r"(êµ¬ì´|ë³¶ìŒ|ì°œ|ìƒëŸ¬ë“œ|ìˆ˜í”„|ì¡°ë¦¼|êµ¬ìš´|ìƒ)", "", name).strip()
    if base and base != name:
        cand = get_close_matches(base, names, n=1, cutoff=0.6)
        if cand:
            return cand[0], True
    return name, False

def ensure_log() -> pd.DataFrame:
    return pd.DataFrame(columns=["type", "date", "time", "food_norm", "item"])

def pick_candidates_by_tags(df: pd.DataFrame, favor_tags: List[str]) -> List[str]:
    if not favor_tags:
        return df["ì‹í’ˆ"].tolist()
    rows = []
    for _, r in df.iterrows():
        tags = r.get("íƒœê·¸(ì˜ì–‘)", [])
        overlap = len(set(tags) & set(favor_tags))
        rows.append((overlap, r["ì‹í’ˆ"]))
    rows.sort(key=lambda x: (-x[0], x[1]))
    return [name for score, name in rows if score > 0] or df["ì‹í’ˆ"].tolist()

def gen_meal(
    df: pd.DataFrame,
    include_caution: bool,
    mode: str = "ê¸°ë³¸",
    recent_items: List[str] = None,
    favor_tags: List[str] = None,
    rng: random.Random = None,
    user_rules: Dict[str, Any] = None,
    allow_rare: bool = False
) -> Tuple[str, List[str], str]:
    rng = rng or random.Random()
    recent_items = set(recent_items or [])
    favor_tags = favor_tags or []

    df2 = df.copy()
    if not include_caution:
        df2 = df2[df2["ë“±ê¸‰"] != "Caution"]

    if user_rules and user_rules.get("avoid_keywords"):
        mask = df2["ì‹í’ˆ"].apply(lambda x: not contains_any(x, user_rules["avoid_keywords"]))
        df2 = df2[mask]

    pool = pick_candidates_by_tags(df2, favor_tags)
    pool = [p for p in pool if p not in recent_items]
    if len(pool) < 3:
        pool = df2["ì‹í’ˆ"].tolist()

    picks = rng.sample(pool, k=min(3, len(pool))) if len(pool) >= 3 else pool
    explain = ""
    if favor_tags:
        explain = f"ë¶€ì¡± íƒœê·¸ ë³´ì™„ ì¤‘ì‹¬: {', '.join(favor_tags)}"
    title = "ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ"
    return title, picks, explain

# -----------------------------
# Core scoring
# -----------------------------
def score_tokens(free_text: str, df_food: pd.DataFrame, user_rules: Dict[str, Any]):
    tokens = split_free_text(free_text)
    rows = []
    score = {k: 0.0 for k in CORE_NUTRIENTS}

    for tok in tokens:
        name_raw, qty = parse_qty(tok)
        name_norm = (name_raw or "").strip()
        if not name_norm:
            continue

        if contains_any(name_norm, user_rules.get("avoid_keywords", [])):
            rows.append({
                "ì‹í’ˆ": name_raw, "ì •ê·œí™”": name_norm, "ìˆ˜ëŸ‰": qty,
                "ë“±ê¸‰": "Avoid", "ì‚¬ìœ ": "ê°œì¸ íšŒí”¼ë¦¬ìŠ¤íŠ¸", "íƒœê·¸(ì˜ì–‘)": []
            })
            continue

        mapped, matched = match_food(name_norm, df_food)
        tags, grade, flags = [], "Safe", ""
        if matched:
            if mapped in VIRTUAL_RULES:
                vr = VIRTUAL_RULES[mapped]
                grade, flags, tags = vr.get("grade", "Safe"), vr.get("flags", ""), vr.get("tags", [])
                if contains_any(name_norm, user_rules.get("allow_keywords", [])):
                    grade, flags = "Safe", "ê°œì¸ í—ˆìš©"
            else:
                rec = df_food[df_food["ì‹í’ˆ"] == mapped].iloc[0]
                grade = rec.get("ë“±ê¸‰", "Safe")
                tags = rec.get("íƒœê·¸(ì˜ì–‘)", [])
                if contains_any(name_norm, user_rules.get("allow_keywords", [])) and grade != "Avoid":
                    grade = "Safe"
        else:
            grade, flags, tags = "Unknown", "DB ë¯¸ë“±ì¬", []

        for t in tags:
            if t in score:
                score[t] += float(qty or 1.0)

        rows.append({
            "ì‹í’ˆ": name_raw,
            "ì •ê·œí™”": mapped if matched else name_norm,
            "ìˆ˜ëŸ‰": qty,
            "ë“±ê¸‰": grade,
            "ì‚¬ìœ ": flags,
            "íƒœê·¸(ì˜ì–‘)": tags
        })

    items_df = pd.DataFrame(rows)
    return score, items_df

# -----------------------------
# UI
# -----------------------------
st.set_page_config(page_title="ì¦‰ì„ ì‹ë‹¨ í‰ê°€", layout="wide")
st.title("âš¡ ì¦‰ì„ ì‹ë‹¨ í‰ê°€ (Instant Diet Evaluator)")

with st.expander("ë°ëª¨ í‘¸ë“œ DB ë³´ê¸° / CSV êµì²´ ì•ˆë‚´", expanded=False):
    st.write("í˜„ì¬ëŠ” ë°ëª¨ìš© DBë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì›í•˜ëŠ” CSVë¥¼ ì—…ë¡œë“œí•˜ì—¬ êµì²´í•  ìˆ˜ ìˆì–´ìš”.")
    st.dataframe(food_db, use_container_width=True, height=220)
    up = st.file_uploader("CSVë¡œ DB êµì²´ (ì‹í’ˆ, ë“±ê¸‰, íƒœê·¸(ì˜ì–‘) ì»¬ëŸ¼ í•„ìš”)", type=["csv"])
    if up is not None:
        try:
            df_new = pd.read_csv(up)
            if df_new["íƒœê·¸(ì˜ì–‘)"].dtype == object:
                def parse_tags(x):
                    if isinstance(x, list):
                        return x
                    parts = re.split(r"[\/,]+", str(x))
                    return [p.strip() for p in parts if p.strip()]
                df_new["íƒœê·¸(ì˜ì–‘)"] = df_new["íƒœê·¸(ì˜ì–‘)"].apply(parse_tags)
            food_db = df_new
            st.success("DB êµì²´ ì™„ë£Œ! ì•„ë˜ ë¶„ì„ì— ë°˜ì˜ë©ë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"CSV íŒŒì‹± ì‹¤íŒ¨: {e}")

with st.sidebar:
    st.header("ê°œì¸ ê·œì¹™")
    avoid = st.text_input("íšŒí”¼ í‚¤ì›Œë“œ(ì‰¼í‘œë¡œ êµ¬ë¶„)", value="")
    allow = st.text_input("í—ˆìš© í‚¤ì›Œë“œ(ì‰¼í‘œë¡œ êµ¬ë¶„)", value="")
    include_caution = st.checkbox("ê²½ê³„(Caution) í¬í•¨í•´ì„œ ì œì•ˆ", value=False)
    diversity_n = st.slider("ë‹¤ì–‘í™”(ìµœê·¼ NíšŒ ì¤‘ë³µ íšŒí”¼)", min_value=0, max_value=10, value=5, step=1)

user_rules = {
    "avoid_keywords": [x.strip() for x in avoid.split(",") if x.strip()],
    "allow_keywords": [x.strip() for x in allow.split(",") if x.strip()],
}

st.subheader("ì…ë ¥í•œ ì‹ë‹¨ì„ ì¦‰ì„ ë¶„ì„")
sample = "ìŒ€ë°¥1, ëŒ€êµ¬êµ¬ì´1, ì–‘ë°°ì¶”1, ë‹¹ê·¼1, ì˜¬ë¦¬ë¸Œìœ 0.5"
text_in = st.text_area("ì‹ë‹¨ í…ìŠ¤íŠ¸ (ì‰¼í‘œ ë˜ëŠ” ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„, ì˜ˆ: "+sample+")", height=120, placeholder=sample)

col_btn1, col_btn2 = st.columns([1,1])
with col_btn1:
    analyze = st.button("ë¶„ì„í•˜ê¸°", type="primary")
with col_btn2:
    clear = st.button("ì§€ìš°ê¸°")
if clear:
    text_in = ""
    st.experimental_rerun()

if analyze:
    try:
        scores, items_df = score_tokens(text_in, food_db, user_rules)

        st.markdown("### ğŸ± íŒŒì‹± ê²°ê³¼")
        if items_df.empty:
            st.info("í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤. ì‹ë‹¨ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        else:
            st.dataframe(items_df, use_container_width=True, height=280)

        st.markdown("### ğŸ§­ íƒœê·¸ ì ìˆ˜ + í•œì¤„ ì„¤ëª…")
        score_df = (
            pd.DataFrame([scores])
            .T.reset_index().rename(columns={"index":"ì˜ì–‘ì†Œ", 0:"ì ìˆ˜"})
            .sort_values("ì ìˆ˜", ascending=False)
        )
        score_df["í•œì¤„ì„¤ëª…"] = score_df["ì˜ì–‘ì†Œ"].map(lambda x: NUTRIENT_TIPS.get(x, ""))
        st.dataframe(score_df, use_container_width=True, height=360)

        # Missing essentials
        missing = [n for n in ESSENTIALS if scores.get(n, 0) < 1]
        if missing:
            tips_list = [f"- **{n}**: {NUTRIENT_TIPS.get(n, '')}" for n in missing]
            st.warning("ë¶€ì¡± íƒœê·¸:\n" + "\n".join(tips_list))
        else:
            st.success("í•µì‹¬ íƒœê·¸ ì¶©ì¡±! (ESSENTIALS ê¸°ì¤€)")

        # Diversity recent items (stub)
        recent_items = []
        try:
            if diversity_n > 0:
                r = ensure_log()
                r = r[r["type"] == "food"].copy()
                if not r.empty:
                    r["date"] = r["date"].astype(str)
                    r["time"] = r["time"].astype(str)
                    recent_df = r.sort_values(["date", "time"]).tail(diversity_n * 5)
                    recent_items = (recent_df["food_norm"].fillna("") + "|" + recent_df["item"].fillna("")).tolist()
                    recent_items = [x.split("|")[0] for x in recent_items if x]
        except Exception:
            recent_items = []

        st.markdown("### ğŸ½ï¸ ë‹¤ìŒ ì‹ì‚¬ ì œì•ˆ (3ê°€ì§€)")
        rng = random.Random(hash(("quick-eval", text_in)) % (10**9))
        favor_tags = missing  # focus on missing
        cols = st.columns(3)
        for idx in range(3):
            try:
                title, meal, explain = gen_meal(
                    food_db,
                    include_caution,
                    mode="ê¸°ë³¸",
                    recent_items=recent_items,
                    favor_tags=favor_tags,
                    rng=rng,
                    user_rules=user_rules,
                    allow_rare=False
                )
                with cols[idx]:
                    st.markdown(f"**{title} #{idx+1}**")
                    st.write(" / ".join(meal))
                    if favor_tags:
                        # show short reasons based on tips (first 2 tags to keep it short)
                        why = [f"Â· {t}: {NUTRIENT_TIPS.get(t, '')}" for t in favor_tags[:2]]
                        st.caption("ë³´ì™„ í¬ì¸íŠ¸:\n" + "\n".join(why))
                    elif explain:
                        st.caption(explain)
            except Exception as e:
                st.error(f"ì œì•ˆ ìƒì„± ì‹¤íŒ¨: {e}")
    except Exception as e:
        st.error(f"ë¶„ì„ ì‹¤íŒ¨: {e}")
